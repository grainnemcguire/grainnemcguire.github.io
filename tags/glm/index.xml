<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GLM | GMG</title>
    <link>/tags/glm/</link>
      <atom:link href="/tags/glm/index.xml" rel="self" type="application/rss+xml" />
    <description>GLM</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Grainne McGuire 2020 [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/)</copyright><lastBuildDate>Thu, 07 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>GLM</title>
      <link>/tags/glm/</link>
    </image>
    
    <item>
      <title>Traditional-style reserving using GLMs</title>
      <link>/post/traditional-style-reserving-using-glms/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/post/traditional-style-reserving-using-glms/</guid>
      <description>


&lt;p&gt;This post provides a worked example in R of fitting a GLM to some non-life claims reserving data.
The example and data are drawn from the CAS Monograph &lt;a href=&#34;/publication/2016_monograph&#34;&gt;Stochastic Loss Reserving using Generalized Linear Models&lt;/a&gt;.
Here we follow through the application of the cross-classified model from that monograph to the data (Chapter 3), and follow through with the additonal work to firstly simplify the model and secondly to improve the model fit through the use of some interaction terms (Chapter 7).&lt;/p&gt;
&lt;p&gt;If you want to access the underlying Rnotebook directly, you may access it at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grainnemcguire/code_snippets/blob/master/R/2019-11-07-traditional-style-reserving-using-glms.Rmd&#34;&gt;2019-11-07-traditional-style-reserving-using-glms.Rmd&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The data used is available in this &lt;a href=&#34;https://github.com/grainnemcguire/code_snippets/blob/master/data/glms_meyershi.csv&#34;&gt;csv file&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setup&lt;/h2&gt;
&lt;p&gt;Before we begin, we first set up the R session by loading in the various packages that we need.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/here/index.html&#34;&gt;here&lt;/a&gt;: I first heard about here from reading &lt;a href=&#34;https://github.com/jennybc/here_here&#34;&gt;Jenny Bryan’s&lt;/a&gt; article on it and have been a fan of &lt;code&gt;here&lt;/code&gt; and the R project structure ever since. It really helps with portability of code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basically it allows you to use relative rather than absolute file paths.&lt;/li&gt;
&lt;li&gt;If you want to run this notebook and don’t want to use &lt;code&gt;here&lt;/code&gt; then all you need to do is put an appropriate pathname in for loading in the data from a CSV file.
Location is not used anywhere else.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/Rdatatable/data.table&#34;&gt;data.table&lt;/a&gt; I really like &lt;code&gt;data.table&lt;/code&gt; - its power, speed and terseness. At some point though I may replace the &lt;code&gt;data.table&lt;/code&gt; code with base R to reduce dependencies. For now though, there isn’t a huge amount of &lt;code&gt;data.table&lt;/code&gt; code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Even if you don’t like &lt;code&gt;data.table&lt;/code&gt; syntax, the &lt;code&gt;fread&lt;/code&gt; and &lt;code&gt;fwrite&lt;/code&gt; functions can be very useful for reading and writing CSV files.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;ggplot2&lt;/a&gt;: create nice graphs easily&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html&#34;&gt;viridis&lt;/a&gt; nice colour palettes that are tested for common forms of colour-blindness&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/cowplot/index.html&#34;&gt;cowplot&lt;/a&gt; - an easy way of grouping graphs into a single figure&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html&#34;&gt;magrittr&lt;/a&gt; Use the &lt;code&gt;%&amp;gt;%&lt;/code&gt; pipe to reduce nested parentheses&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/knitr/index.html&#34;&gt;knitr&lt;/a&gt; The notebook uses &lt;code&gt;kable&lt;/code&gt; from the &lt;code&gt;knitr&lt;/code&gt; package. If you’re using RStudio to run this code in notebook format, then you should already have it. Otherwise you can install it, or you can simply replace all the &lt;code&gt;kable&lt;/code&gt; commands with print statements.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you don’t have any of these packages you will need to install them via &lt;code&gt;install.packages&lt;/code&gt; or, if using RStudio, via the Install buttom in the packages pane.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
library(here)
library(data.table)
library(ggplot2)
library(viridis)
library(cowplot)
library(magrittr)
# I have elected not to attach knitr, so we need to use knitr::kable() below

options(scipen = 99)   # get rid of scientific notation
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;The data are presented in Section 1.3 of the monograph. Ultimately the data were sourced from the Meyers and Shi (2011) database, and are the workers compensation triangle of the New Jersey Manufacturers Group.&lt;/p&gt;
&lt;p&gt;For ease of use, I have created a CSV file with the data which is loaded in this code chunk. As noted above I use relative path names with the &lt;code&gt;here&lt;/code&gt; package. If you don’t want to have a setup that works with &lt;code&gt;here&lt;/code&gt;, just ensure the full pathname to the file is included in the &lt;code&gt;fread&lt;/code&gt; statement below.&lt;/p&gt;
&lt;p&gt;Once the data is loaded in, have a look at the start of it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;msdata &amp;lt;- data.table::fread(here::here(&amp;quot;data/2019-11-07-glms_meyershi.csv&amp;quot;))
# if needed replace here::here(&amp;quot;data/glms_meyershi.csv&amp;quot;) with
# the correct path and filename of where you put the data

setDT(msdata)

print(msdata[1:6,])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    acc_year dev_year cumulative incremental
## 1:        1        1      41821       41821
## 2:        1        2      76550       34729
## 3:        1        3      96697       20147
## 4:        1        4     112662       15965
## 5:        1        5     123947       11285
## 6:        1        6     129871        5924&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we have four columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;acc_year: accident year, numbered from 1 to 10&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;dev_year: development year, also numbered from 1 to 10&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;cumulative: cumulative payments to date&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;incremental: incremental payments for that accident year, development year combination.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s look at the data visually.&lt;/p&gt;
&lt;p&gt;First we plot the cumulative amounts in each accident year&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data=msdata, aes(x=dev_year, y=cumulative, colour=as.factor(acc_year))) +
    geom_line(size=1) +
    scale_color_viridis_d(begin=0.9, end=0) + 
    ggtitle(&amp;quot;Cumulative amounts by development year&amp;quot;) + 
    theme_bw() + 
    theme(legend.position = &amp;quot;right&amp;quot;, legend.title=element_blank(), legend.text=element_text(size=8))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now look at the incremental amounts&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data=msdata, aes(x=dev_year, y=incremental, colour=as.factor(acc_year))) +
    geom_line(size=1) +
    scale_color_viridis_d(begin=0.9, end=0) + 
    ggtitle(&amp;quot;Incremental amounts by development year&amp;quot;) + 
    theme_bw() + 
    theme(legend.position = &amp;quot;right&amp;quot;, legend.title=element_blank(), legend.text=element_text(size=8))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The data look quite well behaved - each year seems to have a similar development pattern.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modelling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modelling&lt;/h2&gt;
&lt;div id=&#34;initial-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Initial model&lt;/h3&gt;
&lt;p&gt;The first model applied here is the Over-dispersed Poisson (ODP) cross classified (cc) model (Sections 3.3.2 and 3.3.3 of the monograph).
This model has been shown to give the same results as the chain ladder algorithm.&lt;/p&gt;
&lt;p&gt;To apply the model, we will use the &lt;code&gt;glm&lt;/code&gt; function from the base R &lt;code&gt;stats&lt;/code&gt; package. The cross-classified model requires separate levels for each of accident and development year so we first make a factor version of these variates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;msdata[, acc_year_factor := as.factor(acc_year)
       ][, dev_year_factor := as.factor(dev_year)
         ][, cal_year := acc_year + dev_year - 1]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we fit the model and look at the results via &lt;code&gt;summary&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The family is the &lt;em&gt;quasipoisson&lt;/em&gt; - this is how we fit an ODP model with &lt;code&gt;glm&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The link is log&lt;/li&gt;
&lt;li&gt;The formula is simply “incremental ~ 0 + acc_year_factor + dev_year_factor”
&lt;ul&gt;
&lt;li&gt;The 0 tells &lt;code&gt;glm&lt;/code&gt; to fit a model without an intercept&lt;/li&gt;
&lt;li&gt;We choose to do that here because then we can more easily compare the results to those in the monograph.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm_fit1 &amp;lt;- glm(data = msdata, 
    family = quasipoisson(link = &amp;quot;log&amp;quot;),
    formula = &amp;quot;incremental ~ 0 + acc_year_factor + dev_year_factor&amp;quot;)


summary(glm_fit1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = &amp;quot;incremental ~ 0 + acc_year_factor + dev_year_factor&amp;quot;, 
##     family = quasipoisson(link = &amp;quot;log&amp;quot;), data = msdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -21.493   -5.534    0.000    5.136   21.059  
## 
## Coefficients:
##                   Estimate Std. Error t value             Pr(&amp;gt;|t|)    
## acc_year_factor1  10.65676    0.03164 336.794 &amp;lt; 0.0000000000000002 ***
## acc_year_factor2  10.79533    0.02994 360.507 &amp;lt; 0.0000000000000002 ***
## acc_year_factor3  10.89919    0.02887 377.465 &amp;lt; 0.0000000000000002 ***
## acc_year_factor4  10.98904    0.02808 391.326 &amp;lt; 0.0000000000000002 ***
## acc_year_factor5  11.03883    0.02783 396.654 &amp;lt; 0.0000000000000002 ***
## acc_year_factor6  11.01590    0.02855 385.867 &amp;lt; 0.0000000000000002 ***
## acc_year_factor7  11.00808    0.02945 373.734 &amp;lt; 0.0000000000000002 ***
## acc_year_factor8  10.89050    0.03266 333.463 &amp;lt; 0.0000000000000002 ***
## acc_year_factor9  10.83613    0.03669 295.348 &amp;lt; 0.0000000000000002 ***
## acc_year_factor10 10.69108    0.05104 209.454 &amp;lt; 0.0000000000000002 ***
## dev_year_factor2  -0.20466    0.02276  -8.993  0.00000000009767316 ***
## dev_year_factor3  -0.74741    0.02819 -26.512 &amp;lt; 0.0000000000000002 ***
## dev_year_factor4  -1.01667    0.03284 -30.954 &amp;lt; 0.0000000000000002 ***
## dev_year_factor5  -1.45160    0.04214 -34.446 &amp;lt; 0.0000000000000002 ***
## dev_year_factor6  -1.83254    0.05471 -33.495 &amp;lt; 0.0000000000000002 ***
## dev_year_factor7  -2.14026    0.07150 -29.933 &amp;lt; 0.0000000000000002 ***
## dev_year_factor8  -2.34827    0.09312 -25.218 &amp;lt; 0.0000000000000002 ***
## dev_year_factor9  -2.51317    0.12673 -19.831 &amp;lt; 0.0000000000000002 ***
## dev_year_factor10 -2.66449    0.19930 -13.369  0.00000000000000158 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 114.5364)
## 
##     Null deviance: 27479374.2  on 55  degrees of freedom
## Residual deviance:     4128.1  on 36  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now extract the coefficient table in a more convenient way and append it onto the &lt;code&gt;glm_fit1&lt;/code&gt; object for later use.&lt;/p&gt;
&lt;p&gt;We will also print the table again in a nicer form to make it easier to compare to the first 3 columns of Table 3-5 of the monograph.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you do this, you should see that the results match.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# save the data for later use
glm_fit1$coeff_table &amp;lt;- data.table(parameter = names(glm_fit1$coefficients), 
                                   coeff_glm_fit1 = glm_fit1$coefficients)

# print out the table so we can compare against Table 3-5.
glm_fit1$coeff_table %&amp;gt;% 
    knitr::kable(digits=c(0,3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;coeff_glm_fit1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.657&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.795&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.899&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.989&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.039&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.008&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.891&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.836&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_factor10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.691&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.205&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.747&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.452&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.833&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.348&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.513&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_factor10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.664&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;loss-reserve&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Loss reserve&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We will calculate the loss reserve for this model&lt;/li&gt;
&lt;li&gt;This should give the same answers as the chain ladder algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# first make the lower triangle data set
ay &amp;lt;- NULL
dy &amp;lt;- NULL


for(i in 2:10){
    ay &amp;lt;- c(ay, rep(i, times=(i-1)))
    dy &amp;lt;- c(dy, (10-i+2):10)
}

futdata &amp;lt;- data.table(acc_year = ay, dev_year = dy)

# make factors
futdata[, cal_year := acc_year + dev_year
        ][, acc_year_factor := as.factor(acc_year)
          ][, dev_year_factor := as.factor(dev_year)]

# make the prediction and sum by acc_year
x &amp;lt;- predict(glm_fit1, newdata = futdata, type=&amp;quot;response&amp;quot;)
futdata[, incremental := x]


ocl_year &amp;lt;- futdata[,  lapply(.SD, sum), .SDcols=c(&amp;quot;incremental&amp;quot;), by=&amp;quot;acc_year&amp;quot;]

ocl_year %&amp;gt;% 
    knitr::kable(digits=c(0, 0))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;acc_year&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;incremental&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3398&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8155&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14579&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;22645&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;31865&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;45753&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;60093&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;80983&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;105874&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;As expected, this matches the results in Table 3-2 of the monograph.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;model-diagnostics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model diagnostics&lt;/h3&gt;
&lt;p&gt;It’s always important to check that a model fits the data well, so here we look at the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Residual Scatterplots
&lt;ul&gt;
&lt;li&gt;by linear predictor&lt;/li&gt;
&lt;li&gt;by accident, development and calendar years&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Heat map of actual vs fitted
&lt;ul&gt;
&lt;li&gt;In this we get the actual/fitted ratio in each (acc, dev) cell [subject to lower and upper bounds of (0.5, 2)] and then plot the colour-coded triangle of the actual/fitted values&lt;/li&gt;
&lt;li&gt;heat maps are helpful to check for model fit and may help to identify missing interactions.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note on residuals with &lt;code&gt;glm&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The residuals in a glm object accessed with &lt;code&gt;$residuals&lt;/code&gt; are residuals used in the model fitting algorithm.&lt;/li&gt;
&lt;li&gt;For diagnostic purposes, the standardised deviance residuals are usually preferable to work with.
&lt;ul&gt;
&lt;li&gt;These are the signed square roots of the contribution of the i&lt;em&gt;th&lt;/em&gt; observation to the deviance, divided by hat matrix values.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;stats::rstandard()&lt;/code&gt; function may be used with glm objects to extract the standardised deviance residuals.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Generating the diagnostics&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First we prepare the data by adding the fitted values and residuals.
&lt;ul&gt;
&lt;li&gt;Because this model has a lot of parameters, there are two observations where the fitted is exactly equal to the actual – (acc_year=1, dev_year=10) and (acc_year=10, dev_year=0).
This is because these observations have a unique parameter.&lt;/li&gt;
&lt;li&gt;The deviance calculations below return NaN (not a number) for these points, but the residual should really be 0 so this adjustment is made manually.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Also add actual/fitted ratios and the log of these (restricted to the range [log(0.5), log(2)]) - these will be used for a heatmap later.
&lt;ul&gt;
&lt;li&gt;The restricted range is used to generate easier to read shadings in the heat-map, while the conversion to log means that the shading scales will be similar intensity for &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(1/x\)&lt;/span&gt; %&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;msdata[, residuals1 := rstandard(glm_fit1)
       ][, fitted1 := glm_fit1$fitted.values
         ][, linear_predictor1 := log(fitted1)
           ][, AvsF1 := incremental / fitted1
             ][, AvsF_restricted1 := log(pmax(0.5, pmin(2,AvsF1)))]

# check for NaN residuals
msdata[is.nan(residuals1),]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    acc_year dev_year cumulative incremental acc_year_factor dev_year_factor
## 1:        1       10     144781        2958               1              10
## 2:       10        1      43962       43962              10               1
##    cal_year residuals1 fitted1 linear_predictor1 AvsF1
## 1:       10        NaN    2958          7.992269     1
## 2:       10        NaN   43962         10.691081     1
##             AvsF_restricted1
## 1: -0.0000000000000019984014
## 2:  0.0000000000000008881784&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# these occur where we expect them so so replace with 0
msdata[is.nan(residuals1), residuals1 := 0]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look at the first 10 rows of msdata&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(msdata, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     acc_year dev_year cumulative incremental acc_year_factor dev_year_factor
##  1:        1        1      41821       41821               1               1
##  2:        1        2      76550       34729               1               2
##  3:        1        3      96697       20147               1               3
##  4:        1        4     112662       15965               1               4
##  5:        1        5     123947       11285               1               5
##  6:        1        6     129871        5924               1               6
##  7:        1        7     134646        4775               1               7
##  8:        1        8     138388        3742               1               8
##  9:        1        9     141823        3435               1               9
## 10:        1       10     144781        2958               1              10
##     cal_year  residuals1   fitted1 linear_predictor1     AvsF1
##  1:        1 -0.37704981 42478.725         10.656759 0.9845164
##  2:        2  0.06821815 34616.808         10.452095 1.0032410
##  3:        3  0.02211088 20117.514          9.909346 1.0014657
##  4:        4  0.50192703 15368.757          9.640092 1.0387958
##  5:        5  1.36344235  9948.355          9.205163 1.1343584
##  6:        6 -1.13119533  6796.876          8.824218 0.8715769
##  7:        7 -0.33754581  4996.553          8.516503 0.9556589
##  8:        8 -0.56680264  4058.159          8.308485 0.9220929
##  9:        9 -0.01379476  3441.253          8.143591 0.9981829
## 10:       10  0.00000000  2958.000          7.992269 1.0000000
##             AvsF_restricted1
##  1: -0.015604749951508145936
##  2:  0.003235741327323749146
##  3:  0.001464610789021573859
##  4:  0.038062125103388820546
##  5:  0.126067171138098593763
##  6: -0.137451186377785167236
##  7: -0.045354245283910396558
##  8: -0.081109303248732236846
##  9: -0.001818723883641001036
## 10: -0.000000000000001998401&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s look at the residual scatterplots - here I use the &lt;code&gt;cowplot&lt;/code&gt; package to combine all 4 graphs into one plot.&lt;/p&gt;
&lt;p&gt;In the linear predictor scatterplot, the points are colour coded so that the lighter points belong to the earlier development years, and the darker points belong to the later ones.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(data=msdata, aes(x=linear_predictor1, y=residuals1, colour=dev_year)) +
    geom_point(size=2) +
    scale_colour_viridis(begin=0.9, end=0) +
    theme_bw() + 
    theme(legend.position = &amp;quot;none&amp;quot;) +
    ggtitle(&amp;quot;Linear predictor&amp;quot;)


p2 &amp;lt;- ggplot(data=msdata, aes(x=acc_year, y=residuals1)) +
    geom_point(size=2, colour=&amp;quot;#2d708eff&amp;quot;) +
    theme_bw() + 
    ggtitle(&amp;quot;Accident year&amp;quot;)

p3 &amp;lt;- ggplot(data=msdata, aes(x=dev_year, y=residuals1)) +
    geom_point(size=2, colour=&amp;quot;#2d708eff&amp;quot;) +
    theme_bw() + 
    ggtitle(&amp;quot;Development year&amp;quot;)

p4 &amp;lt;- ggplot(data=msdata, aes(x=cal_year, y=residuals1)) +
    geom_point(size=2, colour=&amp;quot;#2d708eff&amp;quot;) +
    theme_bw() + 
    ggtitle(&amp;quot;Calendar year&amp;quot;)

p &amp;lt;- plot_grid(p1, p2, p3, p4, nrow=2, rel_widths = c(1,1,1,1))

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now construct and draw the heat map. Note that the colours are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;blue (A/F = 50%)&lt;/li&gt;
&lt;li&gt;white (A/F = 100%)&lt;/li&gt;
&lt;li&gt;red (A/F = 200%)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# heatmap code
# to get the correct shading I&amp;#39;ve plotted the log of the restricted A/F values

p_hm &amp;lt;- ggplot(data=msdata, aes(x=dev_year, y=acc_year)) + 
    geom_tile(aes(fill = AvsF_restricted1))+scale_y_reverse()+
    scale_fill_gradient2(name=&amp;quot;AvF_min&amp;quot;, low=&amp;quot;royalblue&amp;quot;, mid=&amp;quot;white&amp;quot;, high=&amp;quot;red&amp;quot;, midpoint=0, space=&amp;quot;Lab&amp;quot;, na.value=&amp;quot;grey50&amp;quot;, guide=&amp;quot;colourbar&amp;quot;)+
    labs(x=&amp;quot;Development year&amp;quot;, y=&amp;quot;Accident year&amp;quot;)+
    theme(legend.position = &amp;quot;none&amp;quot;)+
    theme(axis.title.x = element_text(size=8), axis.text.x  = element_text(size=7))+
    theme(axis.title.y = element_text(size=8), axis.text.y  = element_text(size=7))+
    theme(panel.background = element_rect(fill = &amp;quot;grey&amp;quot;, colour = &amp;quot;grey&amp;quot;, size = 2, linetype = &amp;quot;solid&amp;quot;),
          panel.grid = element_line(colour=&amp;quot;grey&amp;quot;)) + 
    NULL

print(p_hm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;refining-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Refining the model&lt;/h2&gt;
&lt;p&gt;We could stop here - and just use the results from this model, which match those produced by the chain ladder. The diagnostics suggest that the model fits quite well.
However can we:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;identify simplifications to the model to make it more parsinomious?&lt;/li&gt;
&lt;li&gt;identify any areas of poorer fit than may suggest missing model terms including interactions?&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;simplifying-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simplifying the model&lt;/h3&gt;
&lt;p&gt;First we consider if we can use a parametric shape for the accident and development year parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;accident-year&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Accident year&lt;/h3&gt;
&lt;p&gt;First plot the accident year parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the data
dt_acc_year &amp;lt;- glm_fit1$coeff_table[grepl(&amp;quot;acc_year&amp;quot;, parameter),  
                                    ][, acc_year := as.integer(gsub(&amp;quot;acc_year_factor&amp;quot;, &amp;quot;&amp;quot;, parameter))]


# plot
ggplot(data=dt_acc_year, aes(x=acc_year, y=coeff_glm_fit1)) +
    geom_line(size=2, colour=&amp;quot;#440154ff&amp;quot;) +
    geom_point(size=4, colour=&amp;quot;#440154ff&amp;quot;) + 
    theme_bw() + 
    ggtitle(&amp;quot;Accident year parameters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Note that their shape closely resembles that of a parabola.&lt;/li&gt;
&lt;li&gt;This suggests that we can replace the 10 accident year parameters by
&lt;ul&gt;
&lt;li&gt;the overall intercept&lt;/li&gt;
&lt;li&gt;an acc_year term&lt;/li&gt;
&lt;li&gt;an acc_year squarted term&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;So refit the model on this basis.
&lt;ul&gt;
&lt;li&gt;Drop the 0 from the glm_fit1 formula to allow the model to have an intecept&lt;/li&gt;
&lt;li&gt;Replace the acc_year_factor term with the parabola terms.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add an x and x^2 term
msdata[, acc_year_2 := acc_year^2]

glm_fit2 &amp;lt;- glm(data = msdata, 
    family = quasipoisson(link = &amp;quot;log&amp;quot;),
    formula = &amp;quot;incremental ~ acc_year + acc_year_2 + dev_year_factor&amp;quot;)


summary(glm_fit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = &amp;quot;incremental ~ acc_year + acc_year_2 + dev_year_factor&amp;quot;, 
##     family = quasipoisson(link = &amp;quot;log&amp;quot;), data = msdata)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -28.5517   -5.1747    0.2691    4.5827   24.5421  
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&amp;gt;|t|)    
## (Intercept)       10.470978   0.034414 304.264 &amp;lt; 0.0000000000000002 ***
## acc_year           0.200075   0.014219  14.071 &amp;lt; 0.0000000000000002 ***
## acc_year_2        -0.017907   0.001356 -13.210 &amp;lt; 0.0000000000000002 ***
## dev_year_factor2  -0.205555   0.021276  -9.661     0.00000000000243 ***
## dev_year_factor3  -0.750108   0.026492 -28.314 &amp;lt; 0.0000000000000002 ***
## dev_year_factor4  -1.014806   0.030982 -32.755 &amp;lt; 0.0000000000000002 ***
## dev_year_factor5  -1.451958   0.039797 -36.484 &amp;lt; 0.0000000000000002 ***
## dev_year_factor6  -1.830488   0.051662 -35.432 &amp;lt; 0.0000000000000002 ***
## dev_year_factor7  -2.142154   0.067504 -31.734 &amp;lt; 0.0000000000000002 ***
## dev_year_factor8  -2.352674   0.087924 -26.758 &amp;lt; 0.0000000000000002 ***
## dev_year_factor9  -2.513722   0.119637 -21.011 &amp;lt; 0.0000000000000002 ***
## dev_year_factor10 -2.660878   0.187820 -14.167 &amp;lt; 0.0000000000000002 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 102.5776)
## 
##     Null deviance: 750824  on 54  degrees of freedom
## Residual deviance:   4427  on 43  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see in the coefficient table part of the summary that the two acc_year terms are highly significant.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Now extract the coefficients and compare the previous and current fits.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remember that the intercept must be included in these calculations.&lt;/li&gt;
&lt;li&gt;Again, save the coefficient table in this extracted form with the glm_fit2 object for later use.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the coefficient table
glm_fit2$coeff_table &amp;lt;- data.table(parameter = names(glm_fit2$coefficients), coeff_glm_fit2 = glm_fit2$coefficients)
print(glm_fit2$coeff_table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             parameter coeff_glm_fit2
##  1:       (Intercept)    10.47097818
##  2:          acc_year     0.20007497
##  3:        acc_year_2    -0.01790686
##  4:  dev_year_factor2    -0.20555514
##  5:  dev_year_factor3    -0.75010823
##  6:  dev_year_factor4    -1.01480620
##  7:  dev_year_factor5    -1.45195754
##  8:  dev_year_factor6    -1.83048769
##  9:  dev_year_factor7    -2.14215388
## 10:  dev_year_factor8    -2.35267361
## 11:  dev_year_factor9    -2.51372160
## 12: dev_year_factor10    -2.66087765&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compare the past and current parameter estimates for accident year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# pull out the acc year coefficinents only
dt_acc_year[, coeff_glm_fit2 := glm_fit2$coeff_table[parameter == &amp;quot;acc_year&amp;quot;, coeff_glm_fit2]*acc_year + 
                glm_fit2$coeff_table[parameter == &amp;quot;acc_year_2&amp;quot;, coeff_glm_fit2]*acc_year^2 + 
                glm_fit2$coeff_table[parameter == &amp;quot;(Intercept)&amp;quot;, coeff_glm_fit2]]

# make long for ggplot
dt_acc_year_plot &amp;lt;- melt(dt_acc_year, id.vars = &amp;quot;acc_year&amp;quot;, measure.vars = c(&amp;quot;coeff_glm_fit1&amp;quot;, &amp;quot;coeff_glm_fit2&amp;quot;), variable.name=&amp;quot;model&amp;quot;, value = &amp;quot;estimate&amp;quot;)

# remove the coeff_ from the model names
dt_acc_year_plot[, model := gsub(&amp;quot;coeff_&amp;quot;, &amp;quot;&amp;quot;, model, fixed=TRUE)]

ggplot(data=dt_acc_year_plot, aes(x=acc_year, y=estimate, colour=model)) +
    geom_line(size=2) +
    geom_point(size=4) +
    scale_colour_viridis_d(begin=0, end=0.5) + 
    theme_bw() + 
    ggtitle(&amp;quot;Accident year parameters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This looks very good - the fit is very similar, but we have 7 fewer parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;development-year&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Development year&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Now we do the same thing for development year&lt;/li&gt;
&lt;li&gt;Note that the glm_fit2 model (and the glm_fit1 model too) do not have a parameter for dev_year = 1 as this is the base level.
&lt;ul&gt;
&lt;li&gt;This means that the parameter is really 0, so we must remember to include this.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the data
dt_dev_year &amp;lt;- glm_fit2$coeff_table[grepl(&amp;quot;dev_year&amp;quot;, parameter),  
                                    ][, dev_year := as.integer(gsub(&amp;quot;dev_year_factor&amp;quot;, &amp;quot;&amp;quot;, parameter))][]   # known data.table printing bug

# add year 1
dt_dev_year &amp;lt;- rbind(dt_dev_year, data.table(parameter=&amp;quot;dev_year_factor1&amp;quot;, coeff_glm_fit2=0, dev_year=1))
setorder(dt_dev_year, dev_year)


# plot
ggplot(data=dt_dev_year, aes(x=dev_year, y=coeff_glm_fit2)) +
    geom_line(size=2, colour=&amp;quot;#440154ff&amp;quot;) +
    geom_point(size=4, colour=&amp;quot;#440154ff&amp;quot;) +
    theme_bw() +
    ggtitle(&amp;quot;Development year parameters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Looking at this plot, it appears that a straight line would fit quite well&lt;/li&gt;
&lt;li&gt;This fit would be improved by allowing the straight line to bend (have a knot) at dev_year = 7
&lt;ul&gt;
&lt;li&gt;So let’s try this below&lt;/li&gt;
&lt;li&gt;note we actually fit dev_year - 1 rather than dev_year
&lt;ul&gt;
&lt;li&gt;this means that the parameter estimate at dev_year = 1 is 0, just as it is in the glm_fit2 model, so it makes the results comparable&lt;/li&gt;
&lt;li&gt;if we fit dev_year, then the parameter estimate at dev_year=1 would be non-zero, so the two fits would be shifted relative to each other and we would need to adjust for that.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add dev-1 and dev-7 terms
msdata[, dev_year_m1 := dev_year - 1]
msdata[, dev_year_ge_7 := pmax(dev_year-7.5, 0)]

# fit the model
glm_fit3 &amp;lt;- glm(data = msdata, 
    family = quasipoisson(link = &amp;quot;log&amp;quot;),
    formula = &amp;quot;incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7&amp;quot;)

# extract and save the coefficient table
glm_fit3$coeff_table &amp;lt;- data.table(parameter = names(glm_fit3$coefficients), coeff_glm_fit3 = glm_fit3$coefficients)

# display a summary of the model
summary(glm_fit3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = &amp;quot;incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7&amp;quot;, 
##     family = quasipoisson(link = &amp;quot;log&amp;quot;), data = msdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -25.301   -9.262   -2.080    5.893   42.841  
## 
## Coefficients:
##                Estimate Std. Error t value             Pr(&amp;gt;|t|)    
## (Intercept)   10.509475   0.052096 201.734 &amp;lt; 0.0000000000000002 ***
## acc_year       0.204224   0.021608   9.451     0.00000000000104 ***
## acc_year_2    -0.018295   0.002058  -8.891     0.00000000000719 ***
## dev_year_m1   -0.364073   0.008845 -41.160 &amp;lt; 0.0000000000000002 ***
## dev_year_ge_7  0.238860   0.088426   2.701              0.00941 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 242.0614)
## 
##     Null deviance: 750824  on 54  degrees of freedom
## Residual deviance:  11879  on 50  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Assuming the fit is satisfactory, our original model with 19 parmaeters has now been simplified to 5 parameters - much more parsimonious and robust.&lt;/li&gt;
&lt;li&gt;Let’s check the fit by dev_year to see.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get the dev_year fit under the new model and add to the data.table containing the factor level parameters
p1 &amp;lt;- glm_fit3$coeff_table[parameter == &amp;quot;dev_year_m1&amp;quot;, coeff_glm_fit3]
p2 &amp;lt;- glm_fit3$coeff_table[parameter == &amp;quot;dev_year_ge_7&amp;quot;, coeff_glm_fit3]
dt_dev_year[, coeff_glm_fit3 := p1*(dev_year-1) + p2*pmax(0, dev_year-7.5) ]


# make long for ggplot
dt_dev_year_plot &amp;lt;- melt(dt_dev_year, id.vars = &amp;quot;dev_year&amp;quot;, measure.vars = c(&amp;quot;coeff_glm_fit2&amp;quot;, &amp;quot;coeff_glm_fit3&amp;quot;), variable.name=&amp;quot;model&amp;quot;, value = &amp;quot;estimate&amp;quot;)

# remove the coeff_ from the model names
dt_dev_year_plot[, model := gsub(&amp;quot;coeff_&amp;quot;, &amp;quot;&amp;quot;, model, fixed=TRUE)]


ggplot(data=dt_dev_year_plot, aes(x=dev_year, y=estimate, colour=model)) +
    geom_line(size=2) +
    geom_point(size=4) +
    scale_colour_viridis_d(begin=0, end=0.5) +
    theme_bw() +
    ggtitle(&amp;quot;Accident year parameters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This looks good.&lt;/li&gt;
&lt;li&gt;However dev_year = 2 is a bit underfit in the latest model, so we can add something to improve this fit&lt;/li&gt;
&lt;li&gt;So refit and replot.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;msdata[, dev_year_eq_2 := as.integer(dev_year == 2)]

glm_fit4 &amp;lt;- glm(data = msdata, 
    family = quasipoisson(link = &amp;quot;log&amp;quot;),
    formula = &amp;quot;incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7 + dev_year_eq_2&amp;quot;)


glm_fit4$coeff_table &amp;lt;- data.table(parameter = names(glm_fit4$coefficients), coeff_glm_fit4 = glm_fit4$coefficients)


p1 &amp;lt;- glm_fit4$coeff_table[parameter == &amp;quot;dev_year_m1&amp;quot;, coeff_glm_fit4]
p2 &amp;lt;- glm_fit4$coeff_table[parameter == &amp;quot;dev_year_ge_7&amp;quot;, coeff_glm_fit4]
p3 &amp;lt;- glm_fit4$coeff_table[parameter == &amp;quot;dev_year_eq_2&amp;quot;, coeff_glm_fit4]
dt_dev_year[, coeff_glm_fit4 := p1*(dev_year-1) + p2*pmax(0, dev_year-7.5) + p3*(dev_year == 2) ]


# make long for ggplot
dt_dev_year_plot &amp;lt;- melt(dt_dev_year, id.vars = &amp;quot;dev_year&amp;quot;, measure.vars = c(&amp;quot;coeff_glm_fit2&amp;quot;, &amp;quot;coeff_glm_fit4&amp;quot;), variable.name=&amp;quot;model&amp;quot;, value = &amp;quot;estimate&amp;quot;)

# remove the coeff_ from the model names
dt_dev_year_plot[, model := gsub(&amp;quot;coeff_&amp;quot;, &amp;quot;&amp;quot;, model, fixed=TRUE)]


ggplot(data=dt_dev_year_plot, aes(x=dev_year, y=estimate, colour=model)) +
    geom_line(size=2) +
    geom_point(size=4) +
    scale_colour_viridis_d(begin=0, end=0.5) +
    theme_bw() +
    ggtitle(&amp;quot;Accident year parameters&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Looks good!&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;identifying-missing-structure&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Identifying missing structure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The second part of the model refining process involves checking for missing structure.&lt;/li&gt;
&lt;li&gt;Let’s have a better look at the heat map.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;msdata[, residuals4 := rstandard(glm_fit4)
       ][, fitted4 := glm_fit4$fitted.values
         ][, linear_predictor4 := log(fitted4)
           ][, AvsF4 := incremental / fitted4
             ][, AvsF_restricted4 := log(pmax(0.5, pmin(2,AvsF4)))]


p_hm &amp;lt;- ggplot(data=msdata, aes(x=dev_year, y=acc_year)) + 
    geom_tile(aes(fill = AvsF_restricted4))+scale_y_reverse()+
    scale_fill_gradient2(name=&amp;quot;AvF_min&amp;quot;, low=&amp;quot;royalblue&amp;quot;, mid=&amp;quot;white&amp;quot;, high=&amp;quot;red&amp;quot;, midpoint=0, space=&amp;quot;Lab&amp;quot;, na.value=&amp;quot;grey50&amp;quot;, guide=&amp;quot;colourbar&amp;quot;)+
    labs(x=&amp;quot;Development year&amp;quot;, y=&amp;quot;Accident year&amp;quot;)+
    theme(legend.position = &amp;quot;none&amp;quot;)+
    theme(axis.title.x = element_text(size=8), axis.text.x  = element_text(size=7))+
    theme(axis.title.y = element_text(size=8), axis.text.y  = element_text(size=7))+
    theme(panel.background = element_rect(fill = &amp;quot;grey&amp;quot;, colour = &amp;quot;grey&amp;quot;, size = 2, linetype = &amp;quot;solid&amp;quot;),
          panel.grid = element_line(colour=&amp;quot;grey&amp;quot;)) + 
    NULL

print(p_hm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s look at the heatmap again, with some annotations&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_hm + 
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 0.5, xmax=1.5, ymin=0.5, ymax=6.5, colour=&amp;quot;darkblue&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 0.5, xmax=1.5, ymin=6.5, ymax=10.5, colour=&amp;quot;darkred&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 1.5, xmax=2.5, ymin=0.5, ymax=6.5, colour=&amp;quot;darkred&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 1.5, xmax=2.5, ymin=6.5, ymax=9.5, colour=&amp;quot;darkblue&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;segment&amp;quot;, x=3, xend=3, y=1, yend=8, arrow=arrow(), colour=&amp;quot;darkblue&amp;quot;, size=2) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 3.5, xmax=4.5, ymin=0.5, ymax=7.5, colour=&amp;quot;darkred&amp;quot;, alpha=0.1, size=1.5) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;development year 1, a distinct area of blue in the earlier accident years (A &amp;lt; F), followed by red (A &amp;gt; F)&lt;/li&gt;
&lt;li&gt;development year 2, a distinct area of red in the earlier accident years (A &amp;gt; F), followed by blue (A &amp;lt; F)&lt;/li&gt;
&lt;li&gt;development year 3, a possible progression from red to blue with increasing accident year (F increasing relative to A)&lt;/li&gt;
&lt;li&gt;development year 4, nearly all red (A &amp;gt; F)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This suggests the payment pattern has altered and can be accommodated by (mostly) interaction terms within the GLM. Consider adding the following terms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(development year = 1) * (accident year is between 1 and 6)&lt;/li&gt;
&lt;li&gt;(development year = 2) * (accident year is between 1 and 6)&lt;/li&gt;
&lt;li&gt;(development year = 3) * (accident year linear trend)&lt;/li&gt;
&lt;li&gt;(development year = 4)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, let’s refit the model with terms to capture these and have a look at the heat map again&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add the new terms
msdata[, dev_year_eq_1 := as.integer(dev_year == 1)]
msdata[, dev_year_eq_3 := as.integer(dev_year == 3)]
msdata[, dev_year_eq_4 := as.integer(dev_year == 4)]
msdata[, acc_year_1_6 := as.integer(acc_year &amp;gt;= 1 &amp;amp; acc_year &amp;lt;= 6)]


glm_fit5 &amp;lt;- glm(data = msdata, 
    family = quasipoisson(link = &amp;quot;log&amp;quot;),
    formula = &amp;quot;incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7 + dev_year_eq_2 + dev_year_eq_4 +
    dev_year_eq_1:acc_year_1_6 +  dev_year_eq_2:acc_year_1_6 + dev_year_eq_3:acc_year &amp;quot;)



glm_fit5$coeff_table &amp;lt;- data.table(parameter = names(glm_fit5$coefficients), coeff_glm_fit5 = glm_fit5$coefficients)

# print the coefficient table

glm_fit5$coeff_table %&amp;gt;% 
    knitr::kable(digits=c(0, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;coeff_glm_fit5&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.4904&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2066&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year_2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0183&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_m1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3685&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_ge_7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2720&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_eq_2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0375&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_eq_4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0528&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_eq_1:acc_year_1_6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0671&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;dev_year_eq_2:acc_year_1_6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1273&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;acc_year:dev_year_eq_3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0113&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;This model should match that displayed in Table 7-5 of the monograph - and indeed it does (some very minor differences in parameter values - the model in the monograph was fitted in SAS).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Look at the heat map again with annotations - has the model resolved the identified issues?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# attach fitteds and residuals
msdata[, residuals5 := rstandard(glm_fit5)
       ][, fitted5 := glm_fit5$fitted.values
         ][, linear_predictor5 := log(fitted5)
           ][, AvsF5 := incremental / fitted5
             ][, AvsF_restricted5 := log(pmax(0.5, pmin(2,AvsF5)))]



p_hm &amp;lt;- ggplot(data=msdata, aes(x=dev_year, y=acc_year)) + 
    geom_tile(aes(fill = AvsF_restricted5))+scale_y_reverse()+
    scale_fill_gradient2(name=&amp;quot;AvF_min&amp;quot;, low=&amp;quot;royalblue&amp;quot;, mid=&amp;quot;white&amp;quot;, high=&amp;quot;red&amp;quot;, midpoint=0, space=&amp;quot;Lab&amp;quot;, na.value=&amp;quot;grey50&amp;quot;, guide=&amp;quot;colourbar&amp;quot;)+
    labs(x=&amp;quot;Development year&amp;quot;, y=&amp;quot;Accident year&amp;quot;)+
    theme(legend.position = &amp;quot;none&amp;quot;)+
    theme(axis.title.x = element_text(size=8), axis.text.x  = element_text(size=7))+
    theme(axis.title.y = element_text(size=8), axis.text.y  = element_text(size=7))+
    theme(panel.background = element_rect(fill = &amp;quot;grey&amp;quot;, colour = &amp;quot;grey&amp;quot;, size = 2, linetype = &amp;quot;solid&amp;quot;),
          panel.grid = element_line(colour=&amp;quot;grey&amp;quot;)) + 
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 0.5, xmax=1.5, ymin=0.5, ymax=6.5, colour=&amp;quot;darkblue&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 0.5, xmax=1.5, ymin=6.5, ymax=10.5, colour=&amp;quot;darkred&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 1.5, xmax=2.5, ymin=0.5, ymax=6.5, colour=&amp;quot;darkred&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 1.5, xmax=2.5, ymin=6.5, ymax=9.5, colour=&amp;quot;darkblue&amp;quot;, alpha=0.1, size=1.5) +
    annotate(geom=&amp;quot;segment&amp;quot;, x=3, xend=3, y=1, yend=8, arrow=arrow(), colour=&amp;quot;darkblue&amp;quot;, size=2) +
    annotate(geom=&amp;quot;rect&amp;quot;, xmin= 3.5, xmax=4.5, ymin=0.5, ymax=7.5, colour=&amp;quot;darkred&amp;quot;, alpha=0.1, size=1.5) 


print(p_hm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;This looks much better.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We should also look at the residual plots again&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- ggplot(data=msdata, aes(x=linear_predictor5, y=residuals5, colour=dev_year)) +
    geom_point(size=2) +
    scale_colour_viridis(begin=0.9, end=0) +
    theme_bw() + 
    theme(legend.position = &amp;quot;none&amp;quot;) +
    ggtitle(&amp;quot;Linear predictor&amp;quot;)


p2 &amp;lt;- ggplot(data=msdata, aes(x=acc_year, y=residuals5)) +
    geom_point(size=2, colour=&amp;quot;#2d708eff&amp;quot;) +
    theme_bw() + 
    ggtitle(&amp;quot;Accident year&amp;quot;)

p3 &amp;lt;- ggplot(data=msdata, aes(x=dev_year, y=residuals5)) +
    geom_point(size=2, colour=&amp;quot;#2d708eff&amp;quot;) +
    theme_bw() + 
    ggtitle(&amp;quot;Development year&amp;quot;)

p4 &amp;lt;- ggplot(data=msdata, aes(x=cal_year, y=residuals5)) +
    geom_point(size=2, colour=&amp;quot;#2d708eff&amp;quot;) +
    theme_bw() + 
    ggtitle(&amp;quot;Calendar year&amp;quot;)

p &amp;lt;- plot_grid(p1, p2, p3, p4, nrow=2, rel_widths = c(1,1,1,1))

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-07-traditional-style-reserving-using-glms_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;loss-reserve-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Loss reserve&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Now that we have a model, let’s produce the estimate of the outstanding claims by accident year and in total.
&lt;ul&gt;
&lt;li&gt;Take the lower triangle data [futdata] created above&lt;/li&gt;
&lt;li&gt;Add on the new variates we created&lt;/li&gt;
&lt;li&gt;Score the model on this data&lt;/li&gt;
&lt;li&gt;Summarise the results&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;
Create the data and score using &lt;code&gt;predict&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add all model variates
futdata[, acc_year_2 := acc_year^2
        ][, dev_year_m1 := dev_year - 1
          ][, dev_year_ge_7 := pmax(0, dev_year - 7.5)
            ][, dev_year_eq_1 := as.integer(dev_year == 1)
              ][, dev_year_eq_2 := as.integer(dev_year == 2)
                ][, dev_year_eq_3 := as.integer(dev_year == 3)
                  ][, dev_year_eq_4 := as.integer(dev_year == 4)
                    ][, acc_year_1_6 := as.integer(acc_year&amp;gt;=1 &amp;amp; acc_year &amp;lt;=6)]


x &amp;lt;- predict(glm_fit5, newdata = futdata, type=&amp;quot;response&amp;quot;)
futdata[, incremental := x]

head(futdata)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    acc_year dev_year cal_year acc_year_factor dev_year_factor incremental
## 1:        2       10       12               2              10    3618.769
## 2:        3        9       12               3               9    4470.907
## 3:        3       10       13               3              10    4059.635
## 4:        4        8       12               4               8    5324.841
## 5:        4        9       13               4               9    4835.016
## 6:        4       10       14               4              10    4390.250
##    acc_year_2 dev_year_m1 dev_year_ge_7 dev_year_eq_1 dev_year_eq_2
## 1:          4           9           2.5             0             0
## 2:          9           8           1.5             0             0
## 3:          9           9           2.5             0             0
## 4:         16           7           0.5             0             0
## 5:         16           8           1.5             0             0
## 6:         16           9           2.5             0             0
##    dev_year_eq_3 dev_year_eq_4 acc_year_1_6
## 1:             0             0            1
## 2:             0             0            1
## 3:             0             0            1
## 4:             0             0            1
## 5:             0             0            1
## 6:             0             0            1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Get reserves by accident year and in total&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ocl_year &amp;lt;- futdata[,  lapply(.SD, sum), .SDcols=c(&amp;quot;incremental&amp;quot;), by=&amp;quot;acc_year&amp;quot;]
ocl_total &amp;lt;- ocl_year[, sum(incremental)]


ocl_year %&amp;gt;% 
    knitr::kable(digits=c(0, 0))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;acc_year&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;incremental&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3619&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8531&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14550&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;22173&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32458&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;45695&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62955&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;79301&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;101212&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The total reserve is&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ocl_total %&amp;gt;% round(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 370493&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;These results are similar, though not identical, to the results given in Table 7-6 of the monograph.&lt;/li&gt;
&lt;li&gt;This is because the &lt;em&gt;forecast&lt;/em&gt; column of the monograph contains bootstrapped means rather than the model mean.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The aim of this article has been to demonstrate fitting a GLM to a loss reserve following the example used in the CAS monograph.
We started with the chain ladder equivalent - the cross classified model with an over-dispersed Poisson distribution, then first simplifed it and second, extended it to include some interactions.
We also cover how to create some of the plots discussed in the monograph in R, in particular residual scatter plots and the heat maps.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-information&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session information&lt;/h2&gt;
&lt;p&gt;To assist with reproducibility, here are details of my R session.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.1 (2019-07-05)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18363)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
## [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
## [5] LC_TIME=English_Australia.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] magrittr_1.5      cowplot_1.0.0     viridis_0.5.1     viridisLite_0.3.0
## [5] ggplot2_3.2.1     data.table_1.12.8 here_0.1         
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.3       highr_0.8        compiler_3.6.1   pillar_1.4.2    
##  [5] tools_3.6.1      digest_0.6.23    evaluate_0.14    lifecycle_0.1.0 
##  [9] tibble_2.1.3     gtable_0.3.0     pkgconfig_2.0.3  rlang_0.4.2     
## [13] yaml_2.2.0       blogdown_0.17    xfun_0.11        gridExtra_2.3   
## [17] withr_2.1.2      stringr_1.4.0    dplyr_0.8.3      knitr_1.26      
## [21] rprojroot_1.3-2  grid_3.6.1       tidyselect_0.2.5 glue_1.3.1      
## [25] R6_2.4.1         rmarkdown_2.0    bookdown_0.17    farver_2.0.1    
## [29] purrr_0.3.3      backports_1.1.5  scales_1.1.0     htmltools_0.4.0 
## [33] assertthat_0.2.1 colorspace_1.4-1 labeling_0.3     stringi_1.4.3   
## [37] lazyeval_0.2.2   munsell_0.5.0    crayon_1.3.4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic loss reserving using Generalized Linear Models</title>
      <link>/publication/2016_monograph/</link>
      <pubDate>Wed, 04 May 2016 00:00:00 +0000</pubDate>
      <guid>/publication/2016_monograph/</guid>
      <description>


&lt;p&gt;The purpose of the monograph is to provide access to generalized linear models for loss reserving but initially with strong emphasis on the chain ladder. The chain ladder is formulated in a GLM context, as is the statistical distribution of the loss reserve. This structure is then used to test the need for departure from the chain ladder model and to formulate any required model extensions.&lt;/p&gt;
&lt;p&gt;The chain ladder is by far the most widely used method for loss reserving. The chain ladder algorithm itself is non-stochastic, but Mack (1993) defined a stochastic version of the model and showed how a mean square error of prediction may be associated with any loss reserve obtained from this model.&lt;/p&gt;
&lt;p&gt;There are, however, two families of stochastic model which generate the chain ladder algorithm for the estimation of loss reserve, as discussed in Taylor (2011). They require differing treatments of for the estimation of mean square error of prediction. Both families of model may be formulated as generalized linear models. This is not widely appreciated of the Mack model. The monograph commences with the identification of these two families and their respective GLM formulations.&lt;/p&gt;
&lt;p&gt;GLM formulation naturally invites the use of a bootstrap to estimate prediction error. The bootstrap estimates the entire distribution of loss reserve rather than just the mean square error of prediction obtainable from Mack’s algorithm. The monograph discusses both parametric and semi-parametric forms of the GLM bootstrap.&lt;/p&gt;
&lt;p&gt;Emphasis is placed on the use of statistical software to implement the GLM formulation. This formulation and the associated software provide the diagnostics for testing the validity of the model. This aspect is covered by the existing literature but the monograph reviews this material in view of its importance.&lt;/p&gt;
&lt;p&gt;Practical applications of the chain ladder often depart from the strict model. There are a number of causes but prominent among these are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the need to smooth the age-to-age factor tail;&lt;/li&gt;
&lt;li&gt;the need to give greater weight to more recent data than to older.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two matters are considered within the GLM context. The subject of smoothing leads to a discussion of generalized additive models.&lt;/p&gt;
&lt;p&gt;As regards the second point, the GLM structure is used to test whether or not data are time-homogeneous (as is required by the strict chain ladder model) and, if not, to suggest a procedure for recognising and accommodating time-heterogeneity in the data. This may lead to the common practice of discarding all but the last m diagonals of the claim triangle, but more general approaches are also be considered.&lt;/p&gt;
&lt;p&gt;As time-heterogeneity is not consistent with the chain ladder model, it amounts to model failure, and is recognizable from the diagnostics introduced above. Various forms of model failure are considered and, in each case, a model extension constructed to deal with it.&lt;/p&gt;
&lt;p&gt;Finally, extension to several models that go beyond the scope of generalized linear models is discussed.&lt;/p&gt;
&lt;p&gt;See my &lt;a href=&#34;/post/traditional-style-reserving-using-glms&#34;&gt;blog post&lt;/a&gt; for some R code on how to fit the GLM described in the monograph.&lt;/p&gt;
&lt;!--

---
abstract: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus
  ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed
  ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis
  sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida
  egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id
  dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.
  Vestibulum sit amet erat at nulla eleifend gravida.
authors:
- admin
- Robert Ford
date: &#34;2015-09-01T00:00:00Z&#34;
doi: &#34;&#34;
featured: false
image:
  caption: &#39;Image credit: [**Unsplash**](https://unsplash.com/photos/jdD8gXaTZsc)&#39;
  focal_point: &#34;&#34;
  preview_only: false
projects: []
publication: &#39;*Journal of Source Themes, 1*(1)&#39;
publication_short: &#34;&#34;
publication_types:
- &#34;2&#34;
publishDate: &#34;2017-01-01T00:00:00Z&#34;
slides: example
summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus
  ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.
tags:
- Source Themes
title: An example journal article
url_code: &#34;&#34;
url_dataset: &#34;&#34;
url_pdf: http://arxiv.org/pdf/1512.04133v1
url_poster: &#34;&#34;
url_project: &#34;&#34;
url_slides: &#34;&#34;
url_source: &#34;&#34;
url_video: &#34;&#34;
---

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).


--&gt;
</description>
    </item>
    
    <item>
      <title>Individual claim loss reserving conditioned by case estimates</title>
      <link>/publication/2008_bootstrap/</link>
      <pubDate>Mon, 01 Sep 2008 00:00:00 +0000</pubDate>
      <guid>/publication/2008_bootstrap/</guid>
      <description>


&lt;p&gt;This paper examines various forms of individual claim model for the purpose of loss reserving, with emphasis on the prediction error associated with the reserve. Each form of model is calibrated against a single extensive data set, and then used to generate a forecast of loss reserve and an estimate of its prediction error.&lt;/p&gt;
&lt;p&gt;The basis of this is a model of the “paids” type, in which the sizes of strictly positive individual finalised claims are expressed in terms of a small number of covariates, most of which are in some way functions of time. Such models can be found in the literature.&lt;/p&gt;
&lt;p&gt;The purpose of the current paper is to extend these to individual claim “incurreds” models. These are constructed by the inclusion of case estimates in the model’s conditioning information. This form of model is found to involve rather more complexity in its structure.&lt;/p&gt;
&lt;p&gt;For the particular data set considered here, this did not yield any direct improvement in prediction error. However, a blending of the paids and incurreds models did so.&lt;/p&gt;
&lt;!--

doi: &#34;&#34;


--&gt;
</description>
    </item>
    
    <item>
      <title>Loss reserving with GLMs: a case study</title>
      <link>/publication/2004_cas_glms/</link>
      <pubDate>Sun, 16 May 2004 00:00:00 +0000</pubDate>
      <guid>/publication/2004_cas_glms/</guid>
      <description>


&lt;p&gt;This paper provides a case study in the application of generalised linear models (GLMs) to loss reserving. The study is motivated by approaching the exercise from the viewpoint of an actuary with a predisposition to the application of the chain ladder (CL). The data set under study is seen to violate the conditions for application of the CL in a number of ways. The difficulties of adjusting the CL to allow for these features are noted (Section 3).&lt;/p&gt;
&lt;p&gt;Regression, and particularly GLM regression, is introduced as a structured and rigorous form of dat analysis. This enables the investigation and modelling of a number of complex features of the data responsible for the violation of the CL conditions. These include superimposed inflation and changes in the rules governing the payment of claims (Sections 4 to 7). The development of the analysis is traced in some detail, as is the production of a range of diagnostics and tests used to compare candidate models and validate the final one.&lt;/p&gt;
&lt;p&gt;The benefits of this approach are dicussed in Section 8&#34;&lt;/p&gt;
&lt;!--

doi: &#34;&#34;


--&gt;
</description>
    </item>
    
  </channel>
</rss>
