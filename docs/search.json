[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Grainne McGuire",
    "section": "",
    "text": "I’m a statistician and actuary, with a long-standing interest in using statistics and machine learning in various areas including insurance, government and corporate work. I’m also concerned about the appropriate and fair use of these tools.\nMy original background was in statistical molecular genetics where I used statistical models to detect recombination in bacteria and viruses. As part of that I had to write C and C++ programmes to implement my methods which led me to develop a lifelong interest in the use of coding to implement novel statistical techniques."
  },
  {
    "objectID": "about.html#about",
    "href": "about.html#about",
    "title": "Grainne McGuire",
    "section": "",
    "text": "I’m a statistician and actuary, with a long-standing interest in using statistics and machine learning in various areas including insurance, government and corporate work. I’m also concerned about the appropriate and fair use of these tools.\nMy original background was in statistical molecular genetics where I used statistical models to detect recombination in bacteria and viruses. As part of that I had to write C and C++ programmes to implement my methods which led me to develop a lifelong interest in the use of coding to implement novel statistical techniques."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Odds and ends",
    "section": "",
    "text": "to my website. I use this to occasionally share code snippets and tutorial examples.\nCheck out the list of posts to see what’s available.\n\n\n\n\n\n\nLatest post\n\n\n\nI’ve shared a tutorial example on how to use the Lasso, Bayesian Model Averaging and bootstrapping to to estimate forecast errors for loss reserving. This post was publicly shared in September 2023, prior to that it was online, but hidden, hence the earlier publication date.\n\n\n\n\n\n\n\n\nOther code snippets\n\n\n\nI’m part of the IFoA Machine Learning in Reserving Working Party. On our blog we share a lot of code examples in both R and Python, so check that out if you’d like to see other useful material.\n\n\nLast updated: September-2023"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Odds and ends",
    "section": "",
    "text": "to my website. I use this to occasionally share code snippets and tutorial examples.\nCheck out the list of posts to see what’s available.\n\n\n\n\n\n\nLatest post\n\n\n\nI’ve shared a tutorial example on how to use the Lasso, Bayesian Model Averaging and bootstrapping to to estimate forecast errors for loss reserving. This post was publicly shared in September 2023, prior to that it was online, but hidden, hence the earlier publication date.\n\n\n\n\n\n\n\n\nOther code snippets\n\n\n\nI’m part of the IFoA Machine Learning in Reserving Working Party. On our blog we share a lot of code examples in both R and Python, so check that out if you’d like to see other useful material.\n\n\nLast updated: September-2023"
  },
  {
    "objectID": "post.html",
    "href": "post.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nModel error via regularised regression - CAS monograph data\n\n\n\n\n\n\n\nMachine Learning\n\n\nR\n\n\nLasso\n\n\nModel Error\n\n\nBootstrap\n\n\n\n\nEstimate model error and other error via a Lasso bootstrap\n\n\n\n\n\n\nMay 4, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTraditional-style reserving using GLMs\n\n\n\n\n\n\n\nGLM\n\n\nR\n\n\nReserving\n\n\n\n\nThis post provides a worked example in R of fitting a GLM to some non-life claims reserving data\n\n\n\n\n\n\nNov 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSelf-assembling claim reserving models\n\n\n\n\n\n\n\nMachine Learning\n\n\nR\n\n\nLasso\n\n\n\n\nThis article works through the application of the LAsso model to a reserving problem as discussed in McGuire et al (2021)\n\n\n\n\n\n\nMay 31, 2019\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html",
    "title": "Self-assembling claim reserving models",
    "section": "",
    "text": "The article below is my original article working through a tutorial example of the R code from our Variance paper Self-Assembling Insurance Claim Models Using Regularized Regression and Machine Learning.\nSince then some or all of the article has been published in other forms with slight variations to the code and content:\n\nPresent article - uses base R\nMLRWP blog - some introductory material, code makes use of the data.table package with some nicer graphical output as well\nML modelling on triangles - another MLRWP article where the Lasso was one of a number of methods used. In this article I implemented it using the mlr3 ecosystem\nA python approach this article is based off the one above, but this time using python, so contains a discussion of how to implement this Lasso approach in that language"
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#april-2023-update",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#april-2023-update",
    "title": "Self-assembling claim reserving models",
    "section": "",
    "text": "The article below is my original article working through a tutorial example of the R code from our Variance paper Self-Assembling Insurance Claim Models Using Regularized Regression and Machine Learning.\nSince then some or all of the article has been published in other forms with slight variations to the code and content:\n\nPresent article - uses base R\nMLRWP blog - some introductory material, code makes use of the data.table package with some nicer graphical output as well\nML modelling on triangles - another MLRWP article where the Lasso was one of a number of methods used. In this article I implemented it using the mlr3 ecosystem\nA python approach this article is based off the one above, but this time using python, so contains a discussion of how to implement this Lasso approach in that language"
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#introduction",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#introduction",
    "title": "Self-assembling claim reserving models",
    "section": "Introduction",
    "text": "Introduction\nRecently, Greg Taylor, Hugh Miller and myself completed some work to develop an approach for fitting a claims reserving model using regularised regression, the LASSO in particular. This was published in the Variance Journal in 2021.\nThe motivation behind this work is to develop an automatic method to construct a general insurance claims reserving model for data sets with complex features where simple approaches such as the chain ladder fail. In the past we have advocated the use of GLM models for such data sets, but the construction of a GLM is a time-consuming process, even for a skilled analyst. Our aim was to develop a procedure that produced a model similar to a GLM, but using machine learning techniques. This approach has performed well - as may be seen from the charts towards the end of this example, which show that the fitted curves can track the underlying specification quite well, even in the presence of significant noise, or difficult to detect interactions.\nThe paper fills in the details around the approach, so they will not be repeated here. Instead, this will focus on illustrating the use of the LASSO in claims reserving by fitting the model to one of the synthetic data examples discussed in the paper. I will be working through a fully worked example with all R code available. To reduce dependencies on external libraries, I have carried out the work in base R as much as possible.\nIn our paper we investigate the use of the LASSO using four synthetic (i.e. simulated) data sets as well as a real data set. This worked example will use the third simulated data set. The specifications for this data set are given in Section 4.2.1 of the paper. The main points to note are that this data set :\n\nis a 40x40 triangle, with\naccident and development period effects\ncalendar period effects (i.e. superimposed inflation)\nan step-interaction between accident and development period for accident periods greater than 17 and development periods greater than 20 (note this affects only 10 cells of the triangle)\n\nYou can download a quarto file of this notebook here if you want to try to run the code yourself."
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#r-code",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#r-code",
    "title": "Self-assembling claim reserving models",
    "section": "R code",
    "text": "R code\n\nSetup\nFirst we must open R and load any libraries required. As noted above, I will use base R as much as possible so there are only two additional libraries required:\n\nglmnet - this is the library we used to implement the LASSO model. References are in our paper.\nggplot2 - for producing graphs.\n\n\nlibrary(glmnet)\n## Loading required package: Matrix\n## Loaded glmnet 4.1-7\nlibrary(ggplot2)\n\noptions(\"scipen\"=99)\n\n\n\nGenerating the synthetic data set\nFirst we need a data set. The code below, using a seed of 130 produces the data set used in the paper.\nBefore we generate the data, we need to create a small utility function which will be widely used - it takes a vector var and produces a spline piece between start and stop - flat (and 0) up to start, thereafter increasing to stop and then levelling out at this point. This is used both in the data generation and in the generation of basis functions for the LASSO.\n\nLinearSpline &lt;- function(var, start, stop){\n    pmin(stop - start, pmax(0, var - start))\n}\n\nThe code below generates the data set as specified in our paper. If you want to use our data set, use a seed of 130. Otherwise, use different seeds to produce different data sets.\n\n# initialise the seed for reproducibilty\nset.seed(130)\nnumperiods &lt;- 40\n\n#periods\nkk &lt;- rep(1:numperiods, each = numperiods) #AQ\njj &lt;- rep(1:numperiods, times= numperiods) #DQ\ntt &lt;- kk+jj-1 # PQ\n\n\n# make a function of the SI effect to make it easier to read \ngammafunc &lt;- function(t){\n    gg &lt;- \n        ifelse( t&lt;=12, gg &lt;- 0.0075*LinearSpline(t,1,12),\n                ifelse(t&lt;=24,  gg &lt;- 0.0075*LinearSpline(12,1,12) + 0.001* (t-12)*(t-11)/2,\n                       ifelse(t&lt;=32, gg &lt;- 0.0075*LinearSpline(12,1,12) + 0.001* (24-12)*(24-11)/2,\n                           ifelse(t&lt;=40, gg &lt;- 0.0075*LinearSpline(12,1,12) + 0.001* (24-12)*(24-11)/2 + 0.002*(t-32)*(t-31)/2,\n                               0.0075*LinearSpline(12,1,12) + 0.001* (24-12)*(24-11)/2 + 0.002*(40-32)*(40-31)/2\n                           ))))\n    1*gg  #can scale up shape here if desired\n}\n\nalpha &lt;- log(100000)+0.1*LinearSpline(kk,1,15)+0.2*LinearSpline(kk,15,20) - 0.05*LinearSpline(kk,30,40) \nbeta  &lt;- (16/3 - 1)*log(jj)- (1/3)*jj  # a is 16/3, b is 1/3 \ngamma &lt;- gammafunc(tt)\nmu &lt;- exp( alpha + beta + gamma + 0.3*beta*ifelse(kk&gt;16 & jj&gt;20,1,0))  # need to check\n\nvarbase &lt;- (0.3 * mu[  kk==1 & jj ==16] )^2 # can scale variance up and down here\nCC  &lt;-  varbase / mu[  kk==1 & jj ==16]\n\nvars   &lt;- CC*mu\ntausq  &lt;- log (vars / (mu^2) + 1)\n\nY &lt;- exp( rnorm( numperiods^2, mean = log(mu)-0.5*tausq , sd = sqrt(tausq)  ) )\n\ntrain_ind&lt;-(tt&lt;=numperiods)  \n\nsynthetic_data&lt;-data.frame(Y, kk, jj, tt, mu, train_ind )\ncolnames(synthetic_data)&lt;-c(\"Y\", \"acc\", \"dev\", \"cal\", \"mu\", \"train_ind\")\n\n\n# clean-up\nrm(Y, kk, jj, tt, mu, train_ind)\n\n Let’s have a look at the data\n\nhead(synthetic_data)\n\n           Y acc dev cal          mu train_ind\n1   242671.2   1   1   1    71653.13      TRUE\n2   164001.3   1   2   2  1042775.62      TRUE\n3  3224477.8   1   3   3  4362599.77      TRUE\n4  3682530.8   1   4   4 10955670.09      TRUE\n5 10149368.6   1   5   5 20800545.12      TRUE\n6 28578274.7   1   6   6 33089166.75      TRUE\n\ntail(synthetic_data)\n\n             Y acc dev cal        mu train_ind\n1595 125261750  40  35  74 109039367     FALSE\n1596  62657370  40  36  75  82853302     FALSE\n1597  63467681  40  37  76  62682720     FALSE\n1598  26041979  40  38  77  47227843     FALSE\n1599  33947274  40  39  78  35444881     FALSE\n1600  37258687  40  40  79  26503298     FALSE\n\n\nThe points to note about this data frame are:\n\nY is the comumn containing the data - assumed to be incremental claims payments here\nacc, dev and cal are the columns with the accident, development and calendar period labels. Note that development period is numbered from 1.\nmu contains the values for \\(\\mu\\), the true underlying mean value according to the model specifications\ntrain_ind is a TRUE/FALSE vector. It is TRUE when the observation is in the past, a.k.a. the training data set and FALSE for future observations (unlike real data, we have the future available for a simulated data set)\n\n\n\n\nSpecifying the LASSO model\nThe LASSO model requires data (which we have), basis functions or regressors and model settings for the LASSO procedure. Unlike many regression problems, we actually only have 3 fundamental regressors - accident, development and calendar periods. A key part of our paper was how to expand these into a flexible set of basis functions, capable of capturing a variety of shapes in the model experience.\nIn a nutshell, the approach in our paper sets out:\n\nthe use of ramp and interactions of indicator (or heaviside) functions to capture a range of experience\nscaling factors for each of these.\n\nSince our process is intended to be automatic, we included all functions of accident, development and calendar periods into our synthetic data models, even though that introduces correlations between variables, and examined performance on that basis. For real problems (as in the real data example in the paper) we would recommend more discernment in the selection of which of the effects to include.\n\n\nScaling\nFor now, we are working to replicate the model for synthetic data set 3 so we include all possible functions (and indeed, this data set has accident, development and calendar period effects as well as an interaction). The first step is to calculate the scaling factors for each function derived from each of the three fundamental regressors. As per the paper we use \\(\\rho\\) scaling which is calculated as \\(\\sum{\\frac{(x-\\bar{x})^2}{n}}\\) where \\(\\bar{x}\\) is the mean of the regressor \\(x\\) and \\(n\\) is the number of elements in the regressor.\nFor this synthetic data set, it is important to remember that in the real world, the future data will not be available. So the fundamental vectors are those containing past (or training) data only.\nWe also need to calculate the scaling for each of the three regressors, so for coding efficiency and to reduce the risk of bugs, we first write a little function to do the calculations.\nNote that this scaling is a crucial component to the successful implementation of the reserving LASSO. The paper has more details, but basically the size of the parameters has a significant influence on whether they are included in a regularised regression, so if basis functions are on different scales, then this will influence their inclusion in the model.\n\n# function for ease\nGetScaling &lt;- function(vec) {\n  fn &lt;- length(vec)\n  fm &lt;- mean(vec)\n  fc &lt;- vec - fm\n  rho_factor &lt;- ((sum(fc^2))/fn)^0.5\n}\n\nNow we apply this function to each of the three fundamental regressors (limited to the training or past data) and store the results in a list.\n\nsynthetic_data_train&lt;-subset(synthetic_data, train_ind==TRUE)\n\nrho_factor_list &lt;- vector(mode=\"list\", length=3)\nnames(rho_factor_list) &lt;- c(\"acc\", \"dev\", \"cal\")\n\nfor (v in c(\"acc\", \"dev\", \"cal\")){\n  rho_factor_list[[v]] &lt;- GetScaling(synthetic_data_train[[v]])\n}\n\n\nprint(rho_factor_list)\n\n$acc\n[1] 9.539392\n\n$dev\n[1] 9.539392\n\n$cal\n[1] 9.539392\n\n\nThe factors are all equal in this case. In hindsight this makes sense - we have the complete 40 x 40 past triangle, and all regressors are numbered from 1, so all three regressors are permutations of the same numbers.\n\n\n\nBasis functions\nOur recommended set of basis functions include:\n\nramp functions for main effects:\n\n\\(R_j(i) = \\max(j-i, 0)\\) for \\(j=\\) accident, development and calendar periods and \\(i=1, 2, ..., 39\\)\n\ninteractions of the heaviside indicator functions:\n\n\\(H_j(i) = I(j&gt;=i)\\), i.e. all combinations of \\(H_{acc}(i) * H_{dev}(k)\\), \\(H_{acc}(i) * H_{cal}(k)\\), \\(H_{dev}(i) * H_{cal}(k)\\).\n\n\n\n\nMain effects - ramp functions\nTo calculate the ramps we first write a function to do this, since we need to repeat this three times. glmnet expects a matrix of values for the basis functions, so we create a matrix rather than a data.frame. Furthermore, to ensure speed, we preallocate the space to store all the basis functions before running a loop to produce all the ramp functions (many people are scared of loops in R finding them slow, but often this is because they do not preallocate memory beforehand to store the results of the loop)\n\nGetRamps &lt;- function(vec, vecname, np, scaling){\n  \n  # vec = fundamental regressor\n  # vecname = name of regressor\n  # np = number of periods\n  # scaling = scaling factor to use\n  \n  # pre-allocate the matrix to hold the results for speed/efficiency\n  n &lt;- length(vec)\n  nramps &lt;- (np-1)\n  \n  mat &lt;- matrix(data=NA, nrow=n, ncol=nramps)\n  cnames &lt;- vector(mode=\"character\", length=nramps)\n  \n\n  col_indx &lt;- 0\n\n  for (i in 1:(np-1)){\n    col_indx &lt;- col_indx + 1\n\n    mat[, col_indx] &lt;- LinearSpline(vec, i, 999) / scaling\n    cnames[col_indx] &lt;- paste0(\"L_\", i, \"_999_\", vecname)\n  }\n  \n  colnames(mat) &lt;- cnames\n  \n  return(mat)\n}\n\nNow let’s run the function 3 times to get each set of ramp functions and combine them at the end. Note that we produce ramps for the entire data set, past and future. This leads to a 1600 x 117 (39*3) matrix.\n\nmain_effects_acc &lt;- GetRamps(vec = synthetic_data[[\"acc\"]], vecname = \"acc\", \n                             np = numperiods, scaling = rho_factor_list[[\"acc\"]])\nmain_effects_dev &lt;- GetRamps(vec = synthetic_data[[\"dev\"]], vecname = \"dev\", \n                             np = numperiods, scaling = rho_factor_list[[\"dev\"]])\nmain_effects_cal &lt;- GetRamps(vec = synthetic_data[[\"cal\"]], vecname = \"cal\", \n                             np = numperiods, scaling = rho_factor_list[[\"cal\"]])\n    \nmain_effects &lt;- cbind(main_effects_acc, main_effects_dev, main_effects_cal)\n\nprint(dim(main_effects))\n\n[1] 1600  117\n\n\n\n\n\n\nInteraction effects - heaviside functions\nWe follow a similar approach to the above - write a function since we need to call it 3 times. It is even more important to preallocate memory here before looping to create interactions because of the number of these. Without this, the loop would need to copy an ever-growing matrix each time, thereby significantly slowing down runtimes. Our approach of slotting values into reserved space is far more efficient.\nHere’s the function:\n\nGetInts &lt;- function(vec1, vec2, vecname1, vecname2, np, scaling1, scaling2) {\n  \n  # pre-allocate the matrix to hold the results for speed/efficiency\n  n &lt;- length(vec1)\n  nints &lt;- (np-1)*(np-1)\n  \n  mat &lt;- matrix(data=NA_real_, nrow=n, ncol=nints)\n  cnames &lt;- vector(mode=\"character\", length=nints)\n  \n\n  col_indx &lt;- 0\n\n  for (i in 2:np){\n    \n    ivec &lt;- LinearSpline(vec1, i-1, i) / scaling1\n    iname &lt;- paste0(\"I_\", vecname1, \"_ge_\", i)\n    \n    if (length(ivec[is.na(ivec)]&gt;0)) print(paste(\"NAs in ivec for\", i))\n    \n    for (j in 2:np){\n      col_indx &lt;- col_indx + 1  \n      mat[, col_indx] &lt;- ivec * LinearSpline(vec2, j-1, j) / scaling2\n      cnames[col_indx] &lt;- paste0(iname, \"*I_\", vecname2, \"_ge_\", j)\n      \n      jvec &lt;- LinearSpline(vec2, j-1, j) / scaling2\n      if (length(jvec[is.na(jvec)]&gt;0)) print(paste(\"NAs in jvec for\", j))\n\n    }\n  }\n  \n  colnames(mat) &lt;- cnames\n  \n  return(mat)\n\n  \n}\n\nNow we call it and check the dimensions - 1600 x 4563(! 3 * 39 * 39).:\n\nint_effects &lt;- cbind(\n  GetInts(vec1=synthetic_data[[\"acc\"]], vecname1=\"acc\", scaling1=rho_factor_list[[\"acc\"]], np=numperiods, \n                       vec2=synthetic_data[[\"dev\"]], vecname2=\"dev\", scaling2=rho_factor_list[[\"dev\"]]),\n\n    GetInts(vec1=synthetic_data[[\"dev\"]], vecname1=\"dev\", scaling1=rho_factor_list[[\"dev\"]], np=numperiods, \n                       vec2=synthetic_data[[\"cal\"]], vecname2=\"cal\", scaling2=rho_factor_list[[\"cal\"]]),\n  \n    GetInts(vec1=synthetic_data[[\"acc\"]], vecname1=\"acc\", scaling1=rho_factor_list[[\"acc\"]], np=numperiods, \n                       vec2=synthetic_data[[\"cal\"]], vecname2=\"cal\", scaling2=rho_factor_list[[\"cal\"]])\n\n)\n\n\nprint(dim(int_effects))\n\n[1] 1600 4563\n\n\nFinally combine the main and interactions effects into a single matrix - varset. Also save a vector containing the training (past) data indicator and get the number of main and interaction effects.\n\nvarset &lt;- cbind(main_effects, int_effects)\n\ntrain_ind &lt;- synthetic_data[[\"train_ind\"]]\n\nnum_main_effects &lt;- ncol(main_effects)\nnum_interactions &lt;- ncol(int_effects)\n\n\n\n\nLASSO setup\nThe glmnet package has two functions: glmnet and cv.glmnet. glmnet fits a regularised regression model while cv.glmnet fits using cross validation. We make use of both functions, first glmnet to get a vector of LASSO penalties (referred to as \\(\\lambda\\)), then cv.glmnet using the \\(\\lambda\\)s from glmnet in the cross validation process.\nIn addition to the data and basis functions, glmnet and cv.glmnet have a number of tuning parameters. These include:\n\nA set of values for \\(\\lambda\\), the regularision penalty. We use the \\(\\lambda\\) vector estimated by glmnet and then extend it further to ensure that we have a comprehensive range of \\(\\lambda\\) values for the cross-validation exercise.\npenalty factors: this is a basis function specific penalty factor so provides the functionality to have different penalties for the different basis functions, i.e. if \\(pf\\) is the vector of penalty functions, then \\(\\lambda {pf}\\) is the set of penalty factors used. Here we use the default of the same scaling for all functions (factors of 1 throughout), but we set up a penalty factor vector below in case you would like to experiment with it - e.g. to make interactions less or more likely to be used you could increase/decrease the penalty for interactions.\npmax - the maximum number of variables ever to be non-zero in a model\ndfmax - maximum number of variables in a model\nfamily - the response type to use. Of the options offered by the glmnet package, the Poisson is the best selection for a claims reserving model.\n\nThe settings we used for the latter 3 are below.\n\npenalty_factor &lt;- c( rep(1,num_main_effects), rep(1, num_interactions))\n\nmy_pmax &lt;- numperiods^2   # max number of variables ever to be nonzero\nmy_dfmax &lt;- numperiods*10  #max number of vars in the model\n\nTo get the vector \\(\\lambda\\) values to use in the cross validation, run glmnet as below. Note that alpha=1 makes it fit a LASSO. We have also increased the maximum number of iterations to 200000 since convergence can be slow in this example. The code takes about 13-15 sec on my computer.\nNote we set the standardize argument to false - this is because we use our own standardisation for the basis functions.\n\ntime1 &lt;- Sys.time()\n\npre_fit &lt;- glmnet(x = varset[train_ind,], \n                  y = synthetic_data$Y[train_ind], \n                  family = \"poisson\", \n                  nlambda = 200, \n                  thresh = 1e-08, \n                  lambda.min.ratio = 0, \n                  dfmax = my_dfmax, \n                  pmax = my_pmax, \n                  alpha = 1, \n                  standardize = FALSE, \n                  penalty.factor = penalty_factor, \n                  maxit = 200000)\n\nprint(paste(\"time taken: \", Sys.time() - time1))\n\n[1] \"time taken:  5.9633150100708\"\n\n\nThe \\(\\lambda\\) vector that we actually used in the cross validation implementation of the LASSO is an extended version of the one automatically generated by glmnet. This is to ensure that we do find the minimum CV error point as sometimes it may be beyond the smallest value for \\(\\lambda\\) produced by glmnet above.\n\nlambdavec &lt;- c(pre_fit$lambda, min(pre_fit$lambda)*(0.85^(1:50)))  # lengthen lambda vector\n\n\n\n\nFitting the LASSO model\nWe now do the actual fitting using 8-fold cross validation (Rob Tibshirani, who wrote the original statistical paper on LASSO, recommends between 5 and 10 folds). We use lambdavec, rather than letting cv.glmnet estimate its own version. Otherwise the settings are the same.\n\n#fit now using CV\ntime1 &lt;- Sys.time()\n\ncv_fit &lt;- cv.glmnet(x = varset[train_ind,], \n                  y = synthetic_data$Y[train_ind], \n                  family = \"poisson\", \n                  lambda = lambdavec, \n                  nfolds = 8,\n                  thresh = 1e-08, \n                  lambda.min.ratio = 0, \n                  dfmax = my_dfmax, \n                  pmax = my_pmax, \n                  alpha = 1, \n                  standardize = FALSE, \n                  penalty.factor = penalty_factor, \n                  maxit = 200000)\n\nWarning: from glmnet C++ code (error code -10194); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 194th lambda value; solutions\nfor larger lambdas returned\n\n\nWarning: from glmnet C++ code (error code -10196); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 196th lambda value; solutions\nfor larger lambdas returned\n\nWarning: from glmnet C++ code (error code -10196); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 196th lambda value; solutions\nfor larger lambdas returned\n\nWarning: from glmnet C++ code (error code -10196); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 196th lambda value; solutions\nfor larger lambdas returned\n\n\nWarning: from glmnet C++ code (error code -10195); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 195th lambda value; solutions\nfor larger lambdas returned\n\nWarning: from glmnet C++ code (error code -10195); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 195th lambda value; solutions\nfor larger lambdas returned\n\n\nWarning: from glmnet C++ code (error code -10196); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 196th lambda value; solutions\nfor larger lambdas returned\n\nWarning: from glmnet C++ code (error code -10196); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 196th lambda value; solutions\nfor larger lambdas returned\n\n\nWarning: from glmnet C++ code (error code -10195); Number of nonzero\ncoefficients along the path exceeds pmax=1600 at 195th lambda value; solutions\nfor larger lambdas returned\n\nprint(paste(\"time taken for cross validation fit: \", Sys.time() - time1))\n\n[1] \"time taken for cross validation fit:  1.3287925362587\"\n\n\n Eek! C++ error (or Fortran if you’re using an older version of glmnet)\nYes, there are C++ errors. However, if you read the errors, you see that they result from our settings of the pmax variable. Basically models for the 194th and higher values (and since the \\(\\lambda\\) values monotonically decrease this means smaller values) in the lambdavec do not return solutions that meet the constraints on pmax.\nTherefore the errors are not an issue as long as the cross validation process has found a minimum value within the range of \\(\\lambda\\) values it does consider. cv.glmnet objects have a plot method associated with them which plots the CV fit, so I’ll use it here to see if a minimum value was identified:\n\nplot(cv_fit)\n\n\n\n\nThe dashed lines represent the minimum CV model (smaller \\(\\lambda\\)) and one a standard deviation away. These are selections commonly used by modellers. So while we only got models for 194 of the original 250 \\(\\lambda\\) values input in lambdavec, these models do include a model which produces the minimum CV error (this is actually that the 148th value in lambdavec).\n Given this is simulated data, we can also look at test error - the graph below shows training, test and CV error.\n\n#training error\npredicted_train &lt;- exp(predict(cv_fit, newx = varset[train_ind,], s = cv_fit$lambda))\nerror_train &lt;- colMeans(((synthetic_data$Y[train_ind] - predicted_train)^2) / predicted_train )\n\n#test error - note \npredicted_test &lt;- exp(predict(cv_fit, newx = varset[!train_ind,], s = cv_fit$lambda))\nerror_test &lt;- colMeans(((synthetic_data$Y[!train_ind] - predicted_test)^2) / predicted_test )\n\n\n# number of parameters in models (df field)\n# since not all lambdas returned values, use length of cv.glmnet object to get the right value\nuse_df &lt;- cv_fit$glmnet.fit$df[1:length(cv_fit$lambda)]\n\n#make a stacked data set suitable for ggplot [ i.e. tidy format]\ndferrorg &lt;- data.frame( \n  rep(1:length(use_df), times=3), \n  rep(use_df, times=3), \n  c(error_train, error_test, cv_fit$cvm)/1000,\n    c( rep(\"Training error\", times=length(use_df)), rep(\"Test error\", times=length(use_df)), rep(\"CV error\", times=length(use_df)) )\n)\n\ncolnames(dferrorg)&lt;-c(\"model_number\", \"num_params\", \"Error\", \"labels\")  \n\n\ng &lt;- ggplot(data=dferrorg, aes(x=model_number, y=Error, colour=labels))+\n    geom_line(size=1.5, aes(linetype=labels, colour=labels), alpha=0.8)+\n    theme_classic()+\n    theme(legend.position=\"bottom\")+\n    labs(x=\"Model number\", y=\"Error measure (thousands)\")+\n    scale_color_manual(name=\"\", values=c(\"grey40\", \"steelblue3\", \"dodgerblue4\"))+\n    scale_linetype_manual(name=\"\", values=c(\"solid\", \"dashed\", \"dotdash\"))+\n    scale_y_log10(labels=scales::comma)+\n    NULL\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nprint(g)\n\n\n\n\nHappily, low values of the test error align with low CV error values - which is what we would expect to see."
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#analysing-the-model",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#analysing-the-model",
    "title": "Self-assembling claim reserving models",
    "section": "Analysing the model",
    "text": "Analysing the model\nWe have used the model corresponding to the minimum CV error in the paper (lambda.min in the cv.glmnet results object, cv_fit. First let’s look at the coefficients in this model.\n\n#all coefficients\ncoefs_min &lt;- predict(cv_fit, type = \"coefficients\", s = cv_fit$lambda.min)\ncoefnames &lt;- c(\"Intercept\", colnames(varset))\n\n#indicators for non-zero ones\nind_nz_min&lt;-which(!(coefs_min == 0))\n\n#non-zero coefficient\nnzcoefs_min&lt;-cbind(coefs_min[ind_nz_min,])\nrownames(nzcoefs_min)&lt;-coefnames[ind_nz_min]\ncolnames(nzcoefs_min)&lt;-c(\"coefficients [min CV model]\")\n\n\n\nprint(paste(\"Number of non-zero coefficients in min CV model:\", length(nzcoefs_min)))\n\n[1] \"Number of non-zero coefficients in min CV model: 85\"\n\nprint(nzcoefs_min)\n\n                        coefficients [min CV model]\nIntercept                            12.90849895417\nL_3_999_acc                          -0.17095450637\nL_6_999_acc                           0.20215489391\nL_8_999_acc                          -0.13683790320\nL_9_999_acc                          -0.00672219179\nL_10_999_acc                         -0.00726869288\nL_11_999_acc                         -0.02324637560\nL_12_999_acc                          0.35610588121\nL_14_999_acc                         -0.18739289324\nL_15_999_acc                          0.40181872536\nL_16_999_acc                          0.87558147351\nL_18_999_acc                         -0.51019658081\nL_19_999_acc                         -0.16864837024\nL_20_999_acc                         -1.43901710510\nL_21_999_acc                          0.00953494458\nL_23_999_acc                         -0.79245485689\nL_24_999_acc                          1.24495947878\nL_25_999_acc                         -0.93508762388\nL_26_999_acc                          0.33765209395\nL_30_999_acc                         -0.70157532215\nL_33_999_acc                          0.50643664885\nL_1_999_dev                           8.99462964815\nL_2_999_dev                          -0.01963810231\nL_3_999_dev                          -0.07441073323\nL_4_999_dev                          -3.07653125091\nL_5_999_dev                          -2.80431595417\nL_6_999_dev                          -0.68784568387\nL_7_999_dev                          -0.75804244038\nL_8_999_dev                          -0.98088685136\nL_9_999_dev                          -0.22339931944\nL_10_999_dev                         -0.29737981962\nL_11_999_dev                         -0.65592214772\nL_12_999_dev                         -0.35450910869\nL_13_999_dev                         -0.14473152235\nL_14_999_dev                          0.04054774684\nL_15_999_dev                         -0.77588437653\nL_17_999_dev                         -0.03182416050\nL_19_999_dev                          0.67859925448\nL_21_999_dev                         -1.60282885957\nL_22_999_dev                         -0.36525224424\nL_24_999_dev                          1.09988156299\nL_26_999_dev                         -1.09424407364\nL_27_999_dev                         -0.16350776769\nL_29_999_dev                          0.88266161355\nL_35_999_dev                          1.18335659429\nL_36_999_dev                          3.25213216711\nL_1_999_cal                           1.18058085440\nL_8_999_cal                          -0.00180679927\nL_10_999_cal                         -0.04581221350\nL_11_999_cal                         -0.00001361552\nL_13_999_cal                         -0.59595307177\nL_15_999_cal                          0.35077255812\nL_16_999_cal                          0.23459205760\nL_17_999_cal                          0.04789305662\nL_20_999_cal                          0.01820235961\nL_21_999_cal                          0.00556136996\nL_22_999_cal                         -0.05372168891\nL_24_999_cal                         -0.39892379337\nL_26_999_cal                          0.12054004117\nL_28_999_cal                          0.16486697229\nL_29_999_cal                          0.18948697651\nL_31_999_cal                          0.13696526866\nL_32_999_cal                         -0.83932209806\nL_33_999_cal                          0.45155054841\nL_34_999_cal                          0.03672726734\nL_35_999_cal                         -0.23243271370\nL_36_999_cal                          0.90085223804\nL_37_999_cal                         -0.54525546512\nL_38_999_cal                          0.50161027719\nL_39_999_cal                         -0.74904518519\nI_acc_ge_17*I_dev_ge_19               5.51496375492\nI_acc_ge_17*I_dev_ge_20               0.57649450728\nI_acc_ge_17*I_dev_ge_21             137.29149923902\nI_acc_ge_18*I_dev_ge_21               6.45465886915\nI_acc_ge_20*I_dev_ge_17              -1.11190506997\nI_acc_ge_21*I_dev_ge_9                0.20809435323\nI_dev_ge_10*I_cal_ge_31              -2.32990877614\nI_dev_ge_12*I_cal_ge_26              -0.80542334565\nI_dev_ge_13*I_cal_ge_37               1.16374401723\nI_dev_ge_14*I_cal_ge_26              -0.44214160981\nI_dev_ge_22*I_cal_ge_39               1.78463874002\nI_acc_ge_20*I_cal_ge_36              -0.18540638362\nI_acc_ge_20*I_cal_ge_37              -4.85927414746\nI_acc_ge_20*I_cal_ge_38              -2.86273840469\nI_acc_ge_21*I_cal_ge_31               0.29625590769\n\n\nNote the interactions at the end. Are these detecting the interaction that we know is in this simulated data set? We will find out below.\n\nIt is also useful to look at actual and fitted plots for the different predictors. The paper shows a number of these.\nTo produce these plots, we first add the column of fitted values to the data.frame holding the data using the predict method for a cv.glmnet object. Our selected model is that corresponding to the minimum CV error, which is corresponds to the \\(\\lambda\\) stored by the cv_fit$lambda_min component of the cv.glmnet object.\n\nsynthetic_data$fitted_lasso&lt;- as.vector(exp(predict(cv_fit, newx = varset, s = cv_fit$lambda.min)) )\n\nThe function below produces the tracking graphs shown in the paper - plot values for all levels of one fundamental predictor holding a second predictor at a fixed value. To help with looking at the data, it also shades the past part of the data in grey.\nSince ggplot2 is a tidyverse package, it is easiest to put our data into tidy format (essentially stacked/long output) prior to using ggplot.\n\nGraphModelVals&lt;-function(data, primary_predictor, secondary_predictor, secondary_predictor_val, fitted_name, predictor_label){\n    \n    #extract data we want to use\n    use_data &lt;- data[data[[secondary_predictor]] == secondary_predictor_val,]\n\n    \n    # turn into tidy layout - note that we have simulated data, underlying mean, fitted data all to stack.\n    data_tidy &lt;- data.frame( \n      rep(use_data[[primary_predictor]], times=3),\n      c(use_data[[\"Y\"]], use_data[[\"mu\"]], use_data[[fitted_name]]),\n      c(rep(\"Simulated\", times=nrow(use_data)), rep(\"Underlying\", times=nrow(use_data)), rep(\"Lasso\", times=nrow(use_data))) \n      )\n    colnames(data_tidy) &lt;- c(\"predictor\", \"values\", \"data_labels\")\n    \n    data_tidy$values &lt;- log(data_tidy$values)\n\n    \n    # extract values for past rectangle\n    xmin1 &lt;- min(use_data[[primary_predictor]][use_data$train_ind==TRUE])\n    xmax1 &lt;- max(use_data[[primary_predictor]][use_data$train_ind==TRUE])\n    \n    ymin1 &lt;- min(data_tidy$values)*0.95\n    ymax1 &lt;- max(data_tidy$values)*1.05\n    \n    g &lt;- ggplot(data=data_tidy, aes(x=predictor, y=values, group=data_labels))+\n      geom_line(aes(linetype=data_labels, colour=data_labels, size=data_labels, alpha=data_labels))+\n      scale_colour_manual(name=\"\", values=c(\"indianred4\", \"slategrey\", \"slategrey\"))+\n      scale_linetype_manual(name=\"\", values=c(\"solid\", \"solid\", \"dotted\"))+\n      scale_size_manual(name=\"\", values=c(2,1,1))+\n      scale_alpha_manual(name=\"\", values=c(0.8, 0.5, 0.5))+\n      theme_classic()+\n      annotate(geom=\"rect\", xmin=xmin1, xmax=xmax1, ymin=ymin1, ymax=ymax1, alpha=0.1)+\n      theme(legend.position=\"bottom\")+\n      labs(x=predictor_label, y=\"Log(Payments)\", title=paste(predictor_label, \"tracking for\", secondary_predictor, \"=\", secondary_predictor_val))\n      \n    \n\n  invisible(list(data=data_tidy, graph=g))\n}\n\nNow let’s look at development quarter when accident quarter is 20. Remember the step-interaction starts at dev=21 - which we see in the graph.\n\ndev_graph_list &lt;- GraphModelVals(data = synthetic_data, \n                             primary_predictor = \"dev\", \n                             secondary_predictor = \"acc\", \n                             secondary_predictor_val = 20, \n                             fitted_name = \"fitted_lasso\",\n                             predictor_label = \"Development quarter\")\n\n\ndev_graph_list$graph\n\n\n\n\nSimilarly we can look at accident quarter tracking when development quarter is 24 and again see the interaction.\n\nacc_graph_list &lt;- GraphModelVals(data = synthetic_data, \n                             primary_predictor = \"acc\", \n                             secondary_predictor = \"dev\", \n                             secondary_predictor_val = 24, \n                             fitted_name = \"fitted_lasso\",\n                             predictor_label = \"Accident quarter\")\n\n\nacc_graph_list$graph\n\n\n\n\nYou should, of course, carry out a full model validation exercise on any model prior to use, examining residuals, triangular heat maps and tweak the model if needed."
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#claims-reserves",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#claims-reserves",
    "title": "Self-assembling claim reserving models",
    "section": "Claims reserves",
    "text": "Claims reserves\nFinally, let’s get some claims reserve estimates and compare to those from an 8-period chain ladder.\nFirst let’s calculate the chainladder reserve.\n\n# cumulative payments on training data set\nsynthetic_data_train$Ycum &lt;- unlist(tapply(synthetic_data_train$Y, synthetic_data_train$acc, cumsum))\n\n# calc cl factors using an 8 quarter average\ncl_fac &lt;- numeric(numperiods-1)\n\nfor (j in 1:numperiods-1){\n  \n  cl_fac[j] &lt;- sum(subset(synthetic_data_train, dev == j+1 & acc &gt; (numperiods-8-j) & acc &lt;= numperiods-j)$Ycum) / \n    sum(subset(synthetic_data_train, dev == j & acc &gt; (numperiods-8-j) & acc &lt;= numperiods-j)$Ycum)\n}\n\n\n# accumulate the CL factors\ncl_cum &lt;- cumprod(rev(cl_fac))\n\n# leading diagonal\nleading_diagonal &lt;- subset(synthetic_data_train, cal == numperiods & acc&gt;1)$Ycum\n\n# CL amounts now\ncl_os &lt;- cl_cum * leading_diagonal - leading_diagonal\n\nRunning the code shows that the reserve for accident period 40 is a bit high(!) - so the y-axis scale on any plots may need to be adjusted for display purposes.\n\nprint(\"CL outstanding estimates\")\n\n[1] \"CL outstanding estimates\"\n\nhead( data.frame(Accident=numperiods:2, os = rev(cl_os/1000000000)))\n\n  Accident        os\n1       40 488.32119\n2       39  13.97485\n3       38  21.60132\n4       37  17.46894\n5       36  21.27673\n6       35  22.05057\n\n\nWe use the tapply function to calculate the outstanding amounts by accident period for the LASSO model as well as the true values (both the “actual” simulated values and the true underlying values).\n\nsynthetic_data_test &lt;- subset(synthetic_data, train_ind == FALSE)\n\nlasso_os &lt;- tapply(synthetic_data_test$fitted_lasso, synthetic_data_test$acc, sum)\nsim_os &lt;- tapply(synthetic_data_test$Y, synthetic_data_test$acc, sum)\ntrue_os &lt;- tapply(synthetic_data_test$mu, synthetic_data_test$acc, sum)\n\n\n#combine into a tidy dataset for ggplot\n# add a linetype option to have different linetypes\ncompare_os &lt;- data.frame(\n  rep(2:numperiods, times=4), \n  c(sim_os, lasso_os, cl_os, true_os)/1000000000,\n  c(rep(\"Simulated\", times=numperiods-1), rep(\"Lasso\", times=numperiods-1), rep(\"Chainladder (8 qtr)\", times=numperiods-1), rep(\"Underlying\", times=numperiods-1) )\n)\ncolnames(compare_os)&lt;-c(\"Accident\", \"Outstanding\", \"data_labels\")\n\nHere’s a plot of the results (similar to that in the paper). Note that the y-axis is restricted for readability so that the actual chain ladder value for accident period 40 does not display on the graph.\n\nos_plot &lt;-\n    ggplot(data=compare_os, aes(x=Accident, y=Outstanding, group=data_labels))+\n    geom_line(aes(colour=data_labels, linetype=data_labels), alpha=0.8, size=0.75)+\n    scale_colour_manual(name=\"\", values=c(\"steelblue3\", \"indianred4\", \"slategrey\", \"slategrey\" ))+\n    scale_linetype_manual(name=\"\", values=c(\"dashed\", \"solid\", \"dotted\", \"solid\" ))+\n    geom_line(data=subset(compare_os, data_labels==\"Lasso\"), aes(colour=data_labels), size=1.25, alpha=0.8, colour=\"indianred4\", linetype=\"solid\")+\n  coord_cartesian(ylim=c(0, 40))+\n    theme_classic()+\n    theme(legend.position=\"bottom\", legend.title=element_blank())+\n    scale_y_continuous(labels=scales::comma)+\n    labs(x=\"Accident quarter\", y=\"Amount ($B)\")+\n    NULL\n\nos_plot\n\n\n\n\nYou can see from the graph that - despite the presence of an interaction affecting only a small number of cells, the LASSO model detects and responds appropriately to this change. By contrast, the chain ladder model does not perform so well."
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#conclusion",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#conclusion",
    "title": "Self-assembling claim reserving models",
    "section": "Conclusion",
    "text": "Conclusion\nThe aim of this article has been to demonstrate the fitting of a claims reserving model using a LASSO approach in R and to produce some of the model diagnostic and results output that a user might wish to examine. If you would like to experiment some more, you could try modifying the synthetic data set code to produce other types of simulated data (such as those in our paper), or try it out on a real data example."
  },
  {
    "objectID": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#session-information",
    "href": "post/2019-05-31-self-assembling-claim-reserving-models/index.html#session-information",
    "title": "Self-assembling claim reserving models",
    "section": "Session information",
    "text": "Session information\nTo assist with reproducibility, here are details of my R session.\n\nsessionInfo()\n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   \n[3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=English_Australia.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.2 glmnet_4.1-7  Matrix_1.5-3 \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10       compiler_4.2.3    pillar_1.9.0      iterators_1.0.14 \n [5] tools_4.2.3       digest_0.6.31     jsonlite_1.8.4    evaluate_0.20    \n [9] lifecycle_1.0.3   tibble_3.2.1      gtable_0.3.3      lattice_0.20-45  \n[13] pkgconfig_2.0.3   rlang_1.1.1       foreach_1.5.2     cli_3.6.1        \n[17] yaml_2.3.7        xfun_0.39         fastmap_1.1.1     withr_2.5.0      \n[21] knitr_1.42        htmlwidgets_1.6.2 vctrs_0.6.2       grid_4.2.3       \n[25] glue_1.6.2        R6_2.5.1          fansi_1.0.4       survival_3.5-3   \n[29] rmarkdown_2.21    farver_2.1.1      magrittr_2.0.3    scales_1.2.1     \n[33] codetools_0.2-19  htmltools_0.5.5   splines_4.2.3     shape_1.4.6      \n[37] colorspace_2.1-0  renv_0.17.3       labeling_0.4.2    utf8_1.2.3       \n[41] munsell_0.5.0"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html",
    "title": "Traditional-style reserving using GLMs",
    "section": "",
    "text": "The article below is my original article working through fitting a GLM to aggregate triangular data using the methods and data from the CAS Monograph Stochastic Loss Reserving using Generalized Linear Models.\nSince then some or all of the article has re-published with some changes at:\n\nReserving with GLMs on the MLRWP blog\nReserving with GLMs in Python on the MLRWP blog"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#april-2023-update",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#april-2023-update",
    "title": "Traditional-style reserving using GLMs",
    "section": "",
    "text": "The article below is my original article working through fitting a GLM to aggregate triangular data using the methods and data from the CAS Monograph Stochastic Loss Reserving using Generalized Linear Models.\nSince then some or all of the article has re-published with some changes at:\n\nReserving with GLMs on the MLRWP blog\nReserving with GLMs in Python on the MLRWP blog"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#introduction",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#introduction",
    "title": "Traditional-style reserving using GLMs",
    "section": "Introduction",
    "text": "Introduction\nThis post provides a worked example in R of fitting a GLM to some non-life claims reserving data. The example and data are drawn from the CAS Monograph Stochastic Loss Reserving using Generalized Linear Models. Here we follow through the application of the cross-classified model from that monograph to the data (Chapter 3), and follow through with the additional work to firstly simplify the model and secondly to improve the model fit through the use of some interaction terms (Chapter 7).\n\nThe data used in this article is available here\nYou can download this notebook as a quarto file to run the code yourself from here"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#setup",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#setup",
    "title": "Traditional-style reserving using GLMs",
    "section": "Setup",
    "text": "Setup\nBefore we begin, we first set up the R session by loading in the various packages that we need.\n\nhere: I first heard about here from reading Jenny Bryan’s article on it and have been a fan of here and the R project structure ever since. It really helps with portability of code.\n\nBasically it allows you to use relative rather than absolute file paths.\nIf you want to run this notebook and don’t want to use here then all you need to do is put an appropriate pathname in for loading in the data from a CSV file. Location is not used anywhere else.\n\ndata.table I really like data.table - its power, speed and terseness. At some point though I may replace the data.table code with base R to reduce dependencies. For now though, there isn’t a huge amount of data.table code.\n\nEven if you don’t like data.table syntax, the fread and fwrite functions can be very useful for reading and writing CSV files.\n\nggplot2: create nice graphs easily\n\nviridis nice colour palettes that are tested for common forms of colour-blindness\ncowplot - an easy way of grouping graphs into a single figure\n[patchwork]https://cran.r-project.org/web/packages/patchwork/index.html) - an easy way of grouping graphs into a single figure\n\nknitr The notebook uses kable from the knitr package. If you’re using RStudio to run this code in notebook format, then you should already have it. Otherwise you can install it, or you can simply replace all the kable commands with print statements.\n\nIf you don’t have any of these packages you will need to install them via install.packages or, if using RStudio, via the Install buttom in the packages pane.\n\n\nlibrary(here)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(viridis)\nlibrary(patchwork)\n# I have elected not to attach knitr, so we need to use knitr::kable() below\n\noptions(scipen = 99)   # get rid of scientific notation\n\n# use this theme in all plots\nggplot2::theme_set(theme_classic())"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#data",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#data",
    "title": "Traditional-style reserving using GLMs",
    "section": "Data",
    "text": "Data\nThe data are presented in Section 1.3 of the monograph. Ultimately the data were sourced from the Meyers and Shi (2011) database, and are the workers compensation triangle of the New Jersey Manufacturers Group.\nFor ease of use, I have created a CSV file with the data which is loaded in this code chunk. As noted above I use relative path names with the here package. If you don’t want to have a setup that works with here, just ensure the full pathname to the file is included in the fread statement below.\nOnce the data is loaded in, have a look at the start of it.\n\nmsdata &lt;- data.table::fread(here::here(\"post/2019-11-07-traditional-style-reserving-using-glms/_glms_meyersshi.csv\"))\n# if needed replace here::here(\"data/glms_meyershi.csv\") with\n# the correct path and filename of where you put the data\n\nsetDT(msdata)\n\nprint(msdata[1:6,])\n\n   acc_year dev_year cumulative incremental\n1:        1        1      41821       41821\n2:        1        2      76550       34729\n3:        1        3      96697       20147\n4:        1        4     112662       15965\n5:        1        5     123947       11285\n6:        1        6     129871        5924\n\n\nSo we have four columns:\n\nacc_year: accident year, numbered from 1 to 10\ndev_year: development year, also numbered from 1 to 10\ncumulative: cumulative payments to date\nincremental: incremental payments for that accident year, development year combination.\n\nLet’s look at the data visually.\nFirst we plot the cumulative amounts in each accident year\n\nggplot(data=msdata, aes(x=dev_year, y=cumulative, colour=as.factor(acc_year))) +\n    geom_line(size=1) +\n    scale_color_viridis_d(begin=0.9, end=0) + \n    ggtitle(\"Cumulative amounts by development year\") + \n    theme(legend.position = \"right\", legend.title=element_blank(), legend.text=element_text(size=8))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nNow look at the incremental amounts\n\nggplot(data=msdata, aes(x=dev_year, y=incremental, colour=as.factor(acc_year))) +\n    geom_line(size=1) +\n    scale_color_viridis_d(begin=0.9, end=0) + \n    ggtitle(\"Incremental amounts by development year\") + \n    theme(legend.position = \"right\", legend.title=element_blank(), legend.text=element_text(size=8))\n\n\n\n\nThe data look quite well behaved - each year seems to have a similar development pattern."
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#modelling",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#modelling",
    "title": "Traditional-style reserving using GLMs",
    "section": "Modelling",
    "text": "Modelling\n\nInitial model\nThe first model applied here is the Over-dispersed Poisson (ODP) cross classified (cc) model (Sections 3.3.2 and 3.3.3 of the monograph). This model has been shown to give the same results as the chain ladder algorithm.\nTo apply the model, we will use the glm function from the base R stats package. The cross-classified model requires separate levels for each of accident and development year so we first make a factor version of these variates.\n\nmsdata[, acc_year_factor := as.factor(acc_year)\n       ][, dev_year_factor := as.factor(dev_year)\n         ][, cal_year := acc_year + dev_year - 1]\n\nNow we fit the model and look at the results via summary.\n\nThe family is the quasipoisson - this is how we fit an ODP model with glm.\nThe link is log\nThe formula is simply “incremental ~ 0 + acc_year_factor + dev_year_factor”\n\nThe 0 tells glm to fit a model without an intercept\nWe choose to do that here because then we can more easily compare the results to those in the monograph.\n\n\n\nglm_fit1 &lt;- glm(data = msdata, \n    family = quasipoisson(link = \"log\"),\n    formula = \"incremental ~ 0 + acc_year_factor + dev_year_factor\")\n\n\nsummary(glm_fit1)\n\n\nCall:\nglm(formula = \"incremental ~ 0 + acc_year_factor + dev_year_factor\", \n    family = quasipoisson(link = \"log\"), data = msdata)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-21.493   -5.534    0.000    5.136   21.059  \n\nCoefficients:\n                  Estimate Std. Error t value             Pr(&gt;|t|)    \nacc_year_factor1  10.65676    0.03164 336.794 &lt; 0.0000000000000002 ***\nacc_year_factor2  10.79533    0.02994 360.507 &lt; 0.0000000000000002 ***\nacc_year_factor3  10.89919    0.02887 377.465 &lt; 0.0000000000000002 ***\nacc_year_factor4  10.98904    0.02808 391.326 &lt; 0.0000000000000002 ***\nacc_year_factor5  11.03883    0.02783 396.654 &lt; 0.0000000000000002 ***\nacc_year_factor6  11.01590    0.02855 385.867 &lt; 0.0000000000000002 ***\nacc_year_factor7  11.00808    0.02945 373.734 &lt; 0.0000000000000002 ***\nacc_year_factor8  10.89050    0.03266 333.463 &lt; 0.0000000000000002 ***\nacc_year_factor9  10.83613    0.03669 295.348 &lt; 0.0000000000000002 ***\nacc_year_factor10 10.69108    0.05104 209.454 &lt; 0.0000000000000002 ***\ndev_year_factor2  -0.20466    0.02276  -8.993  0.00000000009767316 ***\ndev_year_factor3  -0.74741    0.02819 -26.512 &lt; 0.0000000000000002 ***\ndev_year_factor4  -1.01667    0.03284 -30.954 &lt; 0.0000000000000002 ***\ndev_year_factor5  -1.45160    0.04214 -34.446 &lt; 0.0000000000000002 ***\ndev_year_factor6  -1.83254    0.05471 -33.495 &lt; 0.0000000000000002 ***\ndev_year_factor7  -2.14026    0.07150 -29.933 &lt; 0.0000000000000002 ***\ndev_year_factor8  -2.34827    0.09312 -25.218 &lt; 0.0000000000000002 ***\ndev_year_factor9  -2.51317    0.12673 -19.831 &lt; 0.0000000000000002 ***\ndev_year_factor10 -2.66449    0.19930 -13.369  0.00000000000000158 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 114.5364)\n\n    Null deviance: 27479374.2  on 55  degrees of freedom\nResidual deviance:     4128.1  on 36  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\nWe now extract the coefficient table in a more convenient way and append it onto the glm_fit1 object for later use.\nWe will also print the table again in a nicer form to make it easier to compare to the first 3 columns of Table 3-5 of the monograph.\n\nIf you do this, you should see that the results match.\n\n\n# save the data for later use\nglm_fit1$coeff_table &lt;- data.table(parameter = names(glm_fit1$coefficients), \n                                   coeff_glm_fit1 = glm_fit1$coefficients)\n\n# print out the table so we can compare against Table 3-5.\nglm_fit1$coeff_table |&gt; \n    knitr::kable(digits=c(0,3))\n\n\n\n\nparameter\ncoeff_glm_fit1\n\n\n\n\nacc_year_factor1\n10.657\n\n\nacc_year_factor2\n10.795\n\n\nacc_year_factor3\n10.899\n\n\nacc_year_factor4\n10.989\n\n\nacc_year_factor5\n11.039\n\n\nacc_year_factor6\n11.016\n\n\nacc_year_factor7\n11.008\n\n\nacc_year_factor8\n10.891\n\n\nacc_year_factor9\n10.836\n\n\nacc_year_factor10\n10.691\n\n\ndev_year_factor2\n-0.205\n\n\ndev_year_factor3\n-0.747\n\n\ndev_year_factor4\n-1.017\n\n\ndev_year_factor5\n-1.452\n\n\ndev_year_factor6\n-1.833\n\n\ndev_year_factor7\n-2.140\n\n\ndev_year_factor8\n-2.348\n\n\ndev_year_factor9\n-2.513\n\n\ndev_year_factor10\n-2.664\n\n\n\n\n\n\n\nLoss reserve\n\nWe will calculate the loss reserve for this model\nThis should give the same answers as the chain ladder algorithm\n\n\n# first make the lower triangle data set\nay &lt;- NULL\ndy &lt;- NULL\n\n\nfor(i in 2:10){\n    ay &lt;- c(ay, rep(i, times=(i-1)))\n    dy &lt;- c(dy, (10-i+2):10)\n}\n\nfutdata &lt;- data.table(acc_year = ay, dev_year = dy)\n\n# make factors\nfutdata[, cal_year := acc_year + dev_year\n        ][, acc_year_factor := as.factor(acc_year)\n          ][, dev_year_factor := as.factor(dev_year)]\n\n# make the prediction and sum by acc_year\nx &lt;- predict(glm_fit1, newdata = futdata, type=\"response\")\nfutdata[, incremental := x]\n\n\nocl_year &lt;- futdata[,  lapply(.SD, sum), .SDcols=c(\"incremental\"), by=\"acc_year\"]\n\nocl_year |&gt; \n    knitr::kable(digits=c(0, 0))\n\n\n\n\nacc_year\nincremental\n\n\n\n\n2\n3398\n\n\n3\n8155\n\n\n4\n14579\n\n\n5\n22645\n\n\n6\n31865\n\n\n7\n45753\n\n\n8\n60093\n\n\n9\n80983\n\n\n10\n105874\n\n\n\n\n\n\nAs expected, this matches the results in Table 3-2 of the monograph.\n\n\n\nModel diagnostics\nIt’s always important to check that a model fits the data well, so here we look at the following:\n\nResidual Scatterplots\n\nby linear predictor\nby accident, development and calendar years\n\nHeat map of actual vs fitted\n\nIn this we get the actual/fitted ratio in each (acc, dev) cell [subject to lower and upper bounds of (0.5, 2)] and then plot the colour-coded triangle of the actual/fitted values\nheat maps are helpful to check for model fit and may help to identify missing interactions.\n\n\nNote on residuals with glm\n\nThe residuals in a glm object accessed with $residuals are residuals used in the model fitting algorithm.\nFor diagnostic purposes, the standardised deviance residuals are usually preferable to work with.\n\nThese are the signed square roots of the contribution of the ith observation to the deviance, divided by hat matrix values.\nThe stats::rstandard() function may be used with glm objects to extract the standardised deviance residuals.\n\n\n\nGenerating the diagnostics\n\nFirst we prepare the data by adding the fitted values and residuals.\n\nBecause this model has a lot of parameters, there are two observations where the fitted is exactly equal to the actual – (acc_year=1, dev_year=10) and (acc_year=10, dev_year=0). This is because these observations have a unique parameter.\nThe deviance calculations below return NaN (not a number) for these points, but the residual should really be 0 so this adjustment is made manually.\n\nAlso add actual/fitted ratios and the log of these (restricted to the range [log(0.5), log(2)]) - these will be used for a heatmap later.\n\nThe restricted range is used to generate easier to read shadings in the heat-map, while the conversion to log means that the shading scales will be similar intensity for \\(x\\)% and \\(1/x\\) %\n\n\n\nmsdata[, residuals1 := rstandard(glm_fit1)\n       ][, fitted1 := glm_fit1$fitted.values\n         ][, linear_predictor1 := log(fitted1)\n           ][, AvsF1 := incremental / fitted1\n             ][, AvsF_restricted1 := log(pmax(0.5, pmin(2,AvsF1)))]\n\n# check for NaN residuals\nmsdata[is.nan(residuals1),]\n\n   acc_year dev_year cumulative incremental acc_year_factor dev_year_factor\n1:        1       10     144781        2958               1              10\n2:       10        1      43962       43962              10               1\n   cal_year residuals1 fitted1 linear_predictor1 AvsF1\n1:       10        NaN    2958          7.992269     1\n2:       10        NaN   43962         10.691081     1\n            AvsF_restricted1\n1: -0.0000000000000019984014\n2:  0.0000000000000008881784\n\n# these occur where we expect them so so replace with 0\nmsdata[is.nan(residuals1), residuals1 := 0]\n\nLook at the first 10 rows of msdata\n\nhead(msdata, 10)\n\n    acc_year dev_year cumulative incremental acc_year_factor dev_year_factor\n 1:        1        1      41821       41821               1               1\n 2:        1        2      76550       34729               1               2\n 3:        1        3      96697       20147               1               3\n 4:        1        4     112662       15965               1               4\n 5:        1        5     123947       11285               1               5\n 6:        1        6     129871        5924               1               6\n 7:        1        7     134646        4775               1               7\n 8:        1        8     138388        3742               1               8\n 9:        1        9     141823        3435               1               9\n10:        1       10     144781        2958               1              10\n    cal_year  residuals1   fitted1 linear_predictor1     AvsF1\n 1:        1 -0.37704981 42478.725         10.656759 0.9845164\n 2:        2  0.06821815 34616.808         10.452095 1.0032410\n 3:        3  0.02211088 20117.514          9.909346 1.0014657\n 4:        4  0.50192703 15368.757          9.640092 1.0387958\n 5:        5  1.36344235  9948.355          9.205163 1.1343584\n 6:        6 -1.13119533  6796.876          8.824218 0.8715769\n 7:        7 -0.33754581  4996.553          8.516503 0.9556589\n 8:        8 -0.56680264  4058.159          8.308485 0.9220929\n 9:        9 -0.01379476  3441.253          8.143591 0.9981829\n10:       10  0.00000000  2958.000          7.992269 1.0000000\n            AvsF_restricted1\n 1: -0.015604749951508145936\n 2:  0.003235741327323749146\n 3:  0.001464610789021573859\n 4:  0.038062125103388820546\n 5:  0.126067171138098593763\n 6: -0.137451186377785167236\n 7: -0.045354245283910396558\n 8: -0.081109303248732236846\n 9: -0.001818723883641001036\n10: -0.000000000000001998401\n\n\nNow let’s look at the residual scatterplots - here I use the cowplot package to combine all 4 graphs into one plot.\nIn the linear predictor scatterplot, the points are colour coded so that the lighter points belong to the earlier development years, and the darker points belong to the later ones.\n\np1 &lt;- ggplot(data=msdata, aes(x=linear_predictor1, y=residuals1, colour=dev_year)) +\n    geom_point(size=2) +\n    scale_colour_viridis(begin=0.9, end=0) +\n    theme(legend.position = \"none\") +\n    ggtitle(\"Linear predictor\")\n\n\np2 &lt;- ggplot(data=msdata, aes(x=acc_year, y=residuals1)) +\n    geom_point(size=2, colour=\"#2d708eff\") +\n    ggtitle(\"Accident year\")\n\np3 &lt;- ggplot(data=msdata, aes(x=dev_year, y=residuals1)) +\n    geom_point(size=2, colour=\"#2d708eff\") +\n    ggtitle(\"Development year\")\n\np4 &lt;- ggplot(data=msdata, aes(x=cal_year, y=residuals1)) +\n    geom_point(size=2, colour=\"#2d708eff\") +\n    ggtitle(\"Calendar year\")\n\n# combine plots with patchwork\np &lt;- (p1 + p2) / (p3 + p4)\n\np\n\n\n\n\nNow construct and draw the heat map. Note that the colours are:\n\nblue (A/F = 50%)\nwhite (A/F = 100%)\nred (A/F = 200%)\n\n\n# heatmap code\n# to get the correct shading I've plotted the log of the restricted A/F values\n\np_hm &lt;- ggplot(data=msdata, aes(x=dev_year, y=acc_year)) + \n    geom_tile(aes(fill = AvsF_restricted1))+scale_y_reverse()+\n    scale_fill_gradient2(name=\"AvF_min\", low=\"royalblue\", mid=\"white\", high=\"red\", midpoint=0, space=\"Lab\", na.value=\"grey50\", guide=\"colourbar\")+\n    labs(x=\"Development year\", y=\"Accident year\")+\n    theme(legend.position = \"none\")+\n    theme(axis.title.x = element_text(size=8), axis.text.x  = element_text(size=7))+\n    theme(axis.title.y = element_text(size=8), axis.text.y  = element_text(size=7))+\n    theme(panel.background = element_rect(fill = \"grey\", colour = \"grey\", size = 2, linetype = \"solid\"),\n          panel.grid = element_line(colour=\"grey\")) + \n    NULL\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nprint(p_hm)"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#refining-the-model",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#refining-the-model",
    "title": "Traditional-style reserving using GLMs",
    "section": "Refining the model",
    "text": "Refining the model\nWe could stop here - and just use the results from this model, which match those produced by the chain ladder. The diagnostics suggest that the model fits quite well. However can we:\n\nidentify simplifications to the model to make it more parsinomious?\nidentify any areas of poorer fit than may suggest missing model terms including interactions?\n\n\nSimplifying the model\nFirst we consider if we can use a parametric shape for the accident and development year parameters.\n\n\nAccident year\nFirst plot the accident year parameters.\n\n# extract the data\ndt_acc_year &lt;- glm_fit1$coeff_table[grepl(\"acc_year\", parameter),  \n                                    ][, acc_year := as.integer(gsub(\"acc_year_factor\", \"\", parameter))]\n\n\n# plot\nggplot(data=dt_acc_year, aes(x=acc_year, y=coeff_glm_fit1)) +\n    geom_line(size=2, colour=\"#440154ff\") +\n    geom_point(size=4, colour=\"#440154ff\") + \n    ggtitle(\"Accident year parameters\")\n\n\n\n\n\nNote that their shape closely resembles that of a parabola.\nThis suggests that we can replace the 10 accident year parameters by\n\nthe overall intercept\nan acc_year term\nan acc_year squarted term\n\nSo refit the model on this basis.\n\nDrop the 0 from the glm_fit1 formula to allow the model to have an intecept\nReplace the acc_year_factor term with the parabola terms.\n\n\n\n# add an x and x^2 term\nmsdata[, acc_year_2 := acc_year^2]\n\nglm_fit2 &lt;- glm(data = msdata, \n    family = quasipoisson(link = \"log\"),\n    formula = \"incremental ~ acc_year + acc_year_2 + dev_year_factor\")\n\n\nsummary(glm_fit2)\n\n\nCall:\nglm(formula = \"incremental ~ acc_year + acc_year_2 + dev_year_factor\", \n    family = quasipoisson(link = \"log\"), data = msdata)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-28.5517   -5.1747    0.2691    4.5827   24.5421  \n\nCoefficients:\n                   Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)       10.470978   0.034414 304.264 &lt; 0.0000000000000002 ***\nacc_year           0.200075   0.014219  14.071 &lt; 0.0000000000000002 ***\nacc_year_2        -0.017907   0.001356 -13.210 &lt; 0.0000000000000002 ***\ndev_year_factor2  -0.205555   0.021276  -9.661     0.00000000000243 ***\ndev_year_factor3  -0.750108   0.026492 -28.314 &lt; 0.0000000000000002 ***\ndev_year_factor4  -1.014806   0.030982 -32.755 &lt; 0.0000000000000002 ***\ndev_year_factor5  -1.451958   0.039797 -36.484 &lt; 0.0000000000000002 ***\ndev_year_factor6  -1.830488   0.051662 -35.432 &lt; 0.0000000000000002 ***\ndev_year_factor7  -2.142154   0.067504 -31.734 &lt; 0.0000000000000002 ***\ndev_year_factor8  -2.352674   0.087924 -26.758 &lt; 0.0000000000000002 ***\ndev_year_factor9  -2.513722   0.119637 -21.011 &lt; 0.0000000000000002 ***\ndev_year_factor10 -2.660878   0.187820 -14.167 &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 102.5776)\n\n    Null deviance: 750824  on 54  degrees of freedom\nResidual deviance:   4427  on 43  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 3\n\n\nWe see in the coefficient table part of the summary that the two acc_year terms are highly significant.\n\nNow extract the coefficients and compare the previous and current fits.\n\nRemember that the intercept must be included in these calculations.\nAgain, save the coefficient table in this extracted form with the glm_fit2 object for later use.\n\n\n# extract the coefficient table\nglm_fit2$coeff_table &lt;- data.table(parameter = names(glm_fit2$coefficients), coeff_glm_fit2 = glm_fit2$coefficients)\nprint(glm_fit2$coeff_table)\n\n            parameter coeff_glm_fit2\n 1:       (Intercept)    10.47097818\n 2:          acc_year     0.20007497\n 3:        acc_year_2    -0.01790686\n 4:  dev_year_factor2    -0.20555514\n 5:  dev_year_factor3    -0.75010823\n 6:  dev_year_factor4    -1.01480620\n 7:  dev_year_factor5    -1.45195754\n 8:  dev_year_factor6    -1.83048769\n 9:  dev_year_factor7    -2.14215388\n10:  dev_year_factor8    -2.35267361\n11:  dev_year_factor9    -2.51372160\n12: dev_year_factor10    -2.66087765\n\n\nNow compare the past and current parameter estimates for accident year.\n\n# pull out the acc year coefficinents only\ndt_acc_year[, coeff_glm_fit2 := glm_fit2$coeff_table[parameter == \"acc_year\", coeff_glm_fit2]*acc_year + \n                glm_fit2$coeff_table[parameter == \"acc_year_2\", coeff_glm_fit2]*acc_year^2 + \n                glm_fit2$coeff_table[parameter == \"(Intercept)\", coeff_glm_fit2]]\n\n# make long for ggplot\ndt_acc_year_plot &lt;- melt(dt_acc_year, id.vars = \"acc_year\", measure.vars = c(\"coeff_glm_fit1\", \"coeff_glm_fit2\"), variable.name=\"model\", value = \"estimate\")\n\n# remove the coeff_ from the model names\ndt_acc_year_plot[, model := gsub(\"coeff_\", \"\", model, fixed=TRUE)]\n\nggplot(data=dt_acc_year_plot, aes(x=acc_year, y=estimate, colour=model)) +\n    geom_line(size=2) +\n    geom_point(size=4) +\n    scale_colour_viridis_d(begin=0, end=0.5) + \n    ggtitle(\"Accident year parameters\")\n\n\n\n\n\nThis looks very good - the fit is very similar, but we have 7 fewer parameters.\n\n\n\nDevelopment year\n\nNow we do the same thing for development year\nNote that the glm_fit2 model (and the glm_fit1 model too) do not have a parameter for dev_year = 1 as this is the base level.\n\nThis means that the parameter is really 0, so we must remember to include this.\n\n\n\n# extract the data\ndt_dev_year &lt;- glm_fit2$coeff_table[grepl(\"dev_year\", parameter),  \n                                    ][, dev_year := as.integer(gsub(\"dev_year_factor\", \"\", parameter))][]   # known data.table printing bug\n\n# add year 1\ndt_dev_year &lt;- rbind(dt_dev_year, data.table(parameter=\"dev_year_factor1\", coeff_glm_fit2=0, dev_year=1))\nsetorder(dt_dev_year, dev_year)\n\n\n# plot\nggplot(data=dt_dev_year, aes(x=dev_year, y=coeff_glm_fit2)) +\n    geom_line(size=2, colour=\"#440154ff\") +\n    geom_point(size=4, colour=\"#440154ff\") +\n    ggtitle(\"Development year parameters\")\n\n\n\n\n\nLooking at this plot, it appears that a straight line would fit quite well\nThis fit would be improved by allowing the straight line to bend (have a knot) at dev_year = 7\n\nSo let’s try this below\nnote we actually fit dev_year - 1 rather than dev_year\n\nthis means that the parameter estimate at dev_year = 1 is 0, just as it is in the glm_fit2 model, so it makes the results comparable\nif we fit dev_year, then the parameter estimate at dev_year=1 would be non-zero, so the two fits would be shifted relative to each other and we would need to adjust for that.\n\n\n\n\n# add dev-1 and dev-7 terms\nmsdata[, dev_year_m1 := dev_year - 1]\nmsdata[, dev_year_ge_7 := pmax(dev_year-7.5, 0)]\n\n# fit the model\nglm_fit3 &lt;- glm(data = msdata, \n    family = quasipoisson(link = \"log\"),\n    formula = \"incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7\")\n\n# extract and save the coefficient table\nglm_fit3$coeff_table &lt;- data.table(parameter = names(glm_fit3$coefficients), coeff_glm_fit3 = glm_fit3$coefficients)\n\n# display a summary of the model\nsummary(glm_fit3)\n\n\nCall:\nglm(formula = \"incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7\", \n    family = quasipoisson(link = \"log\"), data = msdata)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-25.301   -9.262   -2.080    5.893   42.841  \n\nCoefficients:\n               Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)   10.509475   0.052096 201.734 &lt; 0.0000000000000002 ***\nacc_year       0.204224   0.021608   9.451     0.00000000000104 ***\nacc_year_2    -0.018295   0.002058  -8.891     0.00000000000719 ***\ndev_year_m1   -0.364073   0.008845 -41.160 &lt; 0.0000000000000002 ***\ndev_year_ge_7  0.238860   0.088426   2.701              0.00941 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 242.0614)\n\n    Null deviance: 750824  on 54  degrees of freedom\nResidual deviance:  11879  on 50  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAssuming the fit is satisfactory, our original model with 19 parmaeters has now been simplified to 5 parameters - much more parsimonious and robust.\nLet’s check the fit by dev_year to see.\n\n\n# get the dev_year fit under the new model and add to the data.table containing the factor level parameters\np1 &lt;- glm_fit3$coeff_table[parameter == \"dev_year_m1\", coeff_glm_fit3]\np2 &lt;- glm_fit3$coeff_table[parameter == \"dev_year_ge_7\", coeff_glm_fit3]\ndt_dev_year[, coeff_glm_fit3 := p1*(dev_year-1) + p2*pmax(0, dev_year-7.5) ]\n\n\n# make long for ggplot\ndt_dev_year_plot &lt;- melt(dt_dev_year, id.vars = \"dev_year\", measure.vars = c(\"coeff_glm_fit2\", \"coeff_glm_fit3\"), variable.name=\"model\", value = \"estimate\")\n\n# remove the coeff_ from the model names\ndt_dev_year_plot[, model := gsub(\"coeff_\", \"\", model, fixed=TRUE)]\n\n\nggplot(data=dt_dev_year_plot, aes(x=dev_year, y=estimate, colour=model)) +\n    geom_line(size=2) +\n    geom_point(size=4) +\n    scale_colour_viridis_d(begin=0, end=0.5) +\n    ggtitle(\"Accident year parameters\")\n\n\n\n\n\nThis looks good.\nHowever dev_year = 2 is a bit underfit in the latest model, so we can add something to improve this fit\nSo refit and replot.\n\n\nmsdata[, dev_year_eq_2 := as.integer(dev_year == 2)]\n\nglm_fit4 &lt;- glm(data = msdata, \n    family = quasipoisson(link = \"log\"),\n    formula = \"incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7 + dev_year_eq_2\")\n\n\nglm_fit4$coeff_table &lt;- data.table(parameter = names(glm_fit4$coefficients), coeff_glm_fit4 = glm_fit4$coefficients)\n\n\np1 &lt;- glm_fit4$coeff_table[parameter == \"dev_year_m1\", coeff_glm_fit4]\np2 &lt;- glm_fit4$coeff_table[parameter == \"dev_year_ge_7\", coeff_glm_fit4]\np3 &lt;- glm_fit4$coeff_table[parameter == \"dev_year_eq_2\", coeff_glm_fit4]\ndt_dev_year[, coeff_glm_fit4 := p1*(dev_year-1) + p2*pmax(0, dev_year-7.5) + p3*(dev_year == 2) ]\n\n\n# make long for ggplot\ndt_dev_year_plot &lt;- melt(dt_dev_year, id.vars = \"dev_year\", measure.vars = c(\"coeff_glm_fit2\", \"coeff_glm_fit4\"), variable.name=\"model\", value = \"estimate\")\n\n# remove the coeff_ from the model names\ndt_dev_year_plot[, model := gsub(\"coeff_\", \"\", model, fixed=TRUE)]\n\n\nggplot(data=dt_dev_year_plot, aes(x=dev_year, y=estimate, colour=model)) +\n    geom_line(size=2) +\n    geom_point(size=4) +\n    scale_colour_viridis_d(begin=0, end=0.5) +\n    ggtitle(\"Accident year parameters\")\n\n\n\n\n\nLooks good!\n\n\n\nIdentifying missing structure\n\nThe second part of the model refining process involves checking for missing structure.\nLet’s have a better look at the heat map.\n\n\nmsdata[, residuals4 := rstandard(glm_fit4)\n       ][, fitted4 := glm_fit4$fitted.values\n         ][, linear_predictor4 := log(fitted4)\n           ][, AvsF4 := incremental / fitted4\n             ][, AvsF_restricted4 := log(pmax(0.5, pmin(2,AvsF4)))]\n\n\np_hm &lt;- ggplot(data=msdata, aes(x=dev_year, y=acc_year)) + \n    geom_tile(aes(fill = AvsF_restricted4))+scale_y_reverse()+\n    scale_fill_gradient2(name=\"AvF_min\", low=\"royalblue\", mid=\"white\", high=\"red\", midpoint=0, space=\"Lab\", na.value=\"grey50\", guide=\"colourbar\")+\n    labs(x=\"Development year\", y=\"Accident year\")+\n    theme(legend.position = \"none\")+\n    theme(axis.title.x = element_text(size=8), axis.text.x  = element_text(size=7))+\n    theme(axis.title.y = element_text(size=8), axis.text.y  = element_text(size=7))+\n    theme(panel.background = element_rect(fill = \"grey\", colour = \"grey\", size = 2, linetype = \"solid\"),\n          panel.grid = element_line(colour=\"grey\")) + \n    NULL\n\nprint(p_hm)\n\n\n\n\nLet’s look at the heatmap again, with some annotations\n\np_hm + \n    annotate(geom=\"rect\", xmin= 0.5, xmax=1.5, ymin=0.5, ymax=6.5, colour=\"darkblue\", alpha=0.1, size=1.5) +\n    annotate(geom=\"rect\", xmin= 0.5, xmax=1.5, ymin=6.5, ymax=10.5, colour=\"darkred\", alpha=0.1, size=1.5) +\n    annotate(geom=\"rect\", xmin= 1.5, xmax=2.5, ymin=0.5, ymax=6.5, colour=\"darkred\", alpha=0.1, size=1.5) +\n    annotate(geom=\"rect\", xmin= 1.5, xmax=2.5, ymin=6.5, ymax=9.5, colour=\"darkblue\", alpha=0.1, size=1.5) +\n    annotate(geom=\"segment\", x=3, xend=3, y=1, yend=8, arrow=arrow(), colour=\"darkblue\", size=2) +\n    annotate(geom=\"rect\", xmin= 3.5, xmax=4.5, ymin=0.5, ymax=7.5, colour=\"darkred\", alpha=0.1, size=1.5) \n\n\n\n\nWe see:\n\ndevelopment year 1, a distinct area of blue in the earlier accident years (A &lt; F), followed by red (A &gt; F)\ndevelopment year 2, a distinct area of red in the earlier accident years (A &gt; F), followed by blue (A &lt; F)\ndevelopment year 3, a possible progression from red to blue with increasing accident year (F increasing relative to A)\ndevelopment year 4, nearly all red (A &gt; F)\n\nThis suggests the payment pattern has altered and can be accommodated by (mostly) interaction terms within the GLM. Consider adding the following terms:\n\n(development year = 1) * (accident year is between 1 and 6)\n(development year = 2) * (accident year is between 1 and 6)\n(development year = 3) * (accident year linear trend)\n(development year = 4)\n\nSo, let’s refit the model with terms to capture these and have a look at the heat map again\n\n# add the new terms\nmsdata[, dev_year_eq_1 := as.integer(dev_year == 1)]\nmsdata[, dev_year_eq_3 := as.integer(dev_year == 3)]\nmsdata[, dev_year_eq_4 := as.integer(dev_year == 4)]\nmsdata[, acc_year_1_6 := as.integer(acc_year &gt;= 1 & acc_year &lt;= 6)]\n\n\nglm_fit5 &lt;- glm(data = msdata, \n    family = quasipoisson(link = \"log\"),\n    formula = \"incremental ~ acc_year + acc_year_2 + dev_year_m1 + dev_year_ge_7 + dev_year_eq_2 + dev_year_eq_4 +\n    dev_year_eq_1:acc_year_1_6 +  dev_year_eq_2:acc_year_1_6 + dev_year_eq_3:acc_year \")\n\n\n\nglm_fit5$coeff_table &lt;- data.table(parameter = names(glm_fit5$coefficients), coeff_glm_fit5 = glm_fit5$coefficients)\n\n# print the coefficient table\n\nglm_fit5$coeff_table |&gt; \n    knitr::kable(digits=c(0, 4))\n\n\n\n\nparameter\ncoeff_glm_fit5\n\n\n\n\n(Intercept)\n10.4904\n\n\nacc_year\n0.2066\n\n\nacc_year_2\n-0.0183\n\n\ndev_year_m1\n-0.3685\n\n\ndev_year_ge_7\n0.2720\n\n\ndev_year_eq_2\n0.0375\n\n\ndev_year_eq_4\n0.0528\n\n\ndev_year_eq_1:acc_year_1_6\n-0.0671\n\n\ndev_year_eq_2:acc_year_1_6\n0.1273\n\n\nacc_year:dev_year_eq_3\n-0.0113\n\n\n\n\n\n\nThis model should match that displayed in Table 7-5 of the monograph - and indeed it does (some very minor differences in parameter values - the model in the monograph was fitted in SAS).\nLook at the heat map again with annotations - has the model resolved the identified issues?\n\n\n# attach fitteds and residuals\nmsdata[, residuals5 := rstandard(glm_fit5)\n       ][, fitted5 := glm_fit5$fitted.values\n         ][, linear_predictor5 := log(fitted5)\n           ][, AvsF5 := incremental / fitted5\n             ][, AvsF_restricted5 := log(pmax(0.5, pmin(2,AvsF5)))]\n\n\n\np_hm &lt;- ggplot(data=msdata, aes(x=dev_year, y=acc_year)) + \n    geom_tile(aes(fill = AvsF_restricted5))+scale_y_reverse()+\n    scale_fill_gradient2(name=\"AvF_min\", low=\"royalblue\", mid=\"white\", high=\"red\", midpoint=0, space=\"Lab\", na.value=\"grey50\", guide=\"colourbar\")+\n    labs(x=\"Development year\", y=\"Accident year\")+\n    theme(legend.position = \"none\")+\n    theme(axis.title.x = element_text(size=8), axis.text.x  = element_text(size=7))+\n    theme(axis.title.y = element_text(size=8), axis.text.y  = element_text(size=7))+\n    theme(panel.background = element_rect(fill = \"grey\", colour = \"grey\", size = 2, linetype = \"solid\"),\n          panel.grid = element_line(colour=\"grey\")) + \n    annotate(geom=\"rect\", xmin= 0.5, xmax=1.5, ymin=0.5, ymax=6.5, colour=\"darkblue\", alpha=0.1, size=1.5) +\n    annotate(geom=\"rect\", xmin= 0.5, xmax=1.5, ymin=6.5, ymax=10.5, colour=\"darkred\", alpha=0.1, size=1.5) +\n    annotate(geom=\"rect\", xmin= 1.5, xmax=2.5, ymin=0.5, ymax=6.5, colour=\"darkred\", alpha=0.1, size=1.5) +\n    annotate(geom=\"rect\", xmin= 1.5, xmax=2.5, ymin=6.5, ymax=9.5, colour=\"darkblue\", alpha=0.1, size=1.5) +\n    annotate(geom=\"segment\", x=3, xend=3, y=1, yend=8, arrow=arrow(), colour=\"darkblue\", size=2) +\n    annotate(geom=\"rect\", xmin= 3.5, xmax=4.5, ymin=0.5, ymax=7.5, colour=\"darkred\", alpha=0.1, size=1.5) \n\n\nprint(p_hm)\n\n\n\n\n\nThis looks much better.\nWe should also look at the residual plots again\n\n\np1 &lt;- ggplot(data=msdata, aes(x=linear_predictor5, y=residuals5, colour=dev_year)) +\n    geom_point(size=2) +\n    scale_colour_viridis(begin=0.9, end=0) +\n    theme_bw() + \n    theme(legend.position = \"none\") +\n    ggtitle(\"Linear predictor\")\n\n\np2 &lt;- ggplot(data=msdata, aes(x=acc_year, y=residuals5)) +\n    geom_point(size=2, colour=\"#2d708eff\") +\n    theme_bw() + \n    ggtitle(\"Accident year\")\n\np3 &lt;- ggplot(data=msdata, aes(x=dev_year, y=residuals5)) +\n    geom_point(size=2, colour=\"#2d708eff\") +\n    theme_bw() + \n    ggtitle(\"Development year\")\n\np4 &lt;- ggplot(data=msdata, aes(x=cal_year, y=residuals5)) +\n    geom_point(size=2, colour=\"#2d708eff\") +\n    theme_bw() + \n    ggtitle(\"Calendar year\")\n\np &lt;- (p1 + p2) / (p3 + p4)\n\np"
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#loss-reserve-1",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#loss-reserve-1",
    "title": "Traditional-style reserving using GLMs",
    "section": "Loss reserve",
    "text": "Loss reserve\n\nNow that we have a model, let’s produce the estimate of the outstanding claims by accident year and in total.\n\nTake the lower triangle data [futdata] created above\nAdd on the new variates we created\nScore the model on this data\nSummarise the results\n\n\n Create the data and score using predict\n\n# add all model variates\nfutdata[, acc_year_2 := acc_year^2\n        ][, dev_year_m1 := dev_year - 1\n          ][, dev_year_ge_7 := pmax(0, dev_year - 7.5)\n            ][, dev_year_eq_1 := as.integer(dev_year == 1)\n              ][, dev_year_eq_2 := as.integer(dev_year == 2)\n                ][, dev_year_eq_3 := as.integer(dev_year == 3)\n                  ][, dev_year_eq_4 := as.integer(dev_year == 4)\n                    ][, acc_year_1_6 := as.integer(acc_year&gt;=1 & acc_year &lt;=6)]\n\n\nx &lt;- predict(glm_fit5, newdata = futdata, type=\"response\")\nfutdata[, incremental := x]\n\nhead(futdata)\n\n   acc_year dev_year cal_year acc_year_factor dev_year_factor incremental\n1:        2       10       12               2              10    3618.769\n2:        3        9       12               3               9    4470.907\n3:        3       10       13               3              10    4059.635\n4:        4        8       12               4               8    5324.841\n5:        4        9       13               4               9    4835.016\n6:        4       10       14               4              10    4390.250\n   acc_year_2 dev_year_m1 dev_year_ge_7 dev_year_eq_1 dev_year_eq_2\n1:          4           9           2.5             0             0\n2:          9           8           1.5             0             0\n3:          9           9           2.5             0             0\n4:         16           7           0.5             0             0\n5:         16           8           1.5             0             0\n6:         16           9           2.5             0             0\n   dev_year_eq_3 dev_year_eq_4 acc_year_1_6\n1:             0             0            1\n2:             0             0            1\n3:             0             0            1\n4:             0             0            1\n5:             0             0            1\n6:             0             0            1\n\n\nGet reserves by accident year and in total\n\nocl_year &lt;- futdata[,  lapply(.SD, sum), .SDcols=c(\"incremental\"), by=\"acc_year\"]\nocl_total &lt;- ocl_year[, sum(incremental)]\n\n\nocl_year |&gt; \n    knitr::kable(digits=c(0, 0))\n\n\n\n\nacc_year\nincremental\n\n\n\n\n2\n3619\n\n\n3\n8531\n\n\n4\n14550\n\n\n5\n22173\n\n\n6\n32458\n\n\n7\n45695\n\n\n8\n62955\n\n\n9\n79301\n\n\n10\n101212\n\n\n\n\n\nThe total reserve is\n\nocl_total |&gt; round(0)\n\n[1] 370493\n\n\n\nThese results are similar, though not identical, to the results given in Table 7-6 of the monograph.\nThis is because the forecast column of the monograph contains bootstrapped means rather than the model mean."
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#conclusion",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#conclusion",
    "title": "Traditional-style reserving using GLMs",
    "section": "Conclusion",
    "text": "Conclusion\nThe aim of this article has been to demonstrate fitting a GLM to a loss reserve following the example used in the CAS monograph. We started with the chain ladder equivalent - the cross classified model with an over-dispersed Poisson distribution, then first simplified it and second, extended it to include some interactions. We also cover how to create some of the plots discussed in the monograph in R, in particular residual scatter plots and the heat maps."
  },
  {
    "objectID": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#session-information",
    "href": "post/2019-11-07-traditional-style-reserving-using-glms/index.html#session-information",
    "title": "Traditional-style reserving using GLMs",
    "section": "Session information",
    "text": "Session information\nTo assist with reproducibility, here are details of my R session.\n\nsessionInfo()  \n\nR version 4.2.3 (2023-03-15 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   \n[3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=English_Australia.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] patchwork_1.1.2   viridis_0.6.2     viridisLite_0.4.1 ggplot2_3.4.2    \n[5] data.table_1.14.8 here_1.0.1       \n\nloaded via a namespace (and not attached):\n [1] knitr_1.42        magrittr_2.0.3    munsell_0.5.0     colorspace_2.1-0 \n [5] R6_2.5.1          rlang_1.1.1       fastmap_1.1.1     fansi_1.0.4      \n [9] tools_4.2.3       grid_4.2.3        gtable_0.3.3      xfun_0.39        \n[13] utf8_1.2.3        cli_3.6.1         withr_2.5.0       htmltools_0.5.5  \n[17] yaml_2.3.7        rprojroot_2.0.3   digest_0.6.31     tibble_3.2.1     \n[21] lifecycle_1.0.3   gridExtra_2.3     farver_2.1.1      htmlwidgets_1.6.2\n[25] vctrs_0.6.2       glue_1.6.2        evaluate_0.20     rmarkdown_2.21   \n[29] labeling_0.4.2    pillar_1.9.0      compiler_4.2.3    scales_1.2.1     \n[33] jsonlite_1.8.4    renv_0.17.3       pkgconfig_2.0.3"
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html",
    "href": "post/2023-05-04-model-error-example/index.html",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "",
    "text": "In Taylor & McGuire (2022), Greg Taylor and I looked at using the Lasso, together with Bayesian model averaging and the bootstrap procedure, to estimate internal model structure error in claims reserving. The paper contains the full details of the statistical framework used, so please refer to that for details of the approach.\nIn this article, or tutorial, what I’d like to share are the details of our bootstrapping approach which was behind the numerical results we discuss in Section 7 of the paper. This is because we consider that our approach tackles a number of practical problems faced by reserving actuaries:\n\nReserving actuaries must set uncertainty ranges on their reserves. Our approach estimates a number of components of forecast error - while our particular focus was on Internal Model Structure Error (refer to the discussion in Section 3 of the paper for definitions), we are also able to estimate parameter error as a by-product and process error as a straightforward bolt-on to the main process.\nOur estimation of model error relies on the model set produced by the Lasso process - the set of models returned of varying complexities. We use Bayesian model averaging to combine these models, but this requires a prior on each model. In the Lasso framework, the prior falls naturally out of the penalty values, or \\(\\lambda\\) parameters used to produce the model set.\nThe number of models within the Lasso model set is too sparse for reliable estimates of model error, so we use bootstrapping to augment the model set. We show how to bootstrap using a model produced by a Lasso. Furthermore, there are additional challenges in bootstrapping any model that extrapolates into future time periods in that models may display reasonable performance on past time periods, but extrapolate wildly into the future. This is an issue with any reserving model, but is magnified for machine learning models which do not have the same degree of curation to remove model terms that lead to wild behaviour.\n\nIn the paper used synthetic data sets in our examples since we were then able to control the complexity of experience within these and better understand the behaviour of model error in that context. Each data set was a 40x40 triangle of aggregate claims payments. However the computational requirements to run each of these are not particularly well-suited to a tutorial example - for example, a recent run of 500 bootstraps for one of the data sets took about 80 minutes using 10 parallel processes on a 16 core linux machine. So for this tutorial I’ve returned to the 10x10 aggregate triangle data we used in our CAS monograph, Stochastic Loss Reserving using Generalized Linear Models. As well as being smaller, we have analysed the data in detail and understand it well. My earlier post discusses this data set in more detail, so please refer to that and the monograph itself for further details.\nHowever, the same code is used in both examples and I will be adding a link to a notebook set up to run the synthetic data examples in due course, so that if you have the grunt power available to you, you can run the synthetic examples if you like (but note that the parallelisation used only works on linux machines - you will need to edit the code to run on windows machines). In the meantime, I suggest you try things on the smaller data set first.\nYou can download this file as a quarto notebook here.\n\n\n\nThis builds on the modelling approach in Self-Assembling Insurance Claim Models Using Regularized Regression and Machine Learning, so you may need to consult that paper if you are unfamiliar with it.\nAn earlier article works through the details of the model fitting in R.\nThe code underlying this is reasoanbly complex and is contained in functions in _functions.R. To really dig into the details of what’s going on, you may need to look at the R code."
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#introduction",
    "href": "post/2023-05-04-model-error-example/index.html#introduction",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "",
    "text": "In Taylor & McGuire (2022), Greg Taylor and I looked at using the Lasso, together with Bayesian model averaging and the bootstrap procedure, to estimate internal model structure error in claims reserving. The paper contains the full details of the statistical framework used, so please refer to that for details of the approach.\nIn this article, or tutorial, what I’d like to share are the details of our bootstrapping approach which was behind the numerical results we discuss in Section 7 of the paper. This is because we consider that our approach tackles a number of practical problems faced by reserving actuaries:\n\nReserving actuaries must set uncertainty ranges on their reserves. Our approach estimates a number of components of forecast error - while our particular focus was on Internal Model Structure Error (refer to the discussion in Section 3 of the paper for definitions), we are also able to estimate parameter error as a by-product and process error as a straightforward bolt-on to the main process.\nOur estimation of model error relies on the model set produced by the Lasso process - the set of models returned of varying complexities. We use Bayesian model averaging to combine these models, but this requires a prior on each model. In the Lasso framework, the prior falls naturally out of the penalty values, or \\(\\lambda\\) parameters used to produce the model set.\nThe number of models within the Lasso model set is too sparse for reliable estimates of model error, so we use bootstrapping to augment the model set. We show how to bootstrap using a model produced by a Lasso. Furthermore, there are additional challenges in bootstrapping any model that extrapolates into future time periods in that models may display reasonable performance on past time periods, but extrapolate wildly into the future. This is an issue with any reserving model, but is magnified for machine learning models which do not have the same degree of curation to remove model terms that lead to wild behaviour.\n\nIn the paper used synthetic data sets in our examples since we were then able to control the complexity of experience within these and better understand the behaviour of model error in that context. Each data set was a 40x40 triangle of aggregate claims payments. However the computational requirements to run each of these are not particularly well-suited to a tutorial example - for example, a recent run of 500 bootstraps for one of the data sets took about 80 minutes using 10 parallel processes on a 16 core linux machine. So for this tutorial I’ve returned to the 10x10 aggregate triangle data we used in our CAS monograph, Stochastic Loss Reserving using Generalized Linear Models. As well as being smaller, we have analysed the data in detail and understand it well. My earlier post discusses this data set in more detail, so please refer to that and the monograph itself for further details.\nHowever, the same code is used in both examples and I will be adding a link to a notebook set up to run the synthetic data examples in due course, so that if you have the grunt power available to you, you can run the synthetic examples if you like (but note that the parallelisation used only works on linux machines - you will need to edit the code to run on windows machines). In the meantime, I suggest you try things on the smaller data set first.\nYou can download this file as a quarto notebook here.\n\n\n\nThis builds on the modelling approach in Self-Assembling Insurance Claim Models Using Regularized Regression and Machine Learning, so you may need to consult that paper if you are unfamiliar with it.\nAn earlier article works through the details of the model fitting in R.\nThe code underlying this is reasoanbly complex and is contained in functions in _functions.R. To really dig into the details of what’s going on, you may need to look at the R code."
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#r-setup",
    "href": "post/2023-05-04-model-error-example/index.html#r-setup",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "R Setup",
    "text": "R Setup\nFirst I set up my R environment:\n\nPackages used (see bottom of this article for package versions). One thing I recommend is to check you have a recent version of glmnet (4.1-4 or later) since the package was changed to use C++ at that point leading to spped-ups in runtimes.\ncolours and ggplot2 theme settings\nFunctions used to run the code - the main parts of the code are sitting in the file _functions.R. Please note that these functions don’t contain much error catching so use them carefully and at your own risk. If you run into problems you may need to use R debugging tools to work out your error.\n\n\n## here() starts at C:/Work/Research/grainnemcguire.github.io\n## Loading required package: Matrix\n## Loaded glmnet 4.1-7\n## Loading required package: viridisLite\n## \n## Attaching package: 'viridis'\n## The following object is masked from 'package:scales':\n## \n##     viridis_pal\n## Loading required package: foreach\n## Loading required package: iterators\n## Loading required package: parallel\n\ncheck for conflicts and resolve if needed (one conflict found).\n\nconflict_scout()\n## 1 conflict\n## • `viridis_pal()`: viridis and scales\nconflict_prefer(\"viridis_pal\", \"viridis\")\n## [conflicted] Will prefer viridis::viridis_pal over any other package.\n\nNext I set up some things I’ll be using below:\n\nmain_model: Lasso models are a series of models, and we’ll need to specify one as our preferred or primary model. We use the one labelled as lambda.1se by glmnet - this is the model within 1 standard deviation of the minimum cross validation error model, often favoured by users as a good trade-off between quality of fit and overfitting\nlist_dt_filter_params which holds inclusion gates for the bootstrap. There’s more information on these in the paper and below so I’ll defer discussion until then.\nnum_bootstraps is the number of bootstraps to run. I’ve set this to 100 for the tutorial to keep runtimes manageable, but would recommend more in practice. If you’re running the code, I’d recommend you set it something small like 10 first, just to make sure everything runs, and then increase it to a reasonable number.\nnum_workers and batchsize relate to running code in parallel (not done here). Since we run sequentially, set batchsize equal to num_bootstraps\n\n\nmain_model &lt;- \"lambda.1se\"\n\n# inclusion gates for bootstrap\nlist_dt_filter_params &lt;- list(\n  main = list(\n    acc  = data.table(period = c(2, 5, 10), cutoff = c(1.33, 1.25, 1.20)),\n    cal  = data.table(period = c(2, 5, 10), cutoff = c(1.10, 1.15, 1.20))\n  ))\n\n# set initial wider gates\ninit_scale &lt;- 1.4\nlist_dt_filter_params$initial &lt;- list(\n  acc = copy(list_dt_filter_params$main$acc)[, cutoff := cutoff * init_scale],\n  cal = copy(list_dt_filter_params$main$cal)[, cutoff := cutoff * init_scale]\n)\n\n# number of bootstraps\nnum_bootstraps &lt;- 100\nnum_workers &lt;- 1  # we run sequentially\nbatchsize &lt;- num_bootstraps/ num_workers \nuse_parallel &lt;- FALSE"
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#data",
    "href": "post/2023-05-04-model-error-example/index.html#data",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "Data",
    "text": "Data\n\nThe data is located here\nI’ve loaded in the data below using data.table::fread(). The file path is set using the here package.\n\nI use data.table for all my data manipulations - I’ll aim to describe what each code chunk is doing so even if you’re unfamiliar with data.table syntax, you’ll be able to follow along.\nI also use the DT to print out nicely formatted tables using the function DT::datatable() - this is not related to the data.table package.\n\nI need to do some preparing of the data:\n\nThe csv file only contains past data, but I want past and future so I use data.table::CJ() to build the full 10x10 skeleton before merging past data on\nMy model error code requires column names acc, dev, cal, past_ind and pmts so I make sure I have all the right columns and names after this process.\n\n\n\n# edit as needed for your file path\ndt_raw &lt;- fread(here(\"post\", \"2023-05-04-model-error-example\", \"_meyersshi.csv\"))\n\n# put into matching form\ndt &lt;- CJ(acc = 1:10, dev = 1:10)\ndt[, cal := acc + dev - 1]\ndt[, past_ind := cal &lt;= 10]\n\ndt[ dt_raw, on=.(acc = acc_year, dev = dev_year), pmts := i.incremental]\n\n# Look at the data\ndatatable(dt)\n\n\n\n\n\n\nWe can also look at the data graphically too.\n\np1 &lt;- ggplot(data=dt[past_ind==TRUE,], aes(x=dev, y=log(pmts), colour=as.factor(acc)))+\n  geom_line(linewidth = 1)+\n  scale_colour_viridis_d(begin=1, end=0, alpha=1)+\n  theme(legend.position = \"none\")+\n  labs(title=\"Each line is an accident quarter\", x=\"Development quarter\", y=\"log(Payments)\")+\n  NULL\n\np2 &lt;- ggplot(data=dt[past_ind==TRUE,], aes(x=dev, y=log(pmts), colour=as.factor(cal)))+\n  geom_line(linewidth = 1)+\n  scale_colour_viridis_d(begin=0, end=1, alpha=1)+\n  theme(legend.position = \"none\")+\n  labs(title=\"Each line is a calendar quarter\", x=\"Development quarter\", y=\"log(Payments)\")+\n  NULL\n\np1 + p2   # patchwork to combine plots"
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#primary-model",
    "href": "post/2023-05-04-model-error-example/index.html#primary-model",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "Primary model",
    "text": "Primary model\nNow we built the Lasso model of the data. We use the approach described in our earlier paper, Self-Assembling Insurance Claim Models Using Regularized Regression and Machine Learning. My previous article explains this process in more detail so please refer to that to fill in the gaps - e.g. if you need further details on the basis functions used, how they are defined, scaled etc.\nFrom the CAS monograph work we know that the data are modelled reasonably well by a Chain Ladder model (though our optimal GLM included some accident and development year interactions). So we use this information and only consider accident and development year basis functions. This choice is also motivated by practical reasons - fewer basis functions will make the code run faster, which suits the purposes of this tutorial.\nThere are a number of tasks we need to do when fitting the model. These include:\n\nCreating the basis functions to use in the fitting process\nFitting the model\nCalculating a scale parameter for use in bootstrapping\nProducing model forecasts\nProducing model residuals using the main selected model (lambda.1se in our case) and the scale parameter and looking at some diagnostics\nSpecifying the prior\nProducing the initial Bayesian model averaging results from the primary model - this is for interest only - as discussed in our paper, the model set is a bit too sparse to produce reliable estimates of variability, so we need to augment with bootstrapped samples.\n\nFirst we create list object to hold all of these results.\n\nlist_primary &lt;- list()\n\nlist_primary$data &lt;- copy(dt)\n\n\nBasis functions for lasso\nCreate the basis functions - first create a predictor_obj to hold the settings - e.g. what fundamental variables to include, scaling, what interactions to include. Then use a function to create the basis functions.\nAs discussed in my earlier article, I’ve gone through a few iterations of the basis function code over the years so what’s in _functions.R may be be a bit different to what’s discussed there.\n\nPredictor objectBasis functions\n\n\nSet up a predictor object to give information about each of the predictors so that basis functions can be constructed.\nThe predictor object should contain\n\nnum_predictors (2 - acc and dev)\npredictors\nmin - min value of each predictor\nmax - max value of each predictor\nramp_inc - we build a series of ramp functions and this indicates the increment. Always 1 for things like accident and development period\nscaling - this uses the GetScaling() function and applies to the fundamental vector - see the previous articles for more details on scaling\n\n\nlist_primary$predictor_obj &lt;- list()\n\nlist_primary$predictor_obj$num_predictors &lt;- 2\nlist_primary$predictor_obj$predictors &lt;- c(\"acc\", \"dev\")  \nlist_primary$predictor_obj$min &lt;- c(1, 1)\nlist_primary$predictor_obj$max &lt;- c(10, 10)\nlist_primary$predictor_obj$ramp_inc &lt;- c(1, 1)\nlist_primary$predictor_obj$scaling &lt;- c(GetScaling(dt[past_ind==TRUE, acc]), \n                                        GetScaling(dt[past_ind==TRUE, dev])) \n\n\n\n\nWe produce a matrix of all the basis functions. For convenience, this is separated into past and future components as well.\nThe parameter int_effects_list is used to specify what interactions to create - in this case all \\(I(\\text{acc} \\ge i) . I(\\text(dev) \\ge j)\\) heaviside interactions.\n\n\nlist_primary$varset &lt;- vector(mode=\"list\", length=3)\nnames(list_primary$varset) &lt;- c(\"all\", \"past\", \"future\")\n\n# all data (NB scaling above based on past data only)\nlist_primary$varset$all &lt;- GenerateVarset(data = dt,\n                                     predictor_object = list_primary$predictor_obj,\n                                     main_effects_list = c(\"acc\", \"dev\"),\n                                     int_effects_list = list(c(\"acc\", \"dev\")))\n\n# past data\nlist_primary$varset$past &lt;- list_primary$varset$all[dt[, past_ind], ]\n\n# future data\nlist_primary$varset$future &lt;- list_primary$varset$all[!dt[, past_ind], ]\n\n\n# look at start of matrix to see what it looks like\nlist_primary$varset$all[41:46, 1:10]\n\n     L_1_999_acc L_2_999_acc L_3_999_acc L_4_999_acc L_5_999_acc L_6_999_acc\n[1,]    1.632993    1.224745   0.8164966   0.4082483           0           0\n[2,]    1.632993    1.224745   0.8164966   0.4082483           0           0\n[3,]    1.632993    1.224745   0.8164966   0.4082483           0           0\n[4,]    1.632993    1.224745   0.8164966   0.4082483           0           0\n[5,]    1.632993    1.224745   0.8164966   0.4082483           0           0\n[6,]    1.632993    1.224745   0.8164966   0.4082483           0           0\n     L_7_999_acc L_8_999_acc L_9_999_acc L_1_999_dev\n[1,]           0           0           0   0.0000000\n[2,]           0           0           0   0.4082483\n[3,]           0           0           0   0.8164966\n[4,]           0           0           0   1.2247449\n[5,]           0           0           0   1.6329932\n[6,]           0           0           0   2.0412415\n\n\n\n\n\n\n\nLasso fitting\n\nHere we fit Lasso models using the glmnet package.\n\nAlthough we use the gamma distribution later in our analysis, we use the Poisson distribution with glmnet when generating our model set since we had convergence issues when using the gamma distribution.\nYou’ll notice we do 3 fits:\n\nThe first generates a series of lambda values, but does not do the cross validation\nIn the second we lengthen the lambda vector to smaller values to ensure that we do reach the minimum cross validation model and then run the cross-validation fitting process. We also add additional values between each lambda to pad out our model set as much as possible.\n\n\nI’ve also specified values for pmax and dfmax but in this example, these are just the defaults used by glmnet. I need to explicitly set them for the bootstrapping functions below which is why I’ve done it here.\n\n\ndfmax_default &lt;- ncol(list_primary$varset$past) + 1  # default setting of nvars+1\npmax_default &lt;- min(dfmax_default*2 + 20, ncol(list_primary$varset$past))\n\nset.seed(77)\n\naaa &lt;- glmnet(x=list_primary$varset$past, \n              y=dt[past_ind==TRUE, pmts],\n              family = \"poisson\",\n              dfmax = dfmax_default, \n              pmax = pmax_default, \n              nlambda = 50, \n              thresh = 1e-08, \n              lambda.min.ratio = 0,               \n              alpha=1, \n              standardize = FALSE,\n              maxit=1000000)\n\n# lengthen the lambda vector\norig_lambdavec &lt;- c(aaa$lambda, min(aaa$lambda)*(0.85^(1:50)))  # lengthen lambda vector\n\n# pad the lambda vector\nlambdavec &lt;- NULL\nfor(i in 1:(length(orig_lambdavec) - 1)){\n  lambdavec &lt;- c(lambdavec, seq(from = orig_lambdavec[i], to = orig_lambdavec[i+1], length.out = 5))\n}\n\n# remove dups\nlambdavec &lt;- sort( unique(lambdavec), decreasing = TRUE)\n\n\n\n\nset.seed(87)\nlist_primary$glmnet_obj &lt;- cv.glmnet(x = list_primary$varset$past,\n                                y = dt[past_ind==TRUE, pmts],\n                                family = \"poisson\",\n                                lambda=lambdavec,\n                                dfmax = dfmax_default, \n                                pmax = pmax_default, \n                                thresh = 1e-8,  \n                                alpha = 1,          # review after moving to agg data\n                                standardize = FALSE,\n                                nfolds = 8, \n                                parallel=FALSE,\n                                relax=FALSE,\n                                trace.it = FALSE,  # TRUE in notebooks leads to unpleasant output\n                                maxit = 1000000)\n\n\n# cleanup\nrm(aaa)\n\nCheck the fit looks reasonable - main thing to ensure is that the two vertical lines (which mark the lambda.min and the lambda.1se models) are not at the end of the plot, which would indicate that the lambda vector isn’t long enough (though after our manipulation of the vector above, it should be).\n\nplot(list_primary$glmnet_obj)\n\n\n\n\n\n\nScale parameter\nNow we have a set of models and a main model in that corresponding to the lambda.1se value, we can now estimate a scale parameter assuming a gamma distribution. We do this by fitting a gamma GLM to the lambda.1se model structure and taking the scale parameter from that.\nAs a minor technical point, we use MASS::gamma.shape() to get the scale parameter estimate rather than that from glm() directly. This is discussed further here.\n\n# coefficients in lambda.1se model\ncoefs &lt;- predict(list_primary$glmnet_obj, type = \"coefficients\", s = list_primary$glmnet_obj[[main_model]])\ncoefnames &lt;- c(\"Intercept\", colnames(list_primary$varset$past))\n\n# extract the non-zero coefficients\nind_nz_coefs &lt;- which(!(coefs == 0))\nnz_coefs &lt;- coefs[ind_nz_coefs]\nnz_coefnames &lt;- coefnames[ind_nz_coefs]\n\n# get the past_varset with just these observations\npast_varset_small &lt;- list_primary$varset$past[, nz_coefnames[-1]]   # the -1 removes the intercept\nglm_data = as.data.table(cbind(dt[past_ind==TRUE, .(pmts)], past_varset_small))\n\nglm_formula = as.formula(paste(\"pmts~\", paste(nz_coefnames[-1], collapse = \"+\")))\n\n\n#glm_formula\ngamma_mod_1 = glm(formula=glm_formula, family = Gamma(link=\"log\"), data = glm_data)\n\nsummary(gamma_mod_1)\n\n\nCall:\nglm(formula = glm_formula, family = Gamma(link = \"log\"), data = glm_data)\n\nDeviance Residuals: \n      Min         1Q     Median         3Q        Max  \n-0.136693  -0.048222   0.001886   0.041310   0.142041  \n\nCoefficients:\n            Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept) 10.65861    0.03428 310.959 &lt; 0.0000000000000002 ***\nL_1_999_acc  0.28652    0.03021   9.485     0.00000000000266 ***\nL_4_999_acc -0.19576    0.11254  -1.739              0.08879 .  \nL_5_999_acc -0.13971    0.18239  -0.766              0.44768    \nL_6_999_acc -0.01031    0.20091  -0.051              0.95930    \nL_7_999_acc -0.18356    0.15684  -1.170              0.24801    \nL_1_999_dev -0.50158    0.08647  -5.801     0.00000061660403 ***\nL_2_999_dev -0.71488    0.14832  -4.820     0.00001672460156 ***\nL_3_999_dev  0.27983    0.10398   2.691              0.00996 ** \nL_6_999_dev  0.38128    0.05998   6.356     0.00000009220787 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.005763095)\n\n    Null deviance: 36.19257  on 54  degrees of freedom\nResidual deviance:  0.26121  on 45  degrees of freedom\nAIC: 967.87\n\nNumber of Fisher Scoring iterations: 4\n\n\nExtract the updated scale parameter estimate\n\nlist_primary$scale &lt;- round(summary(gamma_mod_1, dispersion = MASS::gamma.dispersion(gamma_mod_1))$dispersion, 4)\n\nprint(list_primary$scale)\n\n[1] 0.0047\n\n\n\n\nForecasts and residuals\n\nCalculate forecasts under both lambda.min and lambda.1se models and add these to list_primary$data\nMake pred field from the main model (currently lambda.1se)\nCalculate Pearson residuals\n\n\n# add predictions under the two models for the min, 1se lambda values\nlist_primary$data[, lambda.1se := predict(list_primary$glmnet_obj, newx = list_primary$varset$all, type=\"response\", s=\"lambda.1se\")]\nlist_primary$data[, lambda.min := predict(list_primary$glmnet_obj, newx = list_primary$varset$all, type=\"response\", s=\"lambda.min\")]\n\n\n# make pred = selected model, pred will be used later in bootstrapping\n# calculate residuals - (actual - expected)/stdev\nlist_primary$data[, pred := get(main_model)]  # duplicate for convenience\nlist_primary$data[past_ind == TRUE, var_pred := (pred^2)*(list_primary$scale)\n                  ][past_ind == TRUE, resid := (pmts - pred)/sqrt(var_pred)]\n\n\n# also calculate reserve values\nlist_primary$reserves &lt;- vector(mode=\"list\", length = 3)\nnames(list_primary$reserves) &lt;- c(\"primary\", \"lambda.1se\", \"lambda.min\")\n\n# lambda.1se\nlist_primary$reserves$lambda.1se &lt;- list_primary$data[past_ind==FALSE, sum(lambda.1se)]\n# lambda.min\nlist_primary$reserves$lambda.min &lt;- list_primary$data[past_ind==FALSE, sum(lambda.min)]\n# selected aka primary\nlist_primary$reserves$primary &lt;- list_primary$reserves[[main_model]]\n\n# look at reserves\nas.data.table(list_primary$reserves)  |&gt;  \n  datatable()  |&gt;  \n  formatRound(names(list_primary$reserves), digits=0)\n\n\n\n\n\n\nSo the reserve under our main model is 368121 - for reference our final estimate in the CAS monograph work was $370,493.\n\nModel diagnostics\n\nResidual scatterplotsResidual density plotAvsE heatmaps\n\n\n\np1 &lt;- ggplot(data=list_primary$data[past_ind==TRUE,], aes(x=log(pred), y=resid, colour=dev)) +\n    geom_point(size=2) +\n    scale_colour_viridis(begin=0.9, end=0) +\n    theme(legend.position = \"none\") +\n    ggtitle(\"Linear predictor\")\n\n\np2 &lt;- ggplot(data=list_primary$data[past_ind==TRUE,], aes(x=acc, y=resid)) +\n    geom_point(size=2, colour=me_colours$blue) +\n    ggtitle(\"Accident\")\n\np3 &lt;- ggplot(data=list_primary$data[past_ind==TRUE,], aes(x=dev, y=resid)) +\n    geom_point(size=2, colour=me_colours$blue) +\n    ggtitle(\"Development\")\n\np4 &lt;- ggplot(data=list_primary$data[past_ind==TRUE,], aes(x=cal, y=resid)) +\n    geom_point(size=2, colour=me_colours$blue) +\n    ggtitle(\"Calendar\")\n\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\nHave a look at the density plot of residuals too\n\nggplot(data=list_primary$data[past_ind==TRUE]) +\n  geom_density(aes(resid, after_stat(density)), fill=me_colours$blue, colour=me_colours$blue) +\n  stat_function(fun = dnorm, colour=me_colours$orange, linewidth=2) \n\n\n\n\n\n\nThis plots shaded actual/expected values where white is close to 100%, red is where actual exceed expected (capped at 200%) and blue is where actual is less than expected (cupped at 50%).\n\nmodel_forecasts_long &lt;- melt(list_primary$data, \n                             measure.vars = c(\"lambda.1se\", \"lambda.min\"), \n                             id.vars=c(\"acc\", \"dev\", \"cal\", \"pmts\"),\n                             variable.name = \"model\",\n                             value.name = \"fitted\")\n\ng &lt;- GraphHeatMap(model_forecasts_long, x=\"dev\", y=\"acc\", facet=\"model\", actual=\"pmts\", fitted=\"fitted\", \n                  xlab=\"Development quarter\", ylab=\"Accident quarter\")\ng$graph\n\n\n\n\n\n\n\n\n\n\nPrior\n\nIn our paper we discuss different possibilities for priors, so refer to that discussion there\nBecause the Lasso is fitted using a poisson, but our analysis assumes a gamma distribution, we need to solve for the priors that produce the desired properties, rather than use the glmnet lambda values directly\nThe process is as follows:\n\nWe specify the priors for the model parameters assuming a laplace distribution\n\nA fairly wide prior for the intercept term centred on the log(average past payments)\nA common scale parameter specified by us for all other coefficient and a prior mean of 0\n\nWe then calculate the posterior distribution of each model given the laplace prior and a gamma log likelihood\nWe plot the posterior distributions and select the prior values that we wish\n\ne.g. the prior value that leads to the lambda.1se coinciding with the posterior mode.\n\n\n\n\nFiltering\nAs this state we should briefly discuss filtering or the inclusion gates - refer to section 5.2.5 of the paper and Table 5-1 therein as well as to the list_dt_filter_params object here.\nThe idea behind filtering is simple - we want to exclude models that extrapolate in a wild manner, and to an extend that an actuary would consider the model reasonable. In the paper we discussed how we looked at forecasts of different periods of payment (calendar periods) and accident periods and based the gates on that.\nI have retained the same inclusion gates for this data as for the simulated data. The filtering is implemented by my CalculatePosterior() function.\n\n\nCode for searching for the priors\nUsing a bit of trial and error and the code below, I came up with prior values for the four different types of prior considered in our paper.\nThe graph below won’t win any data visualisation contests, but captures the various bits and pieces of information I’ve used to interactively find the priors.\n\nlist_pp &lt;- list(\n  laplace_m_intercept = dt[past_ind==TRUE, log(mean(pmts))],   # prior mean of intercept\n  laplace_s_intercept = 2,     # scale for the intercept - must be large since results not centred so intercept can be long way from data average\n  laplace_m_parameters = 0,    # prior mean for the non-intercept params\n  laplace_s_parameters = 0.029,   \n  prior_name = \"finding_priors\"\n)\n\ndt_post &lt;- CalculatePosterior(list_primary$data, \n                              glmnet_obj = list_primary$glmnet_obj, \n                              varset = list_primary$varset$all,\n                              yvar = \"pmts\", \n                              dt_scaling_factor = NULL, \n                              list_filter = list_dt_filter_params$main, \n                              list_prior_params = list_pp, \n                              prior_name = NULL,\n                              scale = list_primary$scale)$probs\n\n\n# plot ----;\n# first get some quantities to put on the plot that we use in search for priors\nmn_1se &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"1se\"]\nmn_min &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"min\"]\nmn_max_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), model_num]\nmax_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), posterior]  # used for drawing lines on graph\nsum_prob_ge_1se &lt;- round(dt_post[model_num &gt;= mn_1se, sum(posterior)], 5)\nsum_prob_le_min &lt;- round(dt_post[model_num &lt;= mn_min, sum(posterior)], 5)\nsum_prob_ge_1se_label &lt;- paste(\"Pr(&gt;= 1se) = \", sum_prob_ge_1se, \"\\nso\", 1-sum_prob_ge_1se, \"in shaded area\")\nsum_prob_le_min_label &lt;- paste(\"Pr(&lt;= min) = \", sum_prob_le_min, \"\\nso\", 1-sum_prob_le_min, \"in shaded area\")\n\n\nggplot(data = dt_post, mapping = aes(x = model_num, y = posterior)) + \n  # max post line\n  annotate(\"segment\", x = mn_max_post, xend = mn_max_post, y=0, yend = max_post, colour = me_colours$teal, linewidth=1.5, linetype = 2) +\n  annotate(\"text\", x = mn_max_post, y = 1*max_post/3, label=paste(\"Max posterior model\"), colour = me_colours$teal) +\n  # 1se shaded box\n  annotate(\"rect\", xmin = min(dt_post$model_num), xmax = mn_1se, ymin = 0, ymax = max_post, fill = me_colours$orange, alpha = 0.1)+\n  annotate(\"text\", x = min(dt_post$model_num), y = 5*max_post/6, label=sum_prob_ge_1se_label, colour = me_colours$orange, hjust = 0) +\n  # min shaded box\n  annotate(\"rect\", xmin = mn_min, xmax = max(dt_post$model_num), ymin = 0, ymax = max_post, fill = me_colours$red, alpha = 0.1)+\n  annotate(\"text\", x = max(dt_post$model_num) + 2, y = 5*max_post/6, label=sum_prob_le_min_label, colour = me_colours$red, hjust = 1) +\n  # 1se line\n  annotate(\"segment\", x = mn_1se, xend = mn_1se, y=0, yend = max_post, colour = me_colours$orange) +\n  annotate(\"text\", x = mn_1se, y = 2*max_post/3, label=paste(\"lambda.1se model\"), colour = me_colours$orange) +\n  # min line\n  annotate(\"segment\", x = mn_min, xend = mn_min, y=0, yend = max_post, colour = me_colours$red) +\n  annotate(\"text\", x = mn_min, y = max_post/2, label=paste(\"lambda.min model\"), colour = me_colours$red) +\n  # posterior\n  geom_line(colour = me_colours$blue) +\n  labs(title = paste(\"Selecting prior - laplace scale is\", list_pp$laplace_s_parameters),\n       subtitle = paste(\"Max post = 1se:\", mn_max_post == mn_1se, \"\\nMax post = min:\", mn_max_post == mn_min)) +\n  # coord_cartesian(xlim=c(50, 150))+   # can use this to zoom in on parts of the graph\n  NULL\n\n\n\n\nUsing the code chunk above, I’ve found the priors corresponding to those used in our paper.\n\nlist_primary$prior$list_prior_params &lt;- list(\n  laplace_m_intercept = dt[past_ind==TRUE, log(mean(pmts))],   # prior mean of intercept\n  laplace_s_intercept = 2,     # scale for the intercept - must be large since results not centred so intercept can be long way from data average\n  laplace_m_parameters = 0,    # prior mean for the non-intercept params\n  laplace_s_parameters = c(0.01505, 0.029, 0.38, 1.55),\n  prior_name = c(\"simple\", \"lambda.1se\", \"lambda.min\", \"complex\")\n)\n\n\n\n\nPosterior distributions\nI’ve shown all four prior possibilities here, but later on will mainly focus on the results relating to the lambda.1se results.\n\nSimplelambda.1selambda.minComplex\n\n\n\n\nCode\ndt_post &lt;- CalculatePosterior(list_primary$data, \n                         glmnet_obj = list_primary$glmnet_obj, \n                         varset = list_primary$varset$all,\n                         yvar = \"pmts\", \n                         dt_scaling_factor = NULL, \n                         list_filter = list_dt_filter_params$main, \n                         list_prior_params = list_primary$prior$list_prior_params, \n                         prior_name = \"simple\",\n                         scale = list_primary$scale)$probs\n\n\n# plot ----;\n# first get some quantities to put on the plot that we use in search for priors\nmn_1se &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"1se\"]\nmn_min &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"min\"]\nmn_max_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), model_num]\nmax_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), posterior]  # used for drawing lines on graph\nsum_prob_ge_1se &lt;- round(dt_post[model_num &gt;= mn_1se, sum(posterior)], 5)\nsum_prob_le_min &lt;- round(dt_post[model_num &lt;= mn_min, sum(posterior)], 5)\nsum_prob_ge_1se_label &lt;- paste(\"Pr(&gt;= 1se) = \", sum_prob_ge_1se)\nsum_prob_le_min_label &lt;- paste(\"Pr(&lt;= min) = \", sum_prob_le_min)\npval &lt;- list_primary$prior$list_prior_params$laplace_s_parameters[which(list_primary$prior$list_prior_params$prior_name == dt_post[1, prior_name])]\n\nggplot(data = dt_post, mapping = aes(x = model_num, y = posterior)) + \n  # max post line\n  # annotate(\"segment\", x = mn_max_post, xend = mn_max_post, y=0, yend = max_post, colour = me_colours$teal, linewidth=1.5, linetype = 2) +\n  # annotate(\"text\", x = mn_max_post, y = 1*max_post/3, label=paste(\"Max posterior model\"), colour = me_colours$teal) +\n  # 1se shaded box\n  annotate(\"rect\", xmin = min(dt_post$model_num), xmax = mn_1se, ymin = 0, ymax = max_post, fill = me_colours$orange, alpha = 0.1)+\n  annotate(\"text\", x = min(dt_post$model_num), y = 5*max_post/6, label=sum_prob_ge_1se_label, colour = me_colours$orange, hjust = 0) +\n  # min shaded box\n  # annotate(\"rect\", xmin = mn_min, xmax = max(dt_post$model_num), ymin = 0, ymax = max_post, fill = me_colours$red, alpha = 0.1)+\n  # annotate(\"text\", x = max(dt_post$model_num) + 2, y = 5*max_post/6, label=sum_prob_le_min_label, colour = me_colours$red, hjust = 1) +\n  # 1se line\n  annotate(\"segment\", x = mn_1se, xend = mn_1se, y=0, yend = max_post, colour = me_colours$orange) +\n  annotate(\"text\", x = mn_1se, y = 2*max_post/3, label=paste(\"lambda.1se model\"), colour = me_colours$orange) +\n  # min line\n  annotate(\"segment\", x = mn_min, xend = mn_min, y=0, yend = max_post, colour = me_colours$red) +\n  annotate(\"text\", x = mn_min, y = max_post/2, label=paste(\"lambda.min model\"), colour = me_colours$red) +\n  # posterior\n  geom_line(colour = me_colours$blue) +\n  labs(title = paste(dt_post[1, prior_name], \"prior - laplace scale is\", pval))+\n  coord_cartesian(xlim = c(50, 150)) +\n  NULL\n\n\n\n\n\n\n\n\n\nCode\ndt_post &lt;- CalculatePosterior(list_primary$data, \n                         glmnet_obj = list_primary$glmnet_obj, \n                         varset = list_primary$varset$all,\n                         yvar = \"pmts\", \n                         dt_scaling_factor = NULL, \n                         list_filter = list_dt_filter_params$main, \n                         list_prior_params = list_primary$prior$list_prior_params, \n                         prior_name = \"lambda.1se\",\n                         scale = list_primary$scale)$probs\n\n\n# plot ----;\n# first get some quantities to put on the plot that we use in search for priors\nmn_1se &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"1se\"]\nmn_min &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"min\"]\nmn_max_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), model_num]\nmax_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), posterior]  # used for drawing lines on graph\nsum_prob_ge_1se &lt;- round(dt_post[model_num &gt;= mn_1se, sum(posterior)], 5)\nsum_prob_le_min &lt;- round(dt_post[model_num &lt;= mn_min, sum(posterior)], 5)\nsum_prob_ge_1se_label &lt;- paste(\"Pr(&gt;= 1se) = \", sum_prob_ge_1se)\nsum_prob_le_min_label &lt;- paste(\"Pr(&lt;= min) = \", sum_prob_le_min)\npval &lt;- list_primary$prior$list_prior_params$laplace_s_parameters[which(list_primary$prior$list_prior_params$prior_name == dt_post[1, prior_name])]\n\nggplot(data = dt_post, mapping = aes(x = model_num, y = posterior)) + \n  # max post line\n  annotate(\"segment\", x = mn_max_post, xend = mn_max_post, y=0, yend = max_post, colour = me_colours$teal, linewidth=1.5, linetype = 2) +\n  annotate(\"text\", x = mn_max_post, y = 1*max_post/3, label=paste(\"Max posterior model\"), colour = me_colours$teal) +\n  # 1se shaded box\n  # annotate(\"rect\", xmin = min(dt_post$model_num), xmax = mn_1se, ymin = 0, ymax = max_post, fill = me_colours$orange, alpha = 0.1)+\n  # annotate(\"text\", x = min(dt_post$model_num), y = 5*max_post/6, label=sum_prob_ge_1se_label, colour = me_colours$orange, hjust = 0) +\n  # min shaded box\n  # annotate(\"rect\", xmin = mn_min, xmax = max(dt_post$model_num), ymin = 0, ymax = max_post, fill = me_colours$red, alpha = 0.1)+\n  # annotate(\"text\", x = max(dt_post$model_num) + 2, y = 5*max_post/6, label=sum_prob_le_min_label, colour = me_colours$red, hjust = 1) +\n  # 1se line\n  annotate(\"segment\", x = mn_1se, xend = mn_1se, y=0, yend = max_post, colour = me_colours$orange) +\n  annotate(\"text\", x = mn_1se, y = 2*max_post/3, label=paste(\"lambda.1se model\"), colour = me_colours$orange) +\n  # min line\n  annotate(\"segment\", x = mn_min, xend = mn_min, y=0, yend = max_post, colour = me_colours$red) +\n  annotate(\"text\", x = mn_min, y = max_post/2, label=paste(\"lambda.min model\"), colour = me_colours$red) +\n  # posterior\n  geom_line(colour = me_colours$blue) +\n  labs(title = paste(dt_post[1, prior_name], \"prior - laplace scale is\", pval))+\n  coord_cartesian(xlim = c(50, 150)) +\n  NULL\n\n\n\n\n\n\n\n\n\nCode\ndt_post &lt;- CalculatePosterior(list_primary$data, \n                         glmnet_obj = list_primary$glmnet_obj, \n                         varset = list_primary$varset$all,\n                         yvar = \"pmts\", \n                         dt_scaling_factor = NULL, \n                         list_filter = list_dt_filter_params$main, \n                         list_prior_params = list_primary$prior$list_prior_params, \n                         prior_name = \"lambda.min\",\n                         scale = list_primary$scale)$probs\n\n\n# plot ----;\n# first get some quantities to put on the plot that we use in search for priors\nmn_1se &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"1se\"]\nmn_min &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"min\"]\nmn_max_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), model_num]\nmax_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), posterior]  # used for drawing lines on graph\nsum_prob_ge_1se &lt;- round(dt_post[model_num &gt;= mn_1se, sum(posterior)], 5)\nsum_prob_le_min &lt;- round(dt_post[model_num &lt;= mn_min, sum(posterior)], 5)\nsum_prob_ge_1se_label &lt;- paste(\"Pr(&gt;= 1se) = \", sum_prob_ge_1se)\nsum_prob_le_min_label &lt;- paste(\"Pr(&lt;= min) = \", sum_prob_le_min)\npval &lt;- list_primary$prior$list_prior_params$laplace_s_parameters[which(list_primary$prior$list_prior_params$prior_name == dt_post[1, prior_name])]\n\nggplot(data = dt_post, mapping = aes(x = model_num, y = posterior)) + \n  # max post line\n  annotate(\"segment\", x = mn_max_post, xend = mn_max_post, y=0, yend = max_post, colour = me_colours$teal, linewidth=1.5, linetype = 2) +\n  annotate(\"text\", x = mn_max_post, y = 1*max_post/3, label=paste(\"Max posterior model\"), colour = me_colours$teal) +\n  # 1se shaded box\n  # annotate(\"rect\", xmin = min(dt_post$model_num), xmax = mn_1se, ymin = 0, ymax = max_post, fill = me_colours$orange, alpha = 0.1)+\n  # annotate(\"text\", x = min(dt_post$model_num), y = 5*max_post/6, label=sum_prob_ge_1se_label, colour = me_colours$orange, hjust = 0) +\n  # min shaded box\n  # annotate(\"rect\", xmin = mn_min, xmax = max(dt_post$model_num), ymin = 0, ymax = max_post, fill = me_colours$red, alpha = 0.1)+\n  # annotate(\"text\", x = max(dt_post$model_num) + 2, y = 5*max_post/6, label=sum_prob_le_min_label, colour = me_colours$red, hjust = 1) +\n  # 1se line\n  annotate(\"segment\", x = mn_1se, xend = mn_1se, y=0, yend = max_post, colour = me_colours$orange) +\n  annotate(\"text\", x = mn_1se, y = 2*max_post/3, label=paste(\"lambda.1se model\"), colour = me_colours$orange) +\n  # min line\n  annotate(\"segment\", x = mn_min, xend = mn_min, y=0, yend = max_post, colour = me_colours$red) +\n  annotate(\"text\", x = mn_min, y = max_post/2, label=paste(\"lambda.min model\"), colour = me_colours$red) +\n  # posterior\n  geom_line(colour = me_colours$blue) +\n  labs(title = paste(dt_post[1, prior_name], \"prior - laplace scale is\", pval))+\n  coord_cartesian(xlim = c(50, 150)) +\n  NULL\n\n\n\n\n\n\n\n\n\nCode\ndt_post &lt;- CalculatePosterior(list_primary$data, \n                         glmnet_obj = list_primary$glmnet_obj, \n                         varset = list_primary$varset$all,\n                         yvar = \"pmts\", \n                         dt_scaling_factor = NULL, \n                         list_filter = list_dt_filter_params$main, \n                         list_prior_params = list_primary$prior$list_prior_params, \n                         prior_name = \"complex\",\n                         scale = list_primary$scale)$probs\n\n\n# plot ----;\n# first get some quantities to put on the plot that we use in search for priors\nmn_1se &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"1se\"]\nmn_min &lt;- list_primary$glmnet_obj$index[rownames(list_primary$glmnet_obj$index) == \"min\"]\nmn_max_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), model_num]\nmax_post &lt;- dt_post[which(dt_post$posterior == max(dt_post$posterior)), posterior]  # used for drawing lines on graph\nsum_prob_ge_1se &lt;- round(dt_post[model_num &gt;= mn_1se, sum(posterior)], 5)\nsum_prob_le_min &lt;- round(dt_post[model_num &lt;= mn_min, sum(posterior)], 5)\nsum_prob_ge_1se_label &lt;- paste(\"Pr(&gt;= 1se) = \", sum_prob_ge_1se)\nsum_prob_le_min_label &lt;- paste(\"Pr(&lt;= min) = \", sum_prob_le_min)\npval &lt;- list_primary$prior$list_prior_params$laplace_s_parameters[which(list_primary$prior$list_prior_params$prior_name == dt_post[1, prior_name])]\n\nggplot(data = dt_post, mapping = aes(x = model_num, y = posterior)) + \n  # max post line\n  # annotate(\"segment\", x = mn_max_post, xend = mn_max_post, y=0, yend = max_post, colour = me_colours$teal, linewidth=1.5, linetype = 2) +\n  # annotate(\"text\", x = mn_max_post, y = 1*max_post/3, label=paste(\"Max posterior model\"), colour = me_colours$teal) +\n  # 1se shaded box\n  # annotate(\"rect\", xmin = min(dt_post$model_num), xmax = mn_1se, ymin = 0, ymax = max_post, fill = me_colours$orange, alpha = 0.1)+\n  # annotate(\"text\", x = min(dt_post$model_num), y = 5*max_post/6, label=sum_prob_ge_1se_label, colour = me_colours$orange, hjust = 0) +\n  # min shaded box\n  annotate(\"rect\", xmin = mn_min, xmax = max(dt_post$model_num), ymin = 0, ymax = max_post, fill = me_colours$red, alpha = 0.1)+\n  annotate(\"text\", x = max(dt_post$model_num) + 2, y = 5*max_post/6, label=sum_prob_le_min_label, colour = me_colours$red, hjust = 1) +\n  # 1se line\n  annotate(\"segment\", x = mn_1se, xend = mn_1se, y=0, yend = max_post, colour = me_colours$orange) +\n  annotate(\"text\", x = mn_1se, y = 2*max_post/3, label=paste(\"lambda.1se model\"), colour = me_colours$orange) +\n  # min line\n  annotate(\"segment\", x = mn_min, xend = mn_min, y=0, yend = max_post, colour = me_colours$red) +\n  annotate(\"text\", x = mn_min, y = max_post/2, label=paste(\"lambda.min model\"), colour = me_colours$red) +\n  # posterior\n  geom_line(colour = me_colours$blue) +\n  labs(title = paste(dt_post[1, prior_name], \"prior - laplace scale is\", pval))+\n  #coord_cartesian(xlim = c(75, 200)) +\n  NULL\n\n\n\n\n\n\n\n\n\n\nBayesian averaging of primary model path\nWe get a first initial estimate of model error by applying Bayesian averaging to the Lasso model path from the initial model. We do this for each of the priors.\nFirst get the posteriors (basically rerunning the code above but putting it into the right object this time).\n\nlist_fitted &lt;- list_probs &lt;- vector(mode = \"list\", length = length(list_primary$prior$list_prior_params$prior_name))\n\nfor(v in list_primary$prior$list_prior_params$prior_name){\n  tem &lt;- CalculatePosterior(list_primary$data, \n                            glmnet_obj = list_primary$glmnet_obj, \n                            varset = list_primary$varset$all,\n                            yvar = \"pmts\", \n                            dt_scaling_factor = NULL, \n                            list_filter = list_dt_filter_params$main, \n                            list_prior_params = list_primary$prior$list_prior_params, \n                            prior_name = v,\n                            scale = list_primary$scale,\n                            return_fitted = TRUE)\n  list_probs[[v]] &lt;- copy(tem$probs)\n  list_fitted [[v]] &lt;- copy(tem$fitted)\n  \n}\n\nlist_primary$dt_probs &lt;- rbindlist(list_probs)\n\ndt_fitted &lt;- rbindlist(list_fitted)  # needed for scaling later on\n\n# factor prior_name to preserve ordering\nlist_primary$dt_probs[, prior_name := factor(prior_name, levels =list_primary$prior$list_prior_params$prior_name)]\ndt_fitted[, prior_name := factor(prior_name, levels =list_primary$prior$list_prior_params$prior_name)]\n\nNow do the Bayesian averaging. We also need to get the posterior average cashflows by acc and dev for use in the bootstraping filtering step - when applying the inclusion gates we do it relative to the posterior cashflows for that particular prior.\n\n# run the Bayesian averaging\nlist_primary$dt_results &lt;- SummariseBayesianAveraging(list_primary$dt_probs)\n\n# Primary posterior forecasts\nlist_primary$dt_posterior_forecasts &lt;- GetPosteriorForecasts(dt_fitted, list_primary$dt_probs)\n\n\n\nResults\nFinally display the results.\n\npost_cov is our initial estimate of internal model structure error - but limited since the model set is sparse\npost_cov_pe adds on process error (we sample each future fitted value from a gamma distribution determined by the cell mean and the scale parameter)\n\nHowever this is not particularly reliable here since we don’t have enough observations.\n\n\n\n# display table of results\nlist_primary$dt_results |&gt; \n  datatable() |&gt; \n  formatRound(c(\"post_mean\", \"post_sd\", \"post_mean_pe\", \"post_sd_pe\"), digits=0) |&gt; \n  formatPercentage(c(\"post_cov\", \"post_cov_pe\"), digits=2)"
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#bootstrap",
    "href": "post/2023-05-04-model-error-example/index.html#bootstrap",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "Bootstrap",
    "text": "Bootstrap\nNow we move onto the bootstrap. The process is described in Section 6.2 of the paper. In less formal language the steps are:\n\nGenerate \\(B\\) pseudo data sets using a semi-parametric bootstrap. By this, I mean that we start with the lambda.1se fitted values, randomly sample the residuals (with replacement) \\(B\\) times and generate \\(B\\) pseudo data sets by combining the fitted values with each of the \\(B\\) samples\nFit a Lasso model to each using the set of lambda values used in the primary model\nFor each bootstrapped sample, produce the liability estimates and posterior probabilities. Since we will centre the bootstraps around the posterior forecasts (next point), which in turn will change the posteriors, use wider inclusion gates to avoid eliminating bootstraps on the boundary of acceptability\nCalculate the scaling factor required to scale the sample mean of the posterior means from each pseudo data set to the original posterior means\nFilter the results based on the normal inclusion gates\nRecalculate the reserves and posterior probabilities\nDrop any bootstrap replication \\(b\\) which has fewer than 5 models with a posterior probability of at least 0.0001.\n\nIn terms of R code, I’ve wrapped all this up in a single function (consisting of a number of other sub-functions) - ParallelBootstrap(). So you’ll need to refer to the function file for the details there.\n\nSemi-parametric bootstrap and first round of calculations\nHere we do steps 1-3 from above.\nAs with the primary model, we’ll make a list to hold all the results from the bootstrapping\n\nlist_bs &lt;- list()\n\nThe time-consuming part of this process is fitting the Lasso models. In the _functions.R file, the BootstrapBatch() is the actual workhorse function that does the bootstrapping. ParallelBootstrap() is a wrapper around it which gives the option of running the code in parallel to speed things up. For example, to produce the numerical results in the paper, I ran 10 parallel processes on a linux machine and it took about 72 minutes.\nNote that the parallelisation currently only works on linux since I’ve used forking. If you want to run parallel code under windows you will need to edit the ParallelBootstrap() function to handle sockets.\n\nx &lt;- ParallelBootstrap(dt = list_primary$data,\n                       nboot = num_bootstraps,\n                       scale = list_primary$scale,\n                       resid_name = \"resid\",\n                       var_pred_name = \"var_pred\",\n                       min_val = 10,\n                       vec_lambda = lambdavec,\n                       list_varset = list_primary$varset,\n                       yvar = \"pmts\",\n                       dfmax = dfmax_default,\n                       pmax = pmax_default,\n                       thresh = 1e-7,  # higher threshold speeds things up a bit\n                       list_prior_params = list_primary$prior$list_prior_params,\n                       dt_scaling_factor = NULL,\n                       list_filter = list_dt_filter_params$initial,  # wider gates\n                       parallel = use_parallel,   # TRUE for parallel, only works on linux\n                       nworkers = num_workers,    # set to number of parallel processes\n                       batchsize = batchsize\n)\n\n[1] \"Time taken: 3.7992 mins\"\n\nlist_bs$list_glmnet &lt;- x$list_glmnet\nlist_bs$dt_unscaled_probs &lt;- x$dt_probs\nlist_bs$dt_bs_data &lt;- x$dt_bs_data\n\nlist_bs$dt_unscaled_results &lt;- CalculateModelError(list_bs$dt_unscaled_probs, min_model_number = 5, min_model_prob_threshold = 1e-4)$results\n\nrm(x)\ngc()  \n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 2526149 135.0    4438395 237.1  4438395 237.1\nVcells 9087459  69.4   17860456 136.3 17860456 136.3\n\n\nParallelBootstrap() returns a list with three elements:\n\na list of all the fitted Lasso models, one for each bootstrap\na data.table of the posterior probabilities for all the models that survive the filtering\na data.table of all the pseudo data sets.\n\nI’ve calculated results after this initial round. This is to facilitate the scaling (next step), other than that we don’t use these results\n\n\nScaling factors\n\nCalculate factors so that the posterior bootstrapped means will match the means from the primary model (step 4 above)\nNote, however, that we don’t expect to get exact matches after scaling. This is because the scaling will lead to some changes in the posterior calculations, and possibly even the included bootstraps\n\n\n# combine bootstrap means and primary posterior means and get scaling\nlist_bs$dt_scaling &lt;- list_bs$dt_unscaled_results[ list_primary$dt_results[, .(prior_name, post_mean)], \n                                          on=.(prior_name), \n                                          primary_post_mean := i.post_mean][, .(prior_name, primary_post_mean, bs_means_mean)]\n\nlist_bs$dt_scaling[, scaling_factor := primary_post_mean / bs_means_mean]\n\n# print out the scaling factors\nlist_bs$dt_scaling |&gt; \n  datatable() |&gt; \n  formatRound(columns = c(\"bs_means_mean\", \"primary_post_mean\"), digits=0, mark=\",\") |&gt; \n  formatPercentage(columns = c(\"scaling_factor\", \"scaling_factor\"), digits=2) \n\n\n\n\n\n\n\n\nRescale the bootstraps\nWe now carry out steps 5-7 above. When calling ParallelBootstrap() this time:\n\nThe input data is the data.table containing all the pseudo data sets\nI use the argument list_glmnet to pass in the list of fitted Lassos. This tells the function not to actually refit the Lasso models. Instead, it just scales the past fitted values for the scaling factor (for the likelihood) and adjusts the intercept term in all the models by the scaling factor (for the prior and the reserve predictions).\nI also use the main inclusion gates rather than the wider ones.\n\nThe function then carried out steps 5-7 and we get a table of all retained bootstraps and the posterior probability of each model. We can then calculate the model error with the CalculateModelError() function.\n\nx &lt;- ParallelBootstrap(dt = list_bs$dt_bs_data,\n                       nboot = num_bootstraps,\n                       scale = list_primary$scale,\n                       resid_name = \"resid\",\n                       var_pred_name = \"var_pred\",\n                       min_val = 10,\n                       vec_lambda = lambdavec,\n                       list_varset = list_primary$varset,\n                       yvar = \"pmts\",\n                       dfmax = dfmax_default,\n                       pmax = pmax_default,\n                       thresh = 1e-7,\n                       list_prior_params = list_primary$prior$list_prior_params,\n                       dt_scaling_factor = list_bs$dt_scaling,\n                       list_filter = list_dt_filter_params$main,\n                       parallel = use_parallel,\n                       nworkers = num_workers,\n                       batchsize = batchsize,\n                       list_glmnet = list_bs$list_glmnet )\n\n[1] \"Time taken: 2.8138 mins\"\n\nlist_bs$dt_probs &lt;- x$dt_probs\n\ntem &lt;- CalculateModelError(list_bs$dt_probs, min_model_number = 5, min_model_prob_threshold = 1e-4)\nlist_bs$dt_results &lt;- tem$results\nlist_bs$dt_retained_bs &lt;- tem$retained_bs\n\nrm(x, tem)\ngc()\n\n          used  (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 2526368 135.0    4438395 237.1  4438395 237.1\nVcells 9627279  73.5   21512547 164.2 17860456 136.3"
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#results-1",
    "href": "post/2023-05-04-model-error-example/index.html#results-1",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "Results",
    "text": "Results\nFinally we can look at some results. I’ve shown results for all priors here, but, as per the paper, we consider the lambda.1se and the lambda.min priors the appropriate ones to choose between. In both of those all bootstraps are retained (same is true for simple), but many are filtered out for the complex model - and, based on the CDF graphs, it is inappropriate to use it.\n\n# used to format tables\n\npercent_cols &lt;- c(\"bs_covs_mean\", \"bs_variances_cov\", \"bs_means_cov\", \n                  \"cov_model_param_process_error\", \"cov_model_error\", \"cov_param_error\", \"cov_process_error\")\npercent_cols &lt;- c(percent_cols, paste0(percent_cols, \"_pe\"))\n\n\nGrand resultsUnderlying tableIndividual bootstrap resultsCDFs of scaled bootstraps - no process errorCDFs of scaled bootstraps - with process error\n\n\n\ngrand_results_cols &lt;- c(\"cov_model_param_process_error\", \"cov_model_error\", \"cov_param_error\", \"cov_process_error\",\n                        \"bs_means_mean\", \"num_bs\",\n                        \"sd_model_param_process_error\", \"sd_model_error\", \"sd_param_error\", \"sd_process_error\")\n\n\nkv &lt;- c(\"prior_name\", grand_results_cols)\nkvpc &lt;- intersect(kv, percent_cols)\n\nlist_bs$dt_results[, ..kv] |&gt; \n  datatable() |&gt; \n  formatRound(columns = setdiff(kv, c(\"prior_name\", kvpc)), digits=0, mark=\",\") |&gt; \n  formatPercentage(columns = kvpc, digits=2) \n\n\n\n\n\n\n\n\nGrand results taken calculated from this\n\nkv &lt;- setdiff(names(list_bs$dt_results), grand_results_cols)\nkvpc &lt;- intersect(kv, percent_cols)\n\nlist_bs$dt_results[, ..kv] |&gt; \n  datatable() |&gt; \n  formatRound(columns = setdiff(kv, c(\"prior_name\", kvpc)), digits=0, mark=\",\") |&gt; \n  formatPercentage(columns = kvpc, digits=2) \n\n\n\n\n\n\n\n\n\n# calculate posterior means, variances\n\nlist_bs$dt_idv_results &lt;- list_bs$dt_probs[,`:=`(bs_post_mean = sum(reserve * posterior), bs_post_mean_pe = sum(reserve_pe * posterior)), \n                                             by=.(boot, prior_name)\n                                          ][, .(bs_post_mean = mean(bs_post_mean),\n                               bs_post_mean_pe = mean(bs_post_mean_pe),\n                               bs_post_var = sum( ((reserve - bs_post_mean)^2) * posterior),\n                               bs_post_var_pe = sum( ((reserve_pe - bs_post_mean_pe)^2) * posterior)    ), \n                           keyby = .(boot, prior_name)]\n\n\n# add sd and cov now\nlist_bs$dt_idv_results[, `:=`(bs_post_sd = sqrt(bs_post_var), \n                           bs_post_sd_pe = sqrt(bs_post_var_pe),\n                           bs_post_cov = sqrt(bs_post_var) / bs_post_mean, \n                           bs_post_cov_pe = sqrt(bs_post_var_pe) / bs_post_mean_pe)]\n\n\ndatatable(list_bs$dt_idv_results, options = list(pageLength = 12, lengthMenu=c(12, 20, 40, 100))) |&gt; \n  formatRound(columns = setdiff(names(list_bs$dt_idv_results), c(\"boot\", \"prior_name\", \"bs_post_cov\", \"bs_post_cov_pe\")), digits=0, mark=\",\") |&gt; \n  formatPercentage(columns = c(\"bs_post_cov\", \"bs_post_cov_pe\"), digits=2) \n\n\n\n\n\n\n\n\n\n# probs_retained_bs calculated above\n\n# combine the original and bootstrapped priors now\ncdfs &lt;- rbind( list_primary$dt_probs[, .(model_num, prior_name, posterior, reserve)][, boot := 0],\n               list_bs$dt_probs[, .(boot, model_num, prior_name, posterior, reserve)]  )\n\nsetorder(cdfs, boot, prior_name, reserve)\ncdfs[, cdf := cumsum(posterior), keyby=.(boot, prior_name)]\n\n# plot\nggplot(data=cdfs, aes(x=reserve, y=cdf, colour = factor(boot), alpha = factor(boot), linewidth = factor(boot)))+\n  geom_line()+\n  facet_wrap(~prior_name)+\n  scale_colour_manual(values=c(me_colours$red, rep(me_colours$grey, max(cdfs$boot))))+\n  scale_alpha_manual(values=c(1, rep(0.25, max(cdfs$boot))))+\n  scale_linewidth_manual(values=c(2, rep(0.5, max(cdfs$boot))))+\n  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))+\n  theme(legend.position=\"none\")+\n  NULL\n\n\n\n\n\n\n\n# probs_retained_bs calculated above\n\n# combine the original and bootstrapped priors now\ncdfs &lt;- rbind( list_primary$dt_probs[, .(model_num, prior_name, posterior, reserve)][, boot := 0],\n               list_bs$dt_probs[, .(boot, model_num, prior_name, posterior, reserve_pe)][, reserve := reserve_pe][, reserve_pe := NULL]  )\n\nsetorder(cdfs, boot, prior_name, reserve)\ncdfs[, cdf := cumsum(posterior), keyby=.(boot, prior_name)]\n\n# plot\nggplot(data=cdfs, aes(x=reserve, y=cdf, colour = factor(boot), alpha = factor(boot), linewidth = factor(boot)))+\n  geom_line()+\n  facet_wrap(~prior_name)+\n  scale_colour_manual(values=c(me_colours$red, rep(me_colours$grey, max(cdfs$boot))))+\n  scale_alpha_manual(values=c(1, rep(0.25, max(cdfs$boot))))+\n  scale_linewidth_manual(values=c(2, rep(0.5, max(cdfs$boot))))+\n  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))+\n  theme(legend.position=\"none\")+\n  NULL\n\n\n\n\n\n\n\n\nComparison with previous results\nIn Section 5.4.2 of the CAS monograph, we used the bootstrap to estimate parameter and process error and found a coefficient of variation of prediction of 3.8%.\nOur results for the two main priors are 3.5% and 5.1% so in a similar ball-park. A priori we’d expect low internal model structural error for this data set since we know that it is well represented by a chain ladder model, while a small number of interactions improve it further. It’s also quite small and simple so we can be confidence that we’re not missing model structure.\nThe GLM results in the monograph were not subject to any filtering of results for inappropriate extrapolation so may have slightly overstated parameter and process error. As noted in our paper (Section 7.4), results can be quite sensitive to inclusion gates."
  },
  {
    "objectID": "post/2023-05-04-model-error-example/index.html#conclusion",
    "href": "post/2023-05-04-model-error-example/index.html#conclusion",
    "title": "Model error via regularised regression - CAS monograph data",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tutorial we’ve worked through the our forecast error estimation process. The same code can be used for larger data sets, such as the synthetic data sets from the paper, with the relevant adjustments (mainly high-level stuff, e.g. appropriate parameters for creating the basis functions).\nWhile some of this functionality is specific to models fitted with a Lasso (e.g. prior specification and selection), other parts (e.g. the filtering) are of relevance to any bootstrapping exercise, whether underpinned by a machine learning algorithm, a GLM or even a chain ladder.\nFinally, don’t forget about the other components of forecast error, specifically external model error, which may require other, more qualitative methods to assess."
  }
]