<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hugh Miller | GMG</title>
    <link>/authors/hugh-miller/</link>
      <atom:link href="/authors/hugh-miller/index.xml" rel="self" type="application/rss+xml" />
    <description>Hugh Miller</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Grainne McGuire 2020 [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/)</copyright><lastBuildDate>Fri, 31 Aug 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Hugh Miller</title>
      <link>/authors/hugh-miller/</link>
    </image>
    
    <item>
      <title>Self-assembling insurance claim models using regularized regression and machine learning</title>
      <link>/publication/sagacious/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/publication/sagacious/</guid>
      <description>


&lt;p&gt;The lasso is applied in an attempt to automate the loss reserving problem. The regression form contained within the lasso is a GLM, and so that the model has all the versatility of that type of model, but the model selection is automated and the parameter coefficients for selected terms will not be the same.&lt;/p&gt;
&lt;p&gt;There are two applications presented, one to synthetic data in conventional triangular form, and another to real data.The secret of success in such an endeavor is the selection of the set of candidate basis functions for representation of the data set. Cross-validation is used for model selection.&lt;/p&gt;
&lt;p&gt;The lasso performs well in modelling, identifying known features in the synthetic data, and tracking them accurately. This is despite complexity in those features that would challenge, and possibly defeat, most loss reserving alternatives. In the case of real data, the lasso also succeeds in tracking features of the data that analysis of the data set over many years has rendered virtually known.&lt;/p&gt;
&lt;p&gt;A later section of the paper discusses the prediction error associated with a lasso-based loss reserve. It is seen that the procedure can be readily adapted to the estimation of parameter and process error, but can also estimate one component of model error. To the authors knowledge, no other loss reserving model in the literature does so. &#34;&lt;/p&gt;
&lt;p&gt;See my &lt;a href=&#34;/post/self-assembling-claim-reserving-models&#34;&gt;blog post&lt;/a&gt; for a tutorial on how to use the method described in this paper.&lt;/p&gt;
&lt;!--

doi: &#34;&#34;


--&gt;
</description>
    </item>
    
  </channel>
</rss>
